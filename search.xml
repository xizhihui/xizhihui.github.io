<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>杀虫剂</title>
      <link href="/2018/11/27/Bugs/"/>
      <url>/2018/11/27/Bugs/</url>
      
        <content type="html"><![CDATA[<p>程序员，男的又叫“程序猿”，女的又称“程序媛”，但是，他两又合称“码农”。既然是码农，自然要除虫。哈？除什么虫？你不知道？天啦噜，活捉一只不会写 Bug 的生物。让我来告诉你，什么叫 Bug，下面这货就是了：</p><p><img src="first_bug.jpg" alt="Bug"></p><p>看见没，既然有了虫子，就要除掉它啦。这里给你所有类型的杀虫剂。</p><a id="more"></a><h3 id="1-问题描述：小弟我用-hexo-建立自己的静态博客，然后部署到-GitHub-之后发现，Tag-文件夹被改成-tag-文件夹，导致博客访问出现-404。"><a href="#1-问题描述：小弟我用-hexo-建立自己的静态博客，然后部署到-GitHub-之后发现，Tag-文件夹被改成-tag-文件夹，导致博客访问出现-404。" class="headerlink" title="1. 问题描述：小弟我用 hexo 建立自己的静态博客，然后部署到 GitHub 之后发现，Tag 文件夹被改成 tag 文件夹，导致博客访问出现 404。"></a>1. 问题描述：小弟我用 hexo 建立自己的静态博客，然后部署到 GitHub 之后发现，<code>Tag</code> 文件夹被改成 <code>tag</code> 文件夹，导致博客访问出现 404。</h3><p>这个开始不好办，因为我不知道出什么地方，然后去改配置啊，改来改去。后来发现啊，是 Git 它默认对大小写不敏感，才会在经过 Git 之后的发布变成小写。这里是杀虫剂，从 <strong><a href="http://www.wujinyu.com/2017/09/01/other/hexo-404/" target="_blank" rel="noopener">卡布奇诺</a></strong> 得到的，感谢他。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> .deploy_git</span><br><span class="line">git config ignorecase <span class="literal">false</span></span><br><span class="line">git rm -rf *</span><br><span class="line">git commit -m <span class="string">'clean all file'</span></span><br><span class="line">git push</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line">hexo clean</span><br><span class="line">hexo deploy -generate</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>第一次写的文</title>
      <link href="/2018/11/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%86%99%E7%9A%84%E6%96%87/"/>
      <url>/2018/11/26/%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%86%99%E7%9A%84%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h2 id="这只是一个测试"><a href="#这只是一个测试" class="headerlink" title="这只是一个测试"></a>这只是一个测试</h2><p>╮(╯▽╰)╭，说来也惭愧。自己花2天时间写个简易的静态博客，包含类似 <code>hexo new</code>, <code>hexo publish</code> 之类的功能，主题就照着 less 官网的形式来写。虽然也依葫芦画瓢添加上文章分类、标签等功能，但是多多少少总会出现点 bug，比如文章列表在点击“展开”之后再点击收回，再点击“展开”的话，就有可能出现文章列表排序不一致的情况，也是要吐血了。发布到 GitHub 上才发现这个问题。这是其一。自己写这个页面框架，在移动端适配方面还是有点不如意，特别是我偷懒直接使用 Rmd 直出 HTML 页面的形式，总有一点异样的味道。这是其二。最近心里有些波动的情况，又时常会想起当初要不要坚持搞这个的问题，人呐，就是这样滴哦，一出现不如意，就想起当初，如果当时。哈哈，这其实也怪生信这个坑，一旦掉入包安装的错误怪圈，就不容易出来，等到腰酸背痛，双目发涩快要失明，就发觉啊，莫名其妙的一下午就这么过去了，就这么过去了。也就时候听见，嘀嗒，嘀嗒，嘀嗒。每次我敲下键盘，它总是响应我这些声音。窗外的邻居喧嚣，也没遮掩掉它。感觉它想要我写点什么，究竟写什么？不好说，写着看吧。伴随着嘀嗒嘀嗒的声音，总算有一些句子出现在这屏幕上。然后是一声滴<del>~</del><del>~</del>~~~~哒，那么些东西，就回退到这里，那就停手罢，今天就这样。因为：</p><blockquote><p>这只是一个测试。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 随想 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随想 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>可视化 ggplot2入门</title>
      <link href="/2018/11/02/%E5%8F%AF%E8%A7%86%E5%8C%96-ggplot2%E5%85%A5%E9%97%A8/"/>
      <url>/2018/11/02/%E5%8F%AF%E8%A7%86%E5%8C%96-ggplot2%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<p>久闻 ggplot2 大名，它的出图也在各个生信分析包中随处可见。今天恰好买来的新书《R 数据科学》里面有讲解，遂随着它一起学习一下，也将以前的相关学习一齐记录于此。</p><a id="more"></a><p>这里我们使用的是 ggplot2 自带的 mpg 和 diamonds 数据集，还有 nlme 的Oxboys 数据集。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">suppressMessages(<span class="keyword">library</span>(ggplot2))</span><br><span class="line">suppressMessages(<span class="keyword">library</span>(reshape2))</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mpg[<span class="number">1</span>:<span class="number">5</span>, ]</span><br><span class="line">diamonds[<span class="number">1</span>:<span class="number">5</span>, ]</span><br><span class="line">data(Oxboys, package = <span class="string">"nlme"</span>)</span><br><span class="line">Oxboys[<span class="number">1</span>:<span class="number">5</span>, ]</span><br></pre></td></tr></table></figure><h2 id="ggplot2-初探"><a href="#ggplot2-初探" class="headerlink" title="ggplot2 初探"></a>ggplot2 初探</h2><h3 id="用-ggplot2-画个图"><a href="#用-ggplot2-画个图" class="headerlink" title="用 ggplot2 画个图"></a>用 ggplot2 画个图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step 1 生成 ggplot 画板，指定数据对象</span></span><br><span class="line">myplot = ggplot(data=mpg)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 2 添加几何对象 (geom_point)，添加图形映射 (aes)</span></span><br><span class="line">ggplot(data=mpg) + </span><br><span class="line">    geom_point(mapping=aes(x=displ, y=hwy))</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 3 添加其他图形映射, 如 color, size, alpha, shape</span></span><br><span class="line"><span class="comment"># 颜色属性 color 以 mpg$class 进行映射</span></span><br><span class="line"><span class="comment"># 大小属性 size 以 mpg$class 进行映射</span></span><br><span class="line">ggplot(data=mpg) + </span><br><span class="line">    geom_point(mapping = aes(x=displ, y=hwy, color=class, size=class))</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 4 尝试改变几何对象的图形属性, 注意与图形映射属性的差别</span></span><br><span class="line">ggplot(data=mpg) + </span><br><span class="line">    geom_point(mapping = aes(x=displ, y=hwy), color=<span class="string">"blue"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 5 尝试使用连续变量来映射图形属性, </span></span><br><span class="line"><span class="comment"># 这时候分类变量就会变成连续的图形属性，比如 color 是颜色过渡而非颜色分类; </span></span><br><span class="line"><span class="comment"># 对于本就是连续变量的图形属性来讲，就没啥影响，比如 size</span></span><br><span class="line"><span class="comment"># 这里的 dispal &lt; 5 生成了一个分类变量</span></span><br><span class="line">ggplot(data = mpg) +</span><br><span class="line">    geom_point(mapping = aes(x=displ, y=hwy, size=cty, color=displ &lt; <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 6 分面的引入</span></span><br><span class="line"><span class="comment"># 前面通过添加图形属性映射来添加新的变量；</span></span><br><span class="line"><span class="comment"># 除此之外，也可以通过分面实现，但是要注意，二者的表现形式不同</span></span><br><span class="line"><span class="comment"># 分面会对变量进行 level，根据 level 设置对应的分面；即便使用的是连续变量</span></span><br><span class="line"><span class="comment"># 单变量分面, 我们得到的是网格形式排列（行列）的分面，ncol 和 nrow 指定行列数</span></span><br><span class="line">ggplot(data=mpg) +</span><br><span class="line">    geom_point(mapping=aes(x=displ, y=hwy)) +</span><br><span class="line">    facet_wrap(~ class)</span><br><span class="line"><span class="comment"># 双变量分面</span></span><br><span class="line">ggplot(data=mpg) +</span><br><span class="line">    geom_point(mapping = aes(x=displ, y=hwy)) +</span><br><span class="line">    facet_grid(drv ~ cyl)</span><br><span class="line">ggplot(data=mpg) +</span><br><span class="line">    geom_point(mapping = aes(x=displ, y=hwy)) +</span><br><span class="line">    facet_grid(cyl ~ drv)</span><br><span class="line"><span class="comment"># 单变量分面，不做网格形式，仅做行排列或列排列</span></span><br><span class="line">ggplot(data=mpg) +</span><br><span class="line">    geom_point(mapping = aes(x=displ, y=hwy)) +</span><br><span class="line">    facet_grid(class ~ .)</span><br><span class="line">ggplot(data=mpg) +</span><br><span class="line">    geom_point(mapping = aes(x=displ, y=hwy)) +</span><br><span class="line">    facet_grid(. ~ class)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 7 使用其他几何对象来表现数据</span></span><br><span class="line">ggplot(data=mpg) +</span><br><span class="line">    geom_point(mapping=aes(x=displ, y=hwy, color=class)) +</span><br><span class="line">    geom_smooth(mapping=aes(x=displ, y=hwy, linetype=class, color=class))</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 8 不同的几何对象的公有和私有图形属性映射</span></span><br><span class="line">ggplot(data=mpg, mapping=aes(x=displ, y=hwy)) +</span><br><span class="line">    geom_point(mapping=aes(color=class)) +</span><br><span class="line">    geom_smooth()</span><br><span class="line"><span class="comment"># step 9 不同几何对象的私有数据对象, geom_smooth 只对 subcompact 生成拟合曲线</span></span><br><span class="line">ggplot(data=mpg, mapping=aes(x=displ, y=hwy)) +</span><br><span class="line">    geom_point(mapping=aes(color=class)) +</span><br><span class="line">    geom_smooth(data=filter(mpg, class==<span class="string">"subcompact"</span>), se=<span class="literal">F</span>)</span><br></pre></td></tr></table></figure><h3 id="尝试一个数据的不同画法"><a href="#尝试一个数据的不同画法" class="headerlink" title="尝试一个数据的不同画法"></a>尝试一个数据的不同画法</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step 10 尝试一个数据的不同画法</span></span><br><span class="line">ggplot(data=mpg, mapping=aes(x=displ, y=hwy)) +</span><br><span class="line">    geom_point() +</span><br><span class="line">    geom_smooth(se=<span class="literal">F</span>)</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ggplot(data=mpg, mapping=aes(x=displ, y=hwy)) +</span><br><span class="line">    geom_point() +</span><br><span class="line">    geom_smooth(se=<span class="literal">F</span>, mapping=aes(group=drv))</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ggplot(data=mpg, mapping=aes(x=displ, y=hwy, color=drv)) +</span><br><span class="line">    geom_point() +</span><br><span class="line">    geom_smooth(se=<span class="literal">F</span>)</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ggplot(data=mpg, mapping=aes(x=displ, y=hwy)) +</span><br><span class="line">    geom_point(mapping=aes(color=drv)) +</span><br><span class="line">    geom_smooth(se=<span class="literal">F</span>)</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ggplot(data=mpg, mapping=aes(x=displ, y=hwy, color=drv)) +</span><br><span class="line">    geom_point() +</span><br><span class="line">    geom_smooth(se=<span class="literal">F</span>, mapping=aes(linetype=drv))</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ggplot(data=mpg, mapping=aes(x=displ, y=hwy, color=drv)) +</span><br><span class="line">    geom_point()</span><br></pre></td></tr></table></figure><h3 id="引入其他新元素如统计变换、坐标变换"><a href="#引入其他新元素如统计变换、坐标变换" class="headerlink" title="引入其他新元素如统计变换、坐标变换"></a>引入其他新元素如统计变换、坐标变换</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># step 10 引入统计变换</span></span><br><span class="line">ggplot(data=diamonds) +</span><br><span class="line">    stat_summary(mapping=aes(x=cut, y=depth), fun.ymin=min, fun.ymax=max, fun.y=median)</span><br><span class="line">ggplot(data=diamonds, mapping=aes(x=cut, y=depth)) + geom_boxplot()</span><br><span class="line"></span><br><span class="line">ggplot(data=diamonds) +</span><br><span class="line">    geom_bar(mapping=aes(x=cut, y=..prop.., group=<span class="number">1</span>))</span><br><span class="line">ggplot(data=diamonds) +</span><br><span class="line">    geom_bar(mapping=aes(x=cut, y=..prop..))</span><br><span class="line"></span><br><span class="line">ggplot(data=mpg, mapping=aes(x=cty, y=hwy)) + geom_point(position = <span class="string">"jitter"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## step 11 引入坐标变换</span></span><br><span class="line">mybar = ggplot(data=diamonds, aes(x=cut, fill=clarity)) +</span><br><span class="line">    geom_bar()</span><br><span class="line">mybar + coord_flip()</span><br><span class="line">mybar + coord_polar()</span><br><span class="line"></span><br><span class="line">ggplot(data=mpg, mapping=aes(x=cty, y=hwy)) +</span><br><span class="line">    geom_point() + geom_abline()</span><br><span class="line">ggplot(data=mpg, mapping=aes(x=cty, y=hwy)) +</span><br><span class="line">    geom_point() + geom_abline() + coord_fixed()</span><br></pre></td></tr></table></figure><h2 id="ggplot2-进阶"><a href="#ggplot2-进阶" class="headerlink" title="ggplot2 进阶"></a>ggplot2 进阶</h2><blockquote><p>在for循环和函数里, ggplot的图形需要显示调用print(plot)才能画出来.</p></blockquote><h3 id="ggplot2-图形分层语法总结"><a href="#ggplot2-图形分层语法总结" class="headerlink" title="ggplot2 图形分层语法总结"></a>ggplot2 图形分层语法总结</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ggplot(data=&lt;DATA&gt;) +</span><br><span class="line">    &lt;geom_function&gt;(</span><br><span class="line">        mapping = aes(&lt;MAPPINGS&gt;),</span><br><span class="line">        stat = &lt;STAT&gt;,</span><br><span class="line">        position = &lt;POSITION&gt;</span><br><span class="line">    ) +</span><br><span class="line">    &lt;scale_function&gt; +</span><br><span class="line">    &lt;coord_function&gt; +</span><br><span class="line">    &lt;facet_function&gt;</span><br></pre></td></tr></table></figure><ul><li>\&lt;DATA>, 数据：必须是一个数据框</li><li>\&lt;MAPPINGS>, 一组图形属性映射，设定数据集中的变量如何映射到该图层的图形属性</li><li>\&lt;geom_function>, 几何对象，指定在图层中进行绘图的几何对象类型</li><li>\&lt;STAT>, 统计变换，指定时候对元数据进行统计变换</li><li>\&lt;POSITION>, 位置调整，指定图形元素的位置，避免图形重合</li><li>\&lt;coord_function>, 坐标变换: coordinate system, 描述数据与图形所在平面的映射关系</li><li>\&lt;facet_function>, 分面设定: 条件作图或网格作图，分解数据成为子集并对后者作图、联合展示</li><li>\&lt;scale_function>, 标度调整指定数据-图形属性、数据-位置、数据-坐标等的映射关系( f(x) )</li></ul><h3 id="数据和图形属性映射"><a href="#数据和图形属性映射" class="headerlink" title="数据和图形属性映射"></a>数据和图形属性映射</h3><h4 id="数据与映射"><a href="#数据与映射" class="headerlink" title="数据与映射"></a>数据与映射</h4><p>ggplot函数对数据的类型要求为数据框(data.frame),它不会直接修改原数据，而是创建一个副本。你可以使用 “%+%” 来改变数据集。你要保证aes的变量(这里是carat,price,cut)都是来自于data(这里是diamonds)，以保证ggplot对象是自含型的。在定义映射时，我们要注意区分设定和映射。例如下方darkblue，在定义为映射时，“darkblue”作为只有一个元素的变量，然后对该变量进行映射，所以你会发现画出的图形上会出现分组信息（单个组darkblue）而图形颜色不是darkblue。而设定则是直接把图形颜色设定为darkblue。这在前面 gglot2 初探的 step4 有涉及。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">p = ggplot(data=diamonds, aes(carat, price, colour=cut))</span><br><span class="line">p %+% mtcars<span class="comment"># 进行映射的数据集被改为mtcars</span></span><br><span class="line"></span><br><span class="line">p + geom_point(aes(colour=<span class="string">'darkblue'</span>))<span class="comment"># 映射</span></span><br><span class="line">p + geom_point(colour=<span class="string">'darkblue'</span>) <span class="comment"># 设定</span></span><br></pre></td></tr></table></figure><h4 id="分组、群组"><a href="#分组、群组" class="headerlink" title="分组、群组"></a>分组、群组</h4><p>有时候，我们想对数据进行分组展示。就需要对映射指定分组变量。分组变量的指定与否会产生很明显的差别（群组）。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ggplot(Oxboys, aes(age, height, group=Subject)) + geom_line()</span><br><span class="line">ggplot(Oxboys, aes(age, height, group=<span class="number">1</span>)) + geom_line()</span><br></pre></td></tr></table></figure><p>群组几何对象还要考虑的是如何将个体的图形属性映射到整体的图形属性。线条和路径遵循差一原则：观测点比线段数目多一，第一条线段将使用第一条观测的图形属性，第二条使用第一条的，最后一条观测的图形属性不会被用到。</p><h3 id="几何对象"><a href="#几何对象" class="headerlink" title="几何对象"></a>几何对象</h3><p>geom，几何对象执行着图层的实际渲染，控制着生成的图像类型。每个几何对象都有一个默认的统计变换，且每个统计变换都有一个默认的几何对象。</p><table><thead><tr><th>几何对象</th><th>描述</th><th>默认统计变换</th><th>图形属性</th></tr></thead><thead></thead><tbody><tr><td>abline</td><td>线,由斜率和截距决定</td><td>abline</td><td>colour,linetype,size</td></tr><tr><td>area</td><td>面积图</td><td>identity</td><td>colour,fill,linetype,size,x,y</td></tr><tr><td>bar</td><td>条形图, 以x轴为底的矩形</td><td>bin</td><td>colour,fill,linetype,size,weight,x</td></tr><tr><td>bin2d</td><td>2维热图</td><td>bin2d</td><td>colour,fill,linetype,size,weight,xmax,xmin,ymax,ymin</td></tr><tr><td>blank</td><td>空白,什么也不画</td><td>identity</td><td></td></tr><tr><td>boxplot</td><td>箱线图</td><td>boxplot</td><td>colour,fill,lower,middle,size,upper,weight,x,ymax,ymin</td></tr><tr><td>contour</td><td>等高线图</td><td>contour</td><td>colour,linetype,size,weight,x,y</td></tr><tr><td>crossbar</td><td>带有水平中心线的盒子图</td><td>identity</td><td>colour,fill,linetype,size,x,y,ymax,ymin</td></tr><tr><td>density</td><td>光滑密度曲线图</td><td>density</td><td>colour,fill,linetype,size,weight,x,y</td></tr><tr><td>density2d</td><td>二维密度等高线图</td><td>density2d</td><td>colour,linetype,size,weight,x,y</td></tr><tr><td>dotplot</td><td>点直方图,用点表示观测值的个数</td><td>bindot</td><td>colour, fill, x, y</td></tr><tr><td>errorbar</td><td>误差棒</td><td>identity</td><td>colour,linetype,size,width,x,ymax,ymin</td></tr><tr><td>errorbarh</td><td>水平的误差行</td><td>identity</td><td>colour,linetype,size,width,x,ymax,ymin</td></tr><tr><td>freqpoly</td><td>频率多边形图</td><td>bin</td><td>colour,linetype,size</td></tr><tr><td>hex</td><td>用六边形表示的二维热图</td><td>binhex</td><td>colour,fill,size,x,y</td></tr><tr><td>histogram</td><td>直方图</td><td>bin</td><td>colour,fill,linetype,size,weight,x</td></tr><tr><td>hline</td><td>水平线</td><td>hline</td><td>colour,linetype,size</td></tr><tr><td>jitter</td><td>给点添加扰动，减轻图形重叠问题</td><td>identity</td><td>colour,fill,shape,size,x,y</td></tr><tr><td>line</td><td>按照x坐标的大小顺序依次连接各个观测值</td><td>identity</td><td>colour,linetype,size,x,y</td></tr><tr><td>linerange</td><td>一条代表一个区间的竖直线</td><td>identity</td><td>colour,linetype,size,x,ymax,ymin</td></tr><tr><td>map</td><td>基准地图里的多边形</td><td>identity</td><td>colour,fill,linetype,size,x,y,map_id</td></tr><tr><td>path</td><td>按数据的原始顺序连接各个观测值</td><td>identity</td><td>colour,linetype,size,x,y</td></tr><tr><td>point</td><td>点,用来绘制散点图</td><td>identity</td><td>colour,shape,fill,size,x,y</td></tr><tr><td>pointrange</td><td>用一条中间带点的竖直线代表一个区间</td><td>identity</td><td>colour,fill,linetype,shape,size,x,y,ymax,ymin</td></tr><tr><td>polygon</td><td>多边形,相当于一个有填充的路径</td><td>identity</td><td>colour,fill,linetype,size,x,y</td></tr><tr><td>quantile</td><td>添加分位数回归线</td><td>quantile</td><td>colour,linetype,size,weight,x,y</td></tr><tr><td>raster</td><td>高效的矩形瓦片图</td><td>identity</td><td>colour,fill,linetype,size,x,y</td></tr><tr><td>rect</td><td>2维的矩形图</td><td>identity</td><td>colour,fill,linetype,size,xmax,xmin,ymax,ymin</td></tr><tr><td>ribbon</td><td>色带图,连续的x值所对应的y的范围</td><td>identity</td><td>colour,fill,linetype,size,x,ymax,ymin</td></tr><tr><td>rug</td><td>边际地毯图</td><td>identity</td><td>colour,linetype,size</td></tr><tr><td>segment</td><td>添加线段或箭头</td><td>identity</td><td>colour,linetype,size,x,xend,y,yend</td></tr><tr><td>smooth</td><td>添加光滑的条件均值线</td><td>smooth</td><td>alpha,colour,fill,linetype,size,weight,x,y</td></tr><tr><td>step</td><td>以阶梯形式连接各个观测值</td><td>identity</td><td>colour,linetype,size,x,y</td></tr><tr><td>text</td><td>文本注释</td><td>identity</td><td>angle,colour, hjust,label,size, vjust,x,y</td></tr><tr><td>tile</td><td>瓦片图</td><td>identity</td><td>colour,fill,linetype,size,x,y</td></tr><tr><td>violin</td><td>小提琴图</td><td>yidentity</td><td>weight,colour,fill,size,linetype,x,y</td></tr><tr><td>vline</td><td>竖直线</td><td>vline</td><td>colour,linetype,size</td></tr></tbody></table><h3 id="统计变换"><a href="#统计变换" class="headerlink" title="统计变换"></a>统计变换</h3><p>stat，对数据进行统计变换，通常是对数据信息进行汇总。一个统计变换必须是一个位置尺度不变量，f(x+a)=f(x)+a &amp;&amp; f(b*x)=b*f(x).统计变量通常会向原数据集中插入新的变量,你可以使用..xxx..的方式直接调用这些变量.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ggplot(diamonds, aes(carat)) + geom_histogram(aes(y=..density..), binwidth=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p><img src="./stat_in_ggplot.png" alt="stats in ggplot"></p><h3 id="位置调整"><a href="#位置调整" class="headerlink" title="位置调整"></a>位置调整</h3><table><thead><tr><th>位置调整参数</th><th>描述</th></tr></thead><tbody><tr><td>dodge</td><td>避免重叠，并排放置</td></tr><tr><td>fill</td><td>堆叠图形元素并将高度标准化为1</td></tr><tr><td>identity</td><td>不做任何调整</td></tr><tr><td>jitter</td><td>添加扰动避免重合</td></tr><tr><td>stack</td><td>把图形元素堆叠起来</td></tr></tbody></table><h3 id="标度"><a href="#标度" class="headerlink" title="标度"></a>标度</h3><p>标度（scale）控制着数据到图形属性的映射，每一种标度都是从数据空间的某个区域（标度定义域）到图形属性空间的某个区域（标度值域）的一个函数.标度的执行过程分为3步，变换、训练和映射。变换是对数据进行汇总（统计变换），训练基于变换后的数据得到标度的定义域，最后映射到图形上去。使用时通过scale_aesType_scaleType来实现改变标度.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">p = qplot(sleep_total, sleep_cycle, data=msleep, colour=vore)</span><br><span class="line">p +scale_colour_hue(&apos;what does it eat?&apos;,</span><br><span class="line">breaks=c(&apos;herbi&apos;, &apos;carni&apos;, &apos;omni&apos;, NA),</span><br><span class="line">labels=c(&apos;plants&apos;, &apos;meants&apos;, &apos;both&apos;, &apos;dont know&apos;))</span><br><span class="line">p + scale_colour_brewer(palette=&apos;Set1&apos;)</span><br></pre></td></tr></table></figure></p><h4 id="标度分类"><a href="#标度分类" class="headerlink" title="标度分类"></a>标度分类</h4><p>标度可以粗略分为4类：位置标度、颜色标度、手动离散型标度和同一型标度。</p><ul><li>位置标度：连续型、离散型、日期-时间型变量的映射到绘图区域，构造坐标轴  </li><li>颜色标度：连续型、离散型变量映射到颜色  </li><li>手动标度：离散型变量映射到我们选择的符号大小、线条类型、形状或颜色，创建对应图例  </li><li>同一型标度：直接用变量值进行绘制图形属性，不执行映射。如颜色变量值  </li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># name: 使用xlab(name),ylab(name),labs()这三个辅助函数进行设置</span></span><br><span class="line">p + xlab(<span class="string">'City mpg'</span>)</span><br><span class="line">p + labs(x=<span class="string">'City mpg'</span>, y=<span class="string">'Highway'</span>, colour=<span class="string">'Displacement'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># limits: 固定标度的定义域, 可以移除不想在图形上展示的数据/保持不同范围数据的范围一致</span></span><br><span class="line"><span class="comment"># breaks&amp;labels: 控制坐标轴显示的断点和在该断点上的标签，二者相匹配</span></span><br><span class="line">p + scale_x_continuous(breaks=c(<span class="number">5.5</span>, <span class="number">6.5</span>))<span class="comment"># 坐标轴在5.5、6.5处进行断点</span></span><br><span class="line">p + scale_x_continuous(limits=c(<span class="number">5.5</span>, <span class="number">6.5</span>))<span class="comment"># 整个图x轴的范围是5.5-6.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># formatter：未指定标签时，在断点处调用formatter来生成格式化的标签。可用的标签刷为：</span></span><br><span class="line"><span class="comment"># 对于连续型：comma, percent, dollar, scientific</span></span><br><span class="line"><span class="comment"># 对于离散型标度：abbreviate</span></span><br></pre></td></tr></table></figure><h4 id="位置标度"><a href="#位置标度" class="headerlink" title="位置标度"></a>位置标度</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">p + scale_x_log10() + scale_y_log10()</span><br><span class="line">p + scale_x_date(</span><br><span class="line">limits=as.Date(c(<span class="string">'2004-01-01'</span>, <span class="string">'2005-01-01'</span>)),</span><br><span class="line">labels=date_format(<span class="string">'%Y-%m-%d'</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="颜色标度"><a href="#颜色标度" class="headerlink" title="颜色标度"></a>颜色标度</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 连续型</span></span><br><span class="line">p + scale_fill_gradient(limits=c(<span class="number">0</span>,<span class="number">0.04</span>))</span><br><span class="line">p + scale_fill_gradient(limits=c(<span class="number">0</span>,<span class="number">0.04</span>), low=<span class="string">'white'</span>, high=<span class="string">'black'</span>)<span class="comment"># 双色标度</span></span><br><span class="line">p + scale_fill_gradient2(limits=c(-<span class="number">0.04</span>,<span class="number">0.04</span>), midpoint=<span class="number">0.02</span>)<span class="comment"># 三色标度, gradientn是多色标度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 离散型</span></span><br><span class="line">p + scale_fill_brewer(palette=<span class="string">'Set2'</span>)</span><br><span class="line">p + scale_colour_brewer(palette=<span class="string">'Pastel1'</span>)</span><br></pre></td></tr></table></figure><h4 id="手动离散标度"><a href="#手动离散标度" class="headerlink" title="手动离散标度"></a>手动离散标度</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 离散型标度</span></span><br><span class="line">p + scale_linetype()</span><br><span class="line">p + scale_size_discrete()</span><br><span class="line">p + scale_shape()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果定制这些离散型标度,则手动创建</span></span><br><span class="line">p + scale_colour_manual(values=c(<span class="string">'red'</span>,<span class="string">'orange'</span>, <span class="string">'yellow'</span>, <span class="string">'green'</span>, <span class="string">'blue'</span>))</span><br><span class="line">p + scale_shape_manual(values=c(<span class="number">1</span>,<span class="number">2</span>,<span class="number">6</span>,<span class="number">0</span>,<span class="number">23</span>))</span><br><span class="line"><span class="comment"># 实际应用</span></span><br><span class="line">ggplot(huron, aes(year)) + </span><br><span class="line">geom_line(aes(y=level-<span class="number">5</span>, colour=<span class="string">'below'</span>)) +</span><br><span class="line">geom_line(aes(y=level+<span class="number">5</span>, colour=<span class="string">'above'</span>)) +</span><br><span class="line">scale_colour_manual(<span class="string">'Direction'</span>, values=c(<span class="string">'below'</span>=<span class="string">'blue'</span>, <span class="string">'above'</span>=<span class="string">'red'</span>))</span><br></pre></td></tr></table></figure><h4 id="同一型标度"><a href="#同一型标度" class="headerlink" title="同一型标度"></a>同一型标度</h4><p>当你的数据能被R中的绘图函数理解（数据空间和图形属性空间相同时），可以使用同一型标度。</p><h2 id="常见图表代码"><a href="#常见图表代码" class="headerlink" title="常见图表代码"></a>常见图表代码</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">attach</span>(msleep)</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mdata = msleep</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">festival.data = read.table(<span class="string">'DownloadFestival.dat'</span>, sep=<span class="string">'\t'</span>, header=<span class="literal">T</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## Warning in file(file, &quot;rt&quot;): cannot open file &apos;DownloadFestival.dat&apos;: No</span><br><span class="line">## such file or directory</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head(mdata)</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head(festival.data)</span><br></pre></td></tr></table></figure><h3 id="常见几何对象及参数"><a href="#常见几何对象及参数" class="headerlink" title="常见几何对象及参数"></a>常见几何对象及参数</h3><ul><li>geom_bar(x,color,size,fill,linetype,alpha): 创建代表不同统计性质的条形图图层</li><li>geom_point(x,y,shape,color,size,fill,alpha): 创建数据点图层</li><li>geom_line(x,y,color,size,linetype,alpha): 创建直线图层</li><li>geom_smooth(x,y,color,size,linetype,alpha): 创建平滑曲线图层(类似于回归曲线/点连线,但是更为平滑的曲线)</li><li>geom_histogram(x,color,size,fill,linetype,alpha): 创建柱状图图层</li><li>geom_boxplot(x,color,siz,fill,alpha): 创建box-whisker图图层</li><li>geom_text(x,y,color,size,angle,hjust,vjust,alpha): 创建文本图层</li><li>geom_errorbar(x,ymin,ymax,color,linetype,width,alpha): 创建误差线图层</li><li>geom_hline(yintercept)/vline(xintercept,color,size,linetype,alpha): 创建水平线或垂直线图层</li></ul><h3 id="点图"><a href="#点图" class="headerlink" title="点图"></a>点图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    scatterplot = ggplot(data = mdata, aes(x=bodywt, y=sleep_total)) + geom_point()</span><br><span class="line">    scatterplot</span><br><span class="line">    <span class="comment"># 添加颜色</span></span><br><span class="line">    scatterplot = ggplot(data = mdata, aes(x=bodywt, y=sleep_total, col=vore)) + geom_point()</span><br><span class="line">    scatterplot</span><br><span class="line">    <span class="comment"># 数据变换</span></span><br><span class="line">    scatterplot = ggplot(data = mdata, aes(x=log(bodywt), y=sleep_total, col=vore)) + geom_point()</span><br><span class="line">    scatterplot</span><br><span class="line">    <span class="comment"># 改变各种外观</span></span><br><span class="line">    scatterplot = scatterplot + geom_point(size=<span class="number">5</span>) + </span><br><span class="line">                                xlab(<span class="string">'Log Body Weight'</span>) + </span><br><span class="line">                                ylab(<span class="string">'Total Hours Sleep'</span>) +</span><br><span class="line">                                ggtitle(<span class="string">'Some Sleep Data'</span>)</span><br><span class="line">    <span class="comment"># 修改x轴刻度线，title位置</span></span><br><span class="line">    scatterplot = scatterplot + scale_color_brewer(palette = <span class="string">'Set2'</span>)</span><br><span class="line">    scatterplot = scatterplot + theme(plot.title=element_text(vjust=+<span class="number">2</span>))+scale_x_continuous(breaks=-<span class="number">5</span>:<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># 调整背景颜色</span></span><br><span class="line">    scatterplot = scatterplot + theme_set(theme_bw(base_size=<span class="number">18</span>))</span><br><span class="line">    scatterplot</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="带状点图"><a href="#带状点图" class="headerlink" title="带状点图"></a>带状点图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    my.stripchart = ggplot(data=mdata, aes(vore, sleep_total)) + geom_point()</span><br><span class="line">    <span class="comment"># 改变大小，位置(左右偏移一些)</span></span><br><span class="line">    my.stripchart = ggplot(data=mdata, aes(vore, sleep_total)) + geom_point(size=<span class="number">5</span>, position=<span class="string">'jitter'</span>)</span><br><span class="line">    <span class="comment"># 通过引入jitter图层来改变位置,默认用于point，所以不用在geom_point中指定</span></span><br><span class="line">    my.stripchart = ggplot(data=mdata, aes(vore, sleep_total, col=vore)) +</span><br><span class="line">                    geom_jitter(position=position_jitter(width = <span class="number">0.2</span>), size=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 添加误差线</span></span><br><span class="line">    my.stripchart = my.stripchart + </span><br><span class="line">                    ylab(<span class="string">'Total Hours Sleep'</span>) + xlab(<span class="string">'Trophic Level'</span>) + </span><br><span class="line">                    stat_summary(fun.data = mdata, geom = <span class="string">"errorbar"</span>, width = <span class="number">.5</span>) +</span><br><span class="line">                    stat_summary(geom = <span class="string">"errorbar"</span>, fun.y = mean, aes(ymin = ..y.., ymax = ..y..))</span><br><span class="line">    <span class="comment"># 添加标题，去掉NA，调整y轴</span></span><br><span class="line">    my.stripchart = my.stripchart +</span><br><span class="line">                    scale_x_discrete(limits=c(<span class="string">'carni'</span>, <span class="string">'herbi'</span>, <span class="string">'insecti'</span>, <span class="string">'omni'</span>)) +</span><br><span class="line">                    ggtitle(<span class="string">'Some Sleep Data'</span>) +</span><br><span class="line">                    theme(plot.title=element_text(vjust = +<span class="number">2</span>)) +</span><br><span class="line">                    scale_y_continuous(breaks=seq(<span class="number">0</span>,<span class="number">20</span>,<span class="number">2</span>))</span><br><span class="line">    my.stripchart</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="柱状图"><a href="#柱状图" class="headerlink" title="柱状图"></a>柱状图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    my.hist = ggplot(data=festival.data, aes(x=day1)) + geom_histogram()</span><br><span class="line">    <span class="comment"># 上点颜色咯</span></span><br><span class="line">    my.hist = ggplot(data=festival.data, aes(x=day1)) + </span><br><span class="line">                geom_histogram(binwidth=<span class="number">0.3</span>, color=<span class="string">'black'</span>, fill=<span class="string">'yellow'</span>) +</span><br><span class="line">                labs(x=<span class="string">'Score'</span>, y=<span class="string">'Counts'</span>) + ggtitle(<span class="string">'Hygiene at Day 1'</span>)</span><br><span class="line">    my.hist</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 构造一下数据</span></span><br><span class="line">    festival.data.stack = melt(festival.data, id=c(<span class="string">'ticknumb'</span>, <span class="string">'gender'</span>))</span><br><span class="line">    colnames(festival.data.stack)[<span class="number">3</span>:<span class="number">4</span>]&lt;-c(<span class="string">'day'</span>,<span class="string">'score'</span>)</span><br><span class="line">    head(festival.data.stack)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 运用facet进行分组,有两种方式 facet_grid(), facet_wrap()</span></span><br><span class="line">    my.hist.day3 = ggplot(data=festival.data.stack,aes(score)) + </span><br><span class="line">                geom_histogram(binwidth=<span class="number">0.3</span>, color=<span class="string">'black'</span>, fill=<span class="string">'yellow'</span>) +</span><br><span class="line">                labs(x=<span class="string">'Score'</span>, y=<span class="string">'Counts'</span>) + ggtitle(<span class="string">'Hygiene at Day 1'</span>) +</span><br><span class="line">                facet_grid(gender~day)</span><br><span class="line">    my.hist.day3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="画个stripchart"><a href="#画个stripchart" class="headerlink" title="画个stripchart;"></a>画个stripchart;</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="comment"># color用于分亚组，gender用于分大组；所以color分组的话与x是一致的分组</span></span><br><span class="line">    <span class="comment"># facet_gripd用于分大组</span></span><br><span class="line">    my.stripchart.day3 = ggplot(data=na.omit(festival.data.stack), aes(day,score, color=day)) +</span><br><span class="line">                geom_point(position=<span class="string">'jitter'</span>) + facet_grid(~gender)</span><br><span class="line">    my.stripchart.day3 = my.stripchart.day3 + </span><br><span class="line">                stat_summary(fun.data = na.omit(festival.data.stack), geom = <span class="string">"errorbar"</span>, width = <span class="number">.5</span>) +</span><br><span class="line">                stat_summary(geom = <span class="string">"errorbar"</span>, fun.y = mean, aes(ymin = ..y.., ymax = ..y..))</span><br><span class="line"><span class="comment"># 带箱图的stripchart</span></span><br><span class="line">    my.stripchart.day3 = ggplot(data=na.omit(festival.data.stack), aes(day,score, color=day)) +</span><br><span class="line">                geom_point(position=<span class="string">'jitter'</span>) + facet_grid(~gender) +</span><br><span class="line">                scale_colour_manual(values=c(<span class="string">"darkorange"</span>, <span class="string">"darkorchid4"</span>,<span class="string">'blue'</span>)) +</span><br><span class="line">                geom_boxplot(alpha=<span class="number">0</span>, colour=<span class="string">"black"</span>)</span><br><span class="line">    my.stripchart.day3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="箱图"><a href="#箱图" class="headerlink" title="箱图"></a>箱图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    my.boxplot = ggplot(data = festival.data.stack, aes(gender,score, fill=gender)) + geom_boxplot() + facet_grid(~day)</span><br><span class="line">    <span class="comment"># scale_fill_manual要配合fill=gender来使用</span></span><br><span class="line">    my.boxplot = my.boxplot + scale_fill_manual(values=c(<span class="string">'orange'</span>, <span class="string">'purple'</span>)) + stat_boxplot(geom=<span class="string">'errorbar'</span>)</span><br><span class="line">    <span class="comment"># 改变x-轴标签顺序</span></span><br><span class="line">    my.boxplot = my.boxplot + scale_x_discrete(limits=c(<span class="string">'Male'</span>, <span class="string">'Female'</span>))</span><br><span class="line">    my.boxplot    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="小提琴图"><a href="#小提琴图" class="headerlink" title="小提琴图"></a>小提琴图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    my.violinplot = ggplot(festival.data.stack, aes(gender, score, fill=gender)) + </span><br><span class="line">                    geom_violin(trim=<span class="literal">FALSE</span>) +</span><br><span class="line">                    facet_grid(~day) + </span><br><span class="line">                    stat_summary(fun.data = festival.data.stack, geom = <span class="string">"errorbar"</span>, width = <span class="number">.5</span>) +</span><br><span class="line">                    stat_summary(geom = <span class="string">"errorbar"</span>, fun.y = mean, aes(ymin = ..y.., ymax = ..y..)) +</span><br><span class="line">                    scale_fill_manual(values=c(<span class="string">'orange'</span>, <span class="string">'yellow'</span>))</span><br><span class="line">    my.violinplot</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="条形图"><a href="#条形图" class="headerlink" title="条形图"></a>条形图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">score.sem = data.frame(gender=rep(c(<span class="string">'Female'</span>, <span class="string">'Male'</span>), each=<span class="number">3</span>),</span><br><span class="line">                       day=rep(c(<span class="string">'day1'</span>, <span class="string">'day2'</span>, <span class="string">'day3'</span>), <span class="number">2</span>),</span><br><span class="line">                       mean=c(<span class="number">1.88</span>, <span class="number">1.08</span>, <span class="number">1.10</span>, <span class="number">1.60</span>, <span class="number">0.77</span>, <span class="number">0.83</span>),</span><br><span class="line">                       sem=c(<span class="number">0.032</span>, <span class="number">0.061</span>, <span class="number">0.099</span>, <span class="number">0.036</span>, <span class="number">0.058</span>, <span class="number">0.073</span>))</span><br><span class="line">head(score.sem)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">##   gender  day mean   sem</span><br><span class="line">## 1 Female day1 1.88 0.032</span><br><span class="line">## 2 Female day2 1.08 0.061</span><br><span class="line">## 3 Female day3 1.10 0.099</span><br><span class="line">## 4   Male day1 1.60 0.036</span><br><span class="line">## 5   Male day2 0.77 0.058</span><br><span class="line">## 6   Male day3 0.83 0.073</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="comment"># geom_errorbar要和stat='identity'一起使用,不然无法知道该进行何类统计</span></span><br><span class="line">    my.barplot = ggplot(data = score.sem, aes(day, mean, fill=gender)) +</span><br><span class="line">                 geom_bar(stat=<span class="string">'identity'</span>, position=<span class="string">'dodge'</span>, color=<span class="string">'black'</span>, size=<span class="number">1</span>) +</span><br><span class="line">                 geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem), position=position_dodge(width=<span class="number">0.8</span>), size=<span class="number">1</span>, width=<span class="number">.5</span>) +</span><br><span class="line">                 ylab(<span class="string">'Mean Scores'</span>) + ggtitle(<span class="string">'Levels of hygiene over 3 days of concert'</span>) +</span><br><span class="line">                <span class="comment"># 去掉x轴标签</span></span><br><span class="line">                 theme(axis.title.x=element_blank()) + </span><br><span class="line">                 theme(plot.title=element_text(vjust=+<span class="number">2</span>))</span><br><span class="line">    my.barplot</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="堆积条形图-百分比堆积图"><a href="#堆积条形图-百分比堆积图" class="headerlink" title="堆积条形图/百分比堆积图"></a>堆积条形图/百分比堆积图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Changing = read.csv(<span class="string">'Changing.csv'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## Warning in file(file, &quot;rt&quot;): cannot open file &apos;Changing.csv&apos;: No such file</span><br><span class="line">## or directory</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head(Changing)</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    my.stackbarchart = ggplot(Changing, aes(Type.of.Behaviour, Sample.Size, fill=Stage.of.Change)) + </span><br><span class="line">                geom_bar(stat=<span class="string">'identity'</span>) +</span><br><span class="line">                coord_flip() <span class="comment"># 水平和垂直堆积变换</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 由于各个堆积图内部的排序都不一致，把stage.of.change改为因子就可以</span></span><br><span class="line">    Changing$Stage.of.Change = factor(Changing$Stage.of.Change, </span><br><span class="line">                                      levels=c(<span class="string">"Precontemplation"</span>, <span class="string">"Contemplation"</span>, <span class="string">"Preparation"</span>, <span class="string">"Action"</span>,</span><br><span class="line">                                                                         <span class="string">"Maintenance"</span>))</span><br><span class="line">    my.stackbarchart = ggplot(Changing, aes(Type.of.Behaviour, Sample.Size, fill=factor(Stage.of.Change))) + </span><br><span class="line">        geom_bar(stat=<span class="string">'identity'</span>) +</span><br><span class="line">        coord_flip() + </span><br><span class="line">        scale_fill_brewer(palette=<span class="number">3</span>) + </span><br><span class="line">        labs(title=<span class="string">'Stages of Each of the 12 Problems Behaviours'</span>,</span><br><span class="line">             y=<span class="string">'Type of Behaviour'</span>,</span><br><span class="line">             x=<span class="string">'Sample Size'</span>,</span><br><span class="line">             fill=<span class="string">'Stage of Change'</span>)</span><br><span class="line">    my.stackbarchart</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 画成百分比堆积图</span></span><br><span class="line">    contingency.table = xtabs(Sample.Size~Type.of.Behaviour+Stage.of.Change, Changing)</span><br><span class="line">    contingency.tab100 = prop.table(contingency.table, <span class="number">1</span>)</span><br><span class="line">    contingency.tab100 = contingency.tab100*<span class="number">100</span></span><br><span class="line">    contingency.percent = as.data.frame(contingency.tab100)</span><br><span class="line">    contingency.percent$Stage.of.Change = factor(contingency.percent$Stage.of.Change, </span><br><span class="line">                                                 levels=c(<span class="string">"Precontemplation"</span>, <span class="string">"Contemplation"</span>, <span class="string">"Preparation"</span>, <span class="string">"Action"</span>,</span><br><span class="line">                                                          <span class="string">"Maintenance"</span>))</span><br><span class="line">    my.stackbarchart.percent = ggplot(contingency.percent, aes(Type.of.Behaviour, Freq, fill=factor(Stage.of.Change))) + </span><br><span class="line">        geom_bar(stat=<span class="string">'identity'</span>) +</span><br><span class="line">        coord_flip() + </span><br><span class="line">        scale_fill_brewer(palette=<span class="string">'RdYlGn'</span>) + </span><br><span class="line">        labs(title=<span class="string">'Freq of Each of the 12 Problems Behaviours'</span>,</span><br><span class="line">             y=<span class="string">'Freq'</span>,</span><br><span class="line">             x=<span class="string">'Type of Behaviour'</span>,</span><br><span class="line">             fill=<span class="string">'Stage of Change'</span>)</span><br><span class="line">    </span><br><span class="line">    my.stackbarchart.percent</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="线图"><a href="#线图" class="headerlink" title="线图"></a>线图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    my.linegraph = ggplot(data = score.sem, aes(day, mean, group=gender, color=gender)) + </span><br><span class="line">                    geom_line(size=<span class="number">1.5</span>) + geom_point() + </span><br><span class="line">                    geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem))</span><br><span class="line">    </span><br><span class="line">    my.linegraph = ggplot(data = score.sem, aes(day, mean, group=gender, color=gender)) + </span><br><span class="line">        geom_line(size=<span class="number">1.5</span>) + geom_point(size=<span class="number">5</span>) + </span><br><span class="line">        geom_errorbar(aes(ymin=mean-sem, ymax=mean+sem), width=<span class="number">.2</span>, size=<span class="number">1.5</span>) +</span><br><span class="line">        ylab(<span class="string">'Mean Scores'</span>) + ggtitle(<span class="string">'Levels of hygiene over 3 days concert'</span>) + </span><br><span class="line">        theme(axis.title.x = element_blank()) + </span><br><span class="line">        scale_color_manual(values=c(<span class="string">'lightblue'</span>, <span class="string">'steelblue'</span>)) + </span><br><span class="line">        theme(legend.justification = c(<span class="number">1</span>,<span class="number">1</span>), legend.position = c(<span class="number">0.95</span>,<span class="number">0.95</span>)) + </span><br><span class="line">        theme(legend.text = element_text(size=<span class="number">16</span>, face=<span class="string">'bold'</span>)) + </span><br><span class="line">        theme(legend.title=element_blank(), plot.title=element_text(vjust=+<span class="number">2</span>))</span><br><span class="line">    my.linegraph</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《R 数据科学》</li><li><a href="https://ggplot2.tidyverse.org/reference/" target="_blank" rel="noopener">ggplot reference</a></li><li>《ggplot2：数据分析与图形艺术》</li><li>Tutorials from Anne Segonds-Pichon in Babraham Bioinformatics (links not found)</li></ul>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 可视化 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>数据处理 dplyr</title>
      <link href="/2018/11/02/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-dplyr/"/>
      <url>/2018/11/02/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86-dplyr/</url>
      
        <content type="html"><![CDATA[<p>以前就看过一些 dplyr 的使用，记得当初说是和 tplyr，reshape2 并称 R 数据处理三剑客，想想和 web 开发的 HTML，JavaScript，CSS 的三剑客有些类似。这两天又在《R 数据科学》看到 dplyr 的使用，还挺详细的。现在把书里的相关用法记录在此，刚好也把书上的习题在这里做个回答，以加强使用。</p><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>dplyr 的这些函数的第一个参数是一个数据框，随后的参数是对数框的操作，使用列名（不带引号）引用列，输出一个新的数据框，不会更改源数据。这里使用的数据是 nycflights13 包里的 flights，不是 tidyverse 里的，需要我们通过 <em>install.packages</em> 安装。具体的列名代表了什么意思，可以通过 <em>?flights</em> 查看。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">suppressPackageStartupMessages(<span class="keyword">library</span>(nycflights13))</span><br><span class="line">suppressPackageStartupMessages(<span class="keyword">library</span>(tidyverse))</span><br><span class="line">suppressPackageStartupMessages(<span class="keyword">library</span>(dplyr))</span><br><span class="line">flights[<span class="number">1</span>:<span class="number">4</span>,]</span><br></pre></td></tr></table></figure><h2 id="使用-filter-筛选行"><a href="#使用-filter-筛选行" class="headerlink" title="使用 filter 筛选行"></a>使用 filter 筛选行</h2><p>我们使用 filter 对数据框的行进行筛选，对于数据框列的操作有以下几种。</p><ul><li>比较运算：&gt;, &gt;=, &lt;=, &lt;, !=, ==（比较浮点数使用 near 函数）</li><li>逻辑运算：&amp;, |, !, xor(x,y), isTRUE(x), isFALSE(x), %in%</li><li>缺失值：is.na(x)</li></ul><p>问题是我们要找到“在夏季 7、8、9 月出发的航班”和“到达时间延误 2 小时，但出发时间没有延误的航班”。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 问题 1，有多种解法, 看下方</span></span><br><span class="line">filter(flights, month == <span class="number">7</span> | month == <span class="number">8</span> | month == <span class="number">9</span>)</span><br><span class="line">filter(flights, month %<span class="keyword">in</span>% c(<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>))</span><br><span class="line">filter(flights, between(momtn, <span class="number">7</span>, <span class="number">9</span>))</span><br><span class="line"><span class="comment"># 问题 2,</span></span><br><span class="line">filter(flights, arr_delay == <span class="number">120</span> &amp; dep_delay == <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="使用-arrange-排列行"><a href="#使用-arrange-排列行" class="headerlink" title="使用 arrange 排列行"></a>使用 arrange 排列行</h2><p>arrange 的作用是改变行的顺序，如果有多个参数，那么就按输入参数的顺序对数据框依次进行排序，注意排序的效果是嵌套的。如果要使用降序，可以使用 <em>des()</em> 函数。一般来说，NA 值总是排在最后的。</p><p>这里的问题是“如何将缺失值排序在前面”和“在所有航班中，哪个航班的飞行时间最长，哪个最短”。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 问题 1，比如把到达时间的 NA 排在前面</span></span><br><span class="line">arrange(flights, desc(is.na(flights$arr_time)))</span><br><span class="line"><span class="comment"># 问题 2,</span></span><br><span class="line">arrange(flights, air_time)</span><br><span class="line">arrange(flights, desc(air_time))</span><br></pre></td></tr></table></figure><h2 id="使用-select-选择列"><a href="#使用-select-选择列" class="headerlink" title="使用 select 选择列"></a>使用 select 选择列</h2><p>select 选择列的时候，可以直接指定待选列的列名，也可以使用切片语法（闭区间），和排除语法“-”。此外，还有以下一些辅助函数。对于 everything，通常在对待选列重排到列首有奇效。在指定一个列名多次时，只会选取一次该列，一是因为列名不允许重复，二是我们从 everything 提取目标列到前面也能猜测到。</p><ul><li>starts_with(“abc”), ends_with(“abc”)</li><li>contains(“abc”)：大小写不敏感的</li><li>matches(“(.)\1”)</li><li>num_range(“x”, 1:3): 获得 x1，x2，x3，两个参数不能同时为多个</li><li>one_of(c(“abc”, “def”))</li><li>everything(): 全选</li></ul><p>在 dplyr 中有个与 select 相近的函数 rename，他可以对列进行重命名。</p><p>这里的问题是“使用尽可能多的方式来选择 dep_time, dep_delay, arr_time, arr_delay ”。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select(flights, starts_with(<span class="string">"dep"</span>), starts_with(<span class="string">"arr"</span>))</span><br><span class="line">select(flights, matches(<span class="string">"^(dep|arr)"</span>))</span><br><span class="line">select(flights, num_range(<span class="string">"dep"</span>, c(<span class="string">"_time"</span>, <span class="string">"_delay"</span>)), num_range(<span class="string">"arr"</span>, c(<span class="string">"_time"</span>, <span class="string">"_delay"</span>)))</span><br><span class="line">select(flights, num_range(c(<span class="string">"dep"</span>, <span class="string">"arr"</span>), <span class="string">"_delay"</span>), num_range(c(<span class="string">"dep"</span>, <span class="string">"arr"</span>), <span class="string">"_time"</span>))</span><br><span class="line">select(flights, one_of(c(<span class="string">"dep_time"</span>, <span class="string">"dep_delay"</span>, <span class="string">"arr_time"</span>, <span class="string">"arr_delay"</span>)))</span><br></pre></td></tr></table></figure><h2 id="使用-mutate-添加新列"><a href="#使用-mutate-添加新列" class="headerlink" title="使用 mutate 添加新列"></a>使用 mutate 添加新列</h2><p>mutate 可以对数据框添加新列，但总是放在最后面。新列在添加时就可以使用。如果你只是想保留新列，则可以使用 transmute 代替。与 select 类似，有多种辅助函数来帮助创建新列，这些函数的一个共同点就是输入和输出都是一个向量数据结构，一维的，长度与数据框的行数相同。常见的辅助函数有下面这些。</p><ul><li>运算符：+, -, *, /, ^, %/%, %%</li><li>运算函数: log, commin, cummax, [sum, min, max, lead, lag], 对于摘要性质的，需要与其他函数联用</li><li>逻辑比较：&lt;, &lt;=, &gt;, &gt;=, !=, ==</li><li>排秩：  min_rank, row_number, dense_rank, percent_rank, cume_dist, ntile</li></ul><p>这里的问题是“比较 air_time 和 arr_time - dep_time，你期望看到什么？实际结果是什么？”</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">transmute(flights, air_time = air_time, arr_dep = arr_time - dep_time)</span><br><span class="line"><span class="comment"># 因为 arr_tim 和 dep_time 是以“ HHMM ”的格式录入的，所以应该如下</span></span><br><span class="line">HMM2min = <span class="keyword">function</span>(HMM) &#123;</span><br><span class="line">    H = HMM %/% <span class="number">100</span></span><br><span class="line">    min = HMM %% <span class="number">100</span> + H * <span class="number">60</span></span><br><span class="line">    min</span><br><span class="line">&#125;</span><br><span class="line">transmute(flights, air_time = air_time, arr_dep = HMM2min(arr_time) - HMM2min(dep_time))</span><br></pre></td></tr></table></figure><h2 id="使用-group-by-分组"><a href="#使用-group-by-分组" class="headerlink" title="使用 group_by 分组"></a>使用 group_by 分组</h2><p>group_by 可以根据使用的列名个数对数据框进行逐级分组，得到分组的统计总量。每进行一次摘要统计，就会使用掉一个分组。这里值得注意的是，进行摘要统计的函数必须是分组层级一致的，比如分组求均值和总体求均值结果一致，但是分组求中位数却不是这样。ungroup 函数可以取消分组，回到未分组的数据。单独使用 group_by 函数的情况较少，通常是与 summrise 联用。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">group_by(flights, year, month, day)</span><br></pre></td></tr></table></figure><h2 id="使用-summarise-摘要数据"><a href="#使用-summarise-摘要数据" class="headerlink" title="使用 summarise 摘要数据"></a>使用 summarise 摘要数据</h2><p>summarise 函数可以对数据框进行摘要统计，把数据框整合成一行，它通常是同groupby联合使用，在 dplyr 中最常用的操作就是进行分组摘要。%&gt;% 的引入让分组摘要的流程更加明确、清晰、自然。在进行分组摘要的时候，由于 NA 具有扩撒性，na.rm 要记得指定为真，n() 与 sum(!is_na()) 总是会不一样。常用的摘要函数如下面所示。</p><ul><li>位置度量：mean, median</li><li>分散程度度量：sd, IQR, mad</li><li>秩度量：min, max, quantile(x, 0.25)</li><li>定位度量：first, nth(x, 2), last</li><li>数量度量：n, sum(!is.na(x)), distinct, count</li></ul><p>这里的问题是“每天取消航班的比例与平均延误时间有什么关系”。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义取消航班为 is.na(dep_time) &amp; is.na(dep_delay)</span></span><br><span class="line">filter(flights, is.na(dep_time) &amp; is.na(dep_delay)) %&gt;%</span><br><span class="line">    mutate(flight = flight, mean_time = HMM2min(sched_arr_time) - HMM2min(sched_dep_time)) %&gt;%</span><br><span class="line">    ggplot(mapping = aes(x=flight, y=abs(mean_time))) +</span><br><span class="line">        geom_point() +</span><br><span class="line">        geom_smooth(se=<span class="literal">F</span>)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《R 数据科学》</li><li>vignette(“dplyr”)</li></ul>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 数据处理 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>可变剪切 rMATS和rmats2sashimiplot</title>
      <link href="/2018/10/28/%E5%8F%AF%E5%8F%98%E5%89%AA%E5%88%87-rMATS%E5%92%8Crmats2sashimiplot/"/>
      <url>/2018/10/28/%E5%8F%AF%E5%8F%98%E5%89%AA%E5%88%87-rMATS%E5%92%8Crmats2sashimiplot/</url>
      
        <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code>environment: py2.7.x</code></p><ul><li>rMATs</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># in linux</span><br><span class="line">wget http://rnaseq-mats.sourceforge.net/rMATS.4.0.2.tgz</span><br><span class="line"></span><br><span class="line"># check version to use, in python</span><br><span class="line">import sys</span><br><span class="line">print sys.maxunicode</span><br><span class="line"># 1114111: rMATS-turbo-xxx-UCS4</span><br><span class="line"># 65535: rMATS-turbo-xxx-UCS2</span><br><span class="line"></span><br><span class="line">&quot;path/to/rMATs-turbo-xxx-UCS&#123;x&#125;/rMATS.py&quot;</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li>rmats2sashimiplot</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://files.pythonhosted.org/packages/f7/15/cd6fa8dc70de55be94f4a55edd388e5ba99c77eca8fd73e556e66e9d8110/rmats2sashimiplot-2.0.2.tar.gz</span><br><span class="line">tar -zxvf rmats2sashimiplot-2.0.2.tar.gz &amp; cd rmats2sashimiplot-2.0.2</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><ul><li>rMATs</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># input as fastq, samples in each group list in s1.txt/s2.txt separated with comma</span><br><span class="line">python rmats.py --s1 s1.txt --s2 s2.txt --gtf gtfFile --bi STARindexFolder -od outDir -t readType -readLength readLength [options]*</span><br><span class="line"># input as sorted.bam, samples in each group list in s1.txt/s2.txt separated with comma</span><br><span class="line">python rmats.py --b1 b1.txt --b2 b2.txt --gtf gtfFile --od outDir -t readType --nthread nthread --readLength readLength --tstat tstat [options]*</span><br></pre></td></tr></table></figure><ul><li>rmats2sashimiplot</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># input as sam</span><br><span class="line">$rmats2sashimiplot --s1 s1_rep1.sam[,s1_rep2.sam]* --s2 s2.rep1.sam[,s2.rep2.sam]* -t eventType -e eventsFile --l1 SampleLabel1 --l2 SampleLabel2 --exon_s exonScale --intron_s intronScale -o outDir</span><br><span class="line"></span><br><span class="line"># input as bam</span><br><span class="line">$rmats2sashimiplot --b1 s1_rep1.bam[,s1_rep2.bam]* --b2 s2.rep1.bam[,s2.rep2.bam]* -c coordinate:annotaionFile --l1 SampleLabel1 --l2 SampleLabel2 --exon_s exonScale --intron_s intronScale -o outDir</span><br><span class="line"></span><br><span class="line"># a group file provided</span><br><span class="line">$rmats2sashimiplot --b1 s1_rep1.bam[,s1_rep2.bam]* --b2 s2.rep1.bam[,s2.rep2.bam]* -c coordinate:annotaionFile --l1 SampleLabel1 --l2 SampleLabel2 --exon_s exonScale --intron_s intronScale -o outDir --group-info gf.gf</span><br></pre></td></tr></table></figure><h2 id="rMATS-结果"><a href="#rMATS-结果" class="headerlink" title="rMATS 结果"></a>rMATS 结果</h2><h3 id="识别的剪切事件类型"><a href="#识别的剪切事件类型" class="headerlink" title="识别的剪切事件类型"></a>识别的剪切事件类型</h3><p>rMATS analyzes skipped exon (SE), alternative 5’ splice site (A5SS), alternative 3’ splice site (A3SS), mutually exclusive exons (MXE), and retained intron (RI) events. </p><p><img src="https://s1.ax1x.com/2018/10/28/ic5Jp9.jpg" alt="5种ASE"><br><img src="https://s1.ax1x.com/2018/10/28/ic5BkD.png" alt="5种ASE"></p><h3 id="结果文件释义"><a href="#结果文件释义" class="headerlink" title="结果文件释义"></a>结果文件释义</h3><ul><li>AS_Event.MATS.JC.txt, 只使用 Junction counts (counts of reads that span splicing junctions) 检测到的 AS_Event 结果</li><li>JS.raw.input.AS_Event.txt, 进行 AS_Event.MATS.JC 分析的源数据</li><li>AS_Event.MATS.JCEC.txt, 同时使用 junction counts 和 reads on target 检测到的 AS_Event 结果</li><li>JCEC.raw.input.AS_Event.txt，进行 AS_Event.MATS.JCEC.txt 分析的源数据</li><li>fromGTF.AS_Event.txt, 来源于 GTF 和 RNA 的所有可能可变剪切事件</li></ul><h3 id="结果文件各列释义"><a href="#结果文件各列释义" class="headerlink" title="结果文件各列释义"></a>结果文件各列释义</h3><ul><li>IJC_SAMPLE_*: inclusion junction counts</li><li>SJC_SAMPLE_*: skipping junction counts</li><li>IC_SAMPLE_*: inclusion counts</li><li>SC_SAMPLE_*: skipping counts</li><li>IncFormLen: length of inclusion form, used for normalization</li><li>SkipFormLen: length of skipping form, used for normalization</li><li>IncLevel1: inclusion level for SAMPLE_1 replicates (comma separated) calculated from normalized counts</li><li>IncLevel2: inclusion level for SAMPLE_2 replicates (comma separated) calculated from normalized counts</li><li>IncLevelDifference: average(IncLevel1) - average(IncLevel2)</li><li>P-Value: Significance of splicing difference between two sample groups. (Only available if statistical model is on)</li><li>FDR: False Discovery Rate calculated from p-value. (Only available if statistical model is on)</li><li>upstreamES/upstreamEE: upstreamExonStart, upstreamExonEnd</li><li>downstreamES/downstreamEE: like above</li></ul><p><img src="https://s1.ax1x.com/2018/10/28/ic5am6.png" alt="IC and SC"><br><img src="https://s1.ax1x.com/2018/10/28/ic5t61.png" alt="upstreamES/EE"></p><h3 id="相关计算"><a href="#相关计算" class="headerlink" title="相关计算"></a>相关计算</h3><p><code>IncLevel1 = (IC_SAMPLE_1 / IncFormLen) / (IC_SAMPLE_1 / IncFormLen + SC_SAMPLE_1 / SkipFormLen)</code></p><p><code>IncFormLen = 2 * (Junction_length - read_length + 1)</code></p><p><code>SkipFormLen = Junction_length - read_length + 1</code></p><p><code>Junction_length = 2 * (read_length - anchor), anchor = 8 bp(default)</code></p><h3 id="结果解读："><a href="#结果解读：" class="headerlink" title="结果解读："></a>结果解读：</h3><ol><li>JunctionCountOnly</li></ol><p>在对剪切事件发生的差异分析过程中，rMATs 采用了 2 种定量方式，即 JunctionCountOnly 和 ReadOnTargetAndJunctionCounts. 对于前者，它把那些会全部比对到 alternatively spliced exon(ASE) 的 reads 进行剔除，而后者不会。也就是说，Junction counts 是 reads 覆盖 (span) 到 splicing site 的 reads count，read on target 就是被 JunctionCountOnly 剔除的 reads，也就是 这些 reads 整体只比对到 ASE 区域的某个部分。</p><ol start="2"><li>PSI</li></ol><p>PSI, 全称为 Percent-splice-in，可以针对 isoform，exon，ASE 进行计算。对于 ASE 来说，PSI = splice_in / (splice_in + splice_out), 在 rMATS 里，splice_in 和 splice_out 是支持 splice_in 和 splice_out 发生的 reads 数目，可以同基因表达的 reads count 作类比。</p><h2 id="rmats2sashimiplot"><a href="#rmats2sashimiplot" class="headerlink" title="rmats2sashimiplot"></a>rmats2sashimiplot</h2><h3 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h3><p><img src="https://raw.githubusercontent.com/Xinglab/rmats2sashimiplot/master/img/plotwitheventgf.png" alt="可视化结果"></p><h3 id="结果解读"><a href="#结果解读" class="headerlink" title="结果解读"></a>结果解读</h3><ul><li>Y-轴释义</li></ul><p><img src="https://raw.githubusercontent.com/Xinglab/rmats2sashimiplot/master/img/RPKM.png" alt="Y-轴释义"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="http://rnaseq-mats.sourceforge.net/user_guide.htm" target="_blank" rel="noopener">rMATS</a></li><li><a href="https://github.com/Xinglab/rmats2sashimiplot" target="_blank" rel="noopener">rmats2sashimiplot</a></li><li><a href="https://www.biostars.org/p/256949/" target="_blank" rel="noopener">biostars</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>流程构建 Snakemake使用初步</title>
      <link href="/2018/10/28/%E6%B5%81%E7%A8%8B%E6%9E%84%E5%BB%BA-Snakemake%E4%BD%BF%E7%94%A8%E5%88%9D%E6%AD%A5/"/>
      <url>/2018/10/28/%E6%B5%81%E7%A8%8B%E6%9E%84%E5%BB%BA-Snakemake%E4%BD%BF%E7%94%A8%E5%88%9D%E6%AD%A5/</url>
      
        <content type="html"><![CDATA[<p>在学习生信的过程中，总是听说流程啊，管道啊，pipeline啊，到底这些意味着什么？你能把测序数据从ncbi下载下来，这不叫流程；你可以继续把数据做完质控，然后搞个比对，再做做什么差异分析啊、富集分析啊、各种类型数据的联合分析啊，这也不叫流程，谁知道你中间因为某个包安装用了多久的时间，谁晓得你这个过程是不是 reproducible 的？要是你中间出了问题怎么办，可控性如何？监控性如何？要是这些问题都能解答，我想就应该可以叫做一个流程了吧，流程化、自动化、可控化、高复用化。作为一个新人，要独自解决这些功能还是有些困难，肯定需要“假于物”的，恰好那天看到有个朋友说到用snakemake来些流程，哈哈，这不就有了，下面就说一说我初步学习使用的理解吧。</p><a id="more"></a><h2 id="snakemake-实现流程化"><a href="#snakemake-实现流程化" class="headerlink" title="snakemake 实现流程化"></a>snakemake 实现流程化</h2><p>在构建所谓的生信分析pipeline的时候，首先要实现pipeline的流程化，那么snakemake是怎么实现的呢？那就要说到snakemake 的rule语法了。如下所示。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># in python</span></span><br><span class="line">rule step_name:</span><br><span class="line">input:</span><br><span class="line"><span class="string">"something"</span></span><br><span class="line">output:</span><br><span class="line"><span class="string">"something"</span></span><br><span class="line">shell:</span><br><span class="line"><span class="string">"some commands do with input, result is output"</span></span><br></pre></td></tr></table></figure><p>写好rule后，保存名字为 Snakefile。我们可以使用这样的方式，来构建每一个分析过程，这样做的好处就是直接明了，这一个rule是干什么的，需要什么输入，会产生什么输出，怎么产生都描述完全。我通常把do what作为rule的step_name，这样一来把分析过程先进行步骤分解，写成rule的形式，这就先完成了分析过程的步骤化，然后，因为流程是一个步骤接一个步骤的，有个次序的问题，如何实现？通过input和output来实现，以rule1的output作为rule2的input，这样就可以把步骤串联起来了。对于这个问题，snakemake提供了一个feature，叫做inheritance rule。我们看下面的示例，step_one对测序reads进行比对，得到bam文件，step_two要对bam文件进行统计。对于整个构建过程，我们完全可以采用inheritance rule的方式来进行，这样对于最终结果是怎么来的，可以按图索骥。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">rule mapping:</span><br><span class="line">input: <span class="string">"rawdata.fastq"</span></span><br><span class="line">output: <span class="string">"rawdata.bam"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 做法一</span></span><br><span class="line">rule stats:</span><br><span class="line">input: <span class="string">"rawdata.bam"</span></span><br><span class="line">output: <span class="string">"mapping.stats.txt"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 做法二</span></span><br><span class="line">rule stats:</span><br><span class="line">input: rules.mapping.output</span><br><span class="line">output: <span class="string">"mapping.stats.txt"</span></span><br></pre></td></tr></table></figure><p>除了上述的 rule 形式，snakemake 还提供了一个 rule all 的语法。它是你这个 pipeline 的最终结果集合，对于你需要的结果，你应该全部显式地列在rule all中，它位于所有rule的最开端。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rule all:</span><br><span class="line">input:</span><br><span class="line"><span class="string">"step_1_result"</span>,</span><br><span class="line"><span class="string">"step_2_result"</span>,</span><br><span class="line"><span class="keyword">...</span></span><br></pre></td></tr></table></figure><p>有人要问了，为什么这么干？原因我认为有二，第一脚本文件的解析过程是由前至后、由上至下的。那么 rule all 放在前面，相当于你的pipeline有个概览。其二，正如前面所述，step-by-step的input和output是串联的，但是整个流程的 step-by-step 不是单一的，而是有多个step-by-step，它们是并联的。而不论串联并联，都有个结果，那就是 rule all。结合实际运行我们会发现，snakemake 的运行方式就是按图(rule all)索骥，我（rule all)需要什么结果 (input)，就去找生成这个结果的rule，然后运行这个rule；对于这个rule，重复这个依据 input 寻找和执行上游 rule 的过程，对于这个寻找过程，我们可以使用 -rn 参数打印出来。如果你的文件名字是 “Snakefile”, 后面的 <code>-s Snakefile</code> 可以省略。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">snakemake -rn -s Snakefile</span><br></pre></td></tr></table></figure><h2 id="snakemake-实现自动化"><a href="#snakemake-实现自动化" class="headerlink" title="snakemake 实现自动化"></a>snakemake 实现自动化</h2><p>虽然我尚未正式做过任何项目，但是依据文献提供的原始数据，一个正常的测序项目，样品数目大多数在 10 个及以上。我们不可能把这些样品都一个个写成一个个 rule，就比如比对过程，你执行一次比对命令执行完成一个样品的比对，通常的做法是使用for循环来实现。但这里是 snakemake，它会帮你的，那就是使用通配符 (wildcards)。一个 wildcards 就是一个匹配的文件名的简单正则。对于每个匹配的文件，snakemake 都会以文件作为 input 执行一次 rule， 看下面的示例。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># samples =&gt; A1.fastq A2.fastq, A3.fastq</span></span><br><span class="line">rule mapping:</span><br><span class="line">input:</span><br><span class="line"><span class="string">"&#123;sample&#125;.fastq"</span></span><br><span class="line">output:</span><br><span class="line"><span class="string">"&#123;sample&#125;.bam"</span></span><br><span class="line">shell:</span><br><span class="line"><span class="string">"bwa mem .... &#123;input&#125; -o &#123;output&#125;"</span></span><br></pre></td></tr></table></figure><p>这样，对于每个 sample 都会进行一次比对。这样就毋须我们自己写 for 循环了。有时候，我们有很多样品，但是，我们仅仅想使用其中某几个作为输入，该如何？ snakemake 提供了constraint wildcards，来对 wildcards 匹配的样品进行限制。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># samples =&gt; A1.fastq A2.fastq, A3.fastq, A14.fastq, A15.fastq</span></span><br><span class="line">rule mapping:</span><br><span class="line">input:</span><br><span class="line"><span class="string">"&#123;sample, \w\d&#125;.fastq"</span></span><br><span class="line"><span class="keyword">...</span></span><br></pre></td></tr></table></figure><p>在我们加入“\w\d”这个正则之后，sample将不会匹配 A14.fastq 和 A15.fastq，这是因为 snakemake 在解析的时候，默认会把 “{sample}.fastq” 解析成 “*.fastq”；但是如果我们使用 constraint wildcards的话，那 “{smaple, \w\d}.fastq” 就会被解析成 “\w\d.fastq”, 这就自然不会匹配 A14.fastq 这样的样品了。除了在 rule 中使用 constraint wildcards，你还可以进行全局声明，不过你得先声明后使用，放在所有的 rule 前面。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wildcard_constaints:</span><br><span class="line">    sample = <span class="string">"\w\d"</span></span><br></pre></td></tr></table></figure><p>对于上面的那个比对示例，有同学会问了，你这个看起来只是 single end 的测序结果作为输入，那要是 paired end 的测序结果，该怎么输入呢？欸，这里就有两种方式啦，一种是，我再提供一个咯；另一种就是使用 snakemake 提供的 expand 函数。但是，这里问题就来了。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 普通方式：</span></span><br><span class="line">rule mapping:</span><br><span class="line">input:</span><br><span class="line"><span class="string">"A1_read1.fastq"</span>,</span><br><span class="line"><span class="string">"A1_read2.fastq"</span></span><br><span class="line"><span class="comment"># expand</span></span><br><span class="line">rule mapping:</span><br><span class="line">input:</span><br><span class="line">expand(<span class="string">"A1_&#123;read&#125;.fastq"</span>, read=[<span class="string">"read1"</span>, <span class="string">"read2"</span>])</span><br></pre></td></tr></table></figure><p>普通的expand是不支持 wildcards 的，看它的使用方式就知道了，与 str.format(read=[]) 形式是一致的。但是，如果要使用 wildcards 怎么办呢？我们需要定义一个 helper，以它作为 input, 这个 helper 你可以正常函数定义，也可以使用匿名函数（如果仅使用一次的话）, 需要注意的是，这个 helper 的参数只能有一个，那就是 wildcards。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rule mapping:</span><br><span class="line">input:</span><br><span class="line">lambda wildcards: expand(<span class="string">"&#123;sample&#125;_&#123;read&#125;.fastq"</span>, sample=wildcards.sample, read=[<span class="string">"read1"</span>, <span class="string">"read2"</span>])</span><br></pre></td></tr></table></figure><h2 id="snakemake-实现流程的可控化"><a href="#snakemake-实现流程的可控化" class="headerlink" title="snakemake 实现流程的可控化"></a>snakemake 实现流程的可控化</h2><p>在分析的过程中，分析的步骤辣么多，时间辣么长，如何保证分析过程的正常进行？出现错误如何发现？是不是一步错，步步错，全局失败？是不是只能一水儿的执行下去？问题这么多，snakemake 说看我的。为了实现流程的可控化，snakemake 提供了多个 feature。要控制整个流程，需要控制什么？没错，那就是控制每一个步骤，控制每一个 rule。如何控制？记录运行日志，写配置。尽管 snakemake 自己会生成日志文件，对于每一个 rule，你也可以指定日志生成，这个通过 rule.log 实现。每个 rule 运行命令的控制可以通过 rule.params 来提供命令的参数选项进行控制。下面看示例。</p><ul><li>命令参数的可控</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">rule mapping:</span><br><span class="line">input:</span><br><span class="line">lambda wildcards: expand(<span class="string">"&#123;sample&#125;_&#123;read&#125;.fastq"</span>, sample=wildcards.sample, read=[<span class="string">"read1"</span>, <span class="string">"read2"</span>])</span><br><span class="line">log:</span><br><span class="line"><span class="string">"mapping/&#123;sample&#125;.log"</span></span><br><span class="line">threads: <span class="number">8</span></span><br><span class="line">params:</span><br><span class="line">extra = <span class="string">""</span></span><br><span class="line">shell:</span><br><span class="line"><span class="string">"bwa mem &#123;params.extra&#125; -t &#123;threads&#125; -o &#123;output&#125; &#123;input&#125; &gt; &#123;log&#125;"</span></span><br></pre></td></tr></table></figure><p>这里我们指定了 “bwa mem” 的运行线程数为 8，日志输出到 “mapping/{sample}.log”(还记得 wildcards 吧？) 中，额外的参数你可以写入到 params.extra 中。对于 线程数，虽然可以通过 params 来指定，但是呢，没有在 threads 声明的话，即使指定了，snakemake 仍旧会把它降级为一核的，你还要在运行 snakemake 的时候指定 “–cores 10”之类的参数。到这里你可能会问，可控性仅此吗？当然不是了。我们继续看。</p><ul><li>执行 rule 的可控</li></ul><p>如前所述，运行过程不会那么一帆风顺的，肯定会出错。根据我们的日志文件，我们定位出错的 rule。在 debug 之后，那肯定要测试一下。这时候以下参数就十分有用了，它可以让我们仅仅执行那些发生变动的 rule。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">snakemake -n <span class="comment"># 打印出运行流程，检验 input、output </span></span><br><span class="line">snakemake -p <span class="comment"># 打印出解析后所有要运行的命令</span></span><br><span class="line">snakemake -f mapping <span class="comment"># 仅仅执行 rule mapping及其所有依赖 rule</span></span><br><span class="line">snakemake -f `snakemake --list-code-changes` <span class="comment"># 执行所有代码发生变动的 rule</span></span><br><span class="line">snakemake -f `snakemake --list-input-changes` <span class="comment"># 执行所有输入发升变动的 rule</span></span><br><span class="line">snakemake -f `snakemake --list-params-changes` <span class="comment"># 执行所有参数设定发生变动的 rule</span></span><br></pre></td></tr></table></figure><ul><li>执行 rule 环境的可控</li></ul><p>做生信最头疼的东西是什么？配置环境，安装包啊，大批的新手倒在这里，白骨累累。来来来，snakemake 助你披襟斩棘。snakemake 提供的conda 和 wrappers 给你飞一般的感觉。对于前者，我们可以提供一个环境配置文件如 “env.baw.yaml”, 如下所示：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># env.bwa.yaml</span></span><br><span class="line">channels:</span><br><span class="line"> - bioconda</span><br><span class="line"> - conda-forge</span><br><span class="line">dependencies:</span><br><span class="line"> - bwa = <span class="number">2.7</span><span class="number">.1</span></span><br><span class="line"> - samtools = <span class="number">2.5</span><span class="number">.8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># your rule</span></span><br><span class="line">rule mapping:</span><br><span class="line"><span class="comment"># input, output, ...</span></span><br><span class="line">conda:</span><br><span class="line"><span class="string">"env.bwa.yaml"</span></span><br></pre></td></tr></table></figure><p>然后在启动 snakemake 时候，添加 “–use-conda” 参数，snakemake 将会自动生成 conda 环境，并基于 “env.bwa.yaml” 的配置安装依赖。你以为这就完了吗？NO NO NO，你还有wrappers。对于一些常用的软件，snakemake 把它整合成wrapper，按照 wrapper 的使用指南配置参数之后，snakemake 会为他自动配置运行环境，你什么都不用管, 不足之处就是支持的软件有点少。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">rule mapping:</span><br><span class="line"><span class="comment"># input, output, ...</span></span><br><span class="line">params:</span><br><span class="line">index = <span class="string">"genome"</span>,</span><br><span class="line">extra = r<span class="string">"-R '@RG\tID:&#123;sample&#125;\tSM:&#123;sample&#125;'"</span>,</span><br><span class="line">sort = <span class="string">"samtools"</span>, <span class="comment"># can be 'none', 'picard'</span></span><br><span class="line">sort_order = <span class="string">"coordinate"</span>, <span class="comment"># can be 'queryname'</span></span><br><span class="line">sort_extra = <span class="string">""</span> <span class="comment"># extra args for samtools/picard</span></span><br><span class="line">threads: <span class="number">8</span></span><br><span class="line">log:</span><br><span class="line"><span class="string">"logs/mapping/&#123;sample&#125;_bwa_mem.log"</span></span><br><span class="line">wrapper:</span><br><span class="line"><span class="string">"0.27.1/bio/bwa/mem"</span></span><br></pre></td></tr></table></figure><ul><li>执行 rule 脚本的可控性</li></ul><p>在不使用 wrapper 的时候，我们需要使用 rule.shell 来指定运行的命令，但是分析过程中，我们不仅会用到 bash，还会用到 python，甚至 R，snakemake 也统统让你使用。因为 snakemake 是基于 python 开发的，你的 Snakefile 其中的 python 代码会被 正常解析。这是其一，其二，如果你要在 rule 中使用 python，可以通过 rule.run 来实现。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rule mapping:</span><br><span class="line"><span class="comment"># input, output,...</span></span><br><span class="line">run:</span><br><span class="line">print(input)</span><br><span class="line">print(output)</span><br><span class="line">print(params)</span><br><span class="line"><span class="keyword">...</span></span><br><span class="line">shell(<span class="string">"some commands"</span>)</span><br></pre></td></tr></table></figure><p>rule.run 可以直接引导 rule 中的其他参数，如 output，input等等，shell是 snakemake引入的 (自己引入：from snakemake.shell import shell)。除此之外，如果你要使用 R 呢？怎么办？snakemake 提供了 rule.script 来满足你。它可以助你引入外部脚本，并执行它，对于 python 脚本，你可以通过 <code>snakemake.input</code> 的方式引用 rule 的各个选项，对于 R 脚本，你可以使用 <code>snakemake@input</code>，如下所示。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Snakemake</span></span><br><span class="line">rule mapping:</span><br><span class="line"><span class="comment"># input, output</span></span><br><span class="line">script:</span><br><span class="line"><span class="string">"mapping.R"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># mapping.R</span></span><br><span class="line">in_file = snakemake@input <span class="comment"># as a list</span></span><br><span class="line">out_file = snakemake@output <span class="comment"># as a list</span></span><br><span class="line">dosomething()</span><br></pre></td></tr></table></figure><h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><p>在写好这些 rule 之后，你一运行 <code>snakemake -n</code>，应该会出现一些 error （哈哈）。MissingInputError 表明你的 rule.all.input 中有些结果你没有生成哦，需要看看是那个输出结果你写了，但是没有 rule 生成它。Wildcards Error，表明你的通配符有问题，最直观的就是通配符要匹配的值你没有给。这个值得说一下。看下方的示例。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">rule all:</span><br><span class="line">input:</span><br><span class="line"><span class="string">"&#123;sample&#125;.bam"</span></span><br><span class="line"></span><br><span class="line">rule mapping:</span><br><span class="line">input:</span><br><span class="line"><span class="string">"&#123;sample&#125;.fastq"</span></span><br><span class="line">output:</span><br><span class="line"><span class="string">"&#123;sample&#125;.bam"</span></span><br></pre></td></tr></table></figure><p>初看之下，rule.all 中我们需要 “{sample}.bam” 文件，所以需要运行 rule.mapping。然而，snakemake 会给你报错的，说是无法指定确定的 input。为什么呢？通配符不能无中生有，它通配的是什么？通配的是 pipeline 最后结果，这个最后结果是我们指定的。所以 rule.all.input 不能含有不确定的东西，即必须确定。所以首先，rule.all.input应该改成：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rule all:</span><br><span class="line">input: expand(<span class="string">"&#123;sample&#125;.bam"</span>, sample=[<span class="string">"A1"</span>, <span class="string">"A2"</span>, <span class="string">"A3"</span>, <span class="string">"A4"</span>])</span><br></pre></td></tr></table></figure><p>如此一来，就可以了。但是 wildcards 的使用还有个问题，那就是 rule.input, rule.output, rule.log 这三个的通配符要一致。就是说，当 input 有通配符时，表明该 rule 会执行多次，那么 output 也应该是有多个，log 也应该有多个，不能覆盖，所以都需要一致的通配符 wildcards。但是，有时候，我们不想把 “{sample}.bam” 作为 rule.all 的 input （即最终结果），但仍旧想使用 wildcards，上面的修改方式就还会出现问题。例如：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">rule all:</span><br><span class="line">input: <span class="string">"mapping.stats.txt"</span></span><br><span class="line"></span><br><span class="line">rule mapping:</span><br><span class="line">input:</span><br><span class="line"><span class="string">"&#123;sample&#125;.fastq"</span></span><br><span class="line">output:</span><br><span class="line"><span class="string">"&#123;sample&#125;.bam"</span></span><br><span class="line"></span><br><span class="line">rule stats:</span><br><span class="line">input: <span class="string">"&#123;sample&#125;.bam"</span></span><br><span class="line">output: <span class="string">"mapping.stats.txt"</span></span><br></pre></td></tr></table></figure><p>这里还是一样，无法确定通配符要通配的对象。这时候，就要像 rule.all.input 一样，在某一处，确定通配符通配对象，结合前面所说，input/output/log 三种的通配情况应该一致，我们如果要在 rule.mapping 中使用通配，那它就不能发生变化，所以应该改为：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ... </span></span><br><span class="line">rule stats:</span><br><span class="line">input: expand(<span class="string">"&#123;sample&#125;.bam"</span>, sample=[<span class="string">"A1"</span>, <span class="string">"A2"</span>, <span class="string">"A3"</span>, <span class="string">"A4"</span>])</span><br><span class="line"><span class="comment"># ...</span></span><br></pre></td></tr></table></figure><p>如果 rule.mapping 中不使用 wildcards 的话，就可以把 rule.mapping.input/output/log 全部改成 expand 的形式。但是请注意，上述代码仅仅是作为解决通配符问题的例子，如果是比对的话，最好使用通配符，因为比对软件的输入输出是一对一的，不像 fastqc，一个命令输入多个样品，生成多个样品的结果。</p><p>最后，snakemake 还有许多 features，比如 temp/protected, cluster, derectory, touch等特性，值得再了解了解。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://snakemake.readthedocs.io/en/stable/" target="_blank" rel="noopener">Snakemake</a></p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 流程 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>扩增子测序 QIIME2</title>
      <link href="/2018/10/15/%E6%89%A9%E5%A2%9E%E5%AD%90%E6%B5%8B%E5%BA%8F-QIIME2/"/>
      <url>/2018/10/15/%E6%89%A9%E5%A2%9E%E5%AD%90%E6%B5%8B%E5%BA%8F-QIIME2/</url>
      
        <content type="html"><![CDATA[<h2 id="1-qiime2中数据的导入与导出"><a href="#1-qiime2中数据的导入与导出" class="headerlink" title="1 qiime2中数据的导入与导出"></a>1 qiime2中数据的导入与导出</h2><p>在QIIME2中，所有的输入数据都是以qiime2 artifacts的格式(.qza)存在，该格式有利于数据传递和生成路径追踪。在QIIME2中，你可以在分析的各个阶段导入数据，不论是原始的测序数据，还是经过处理产生的中间数据(eg. biom)，你都可以直接导入，接着进行后续分析。导入数据使用qiime tools import命令，你可以使用–show-importable-types和–show-importable-formats查看支持导入的数据类型，选择与你数据相应的导入类型。</p><p>你可以使用qiime tools export导出qiime的数据，用于R或者其他软件。这个命令与qiime tools extract命令的差别在于，导出命令只导出数据，与数据相关的生成追踪信息将被丢弃；但是提取命令不会，里面包含的provenance文件保存了这些追踪信息。</p><a id="more"></a><h3 id="1-1-导入含有测序质量的信息序列数据"><a href="#1-1-导入含有测序质量的信息序列数据" class="headerlink" title="1.1 导入含有测序质量的信息序列数据"></a>1.1 导入含有测序质量的信息序列数据</h3><h4 id="1-1-1-‘EMP-protocol’-multiplexed-fastq"><a href="#1-1-1-‘EMP-protocol’-multiplexed-fastq" class="headerlink" title="1.1.1 ‘EMP protocol’ multiplexed fastq"></a>1.1.1 ‘EMP protocol’ multiplexed fastq</h4><p>在EMP的格式结果中，由于它是混池测序的，有不同样品不同实验的测序结果，所以有2个fastq.gz文件，一个是测序序列文件，各个样品的测序结果混杂在一起(multiplexed)，另一个是对应的barcode文件.</p><p>这里的测序数据分别有single-end和pair-end，需要指定不同的导入类型</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">qiime tools import \</span><br><span class="line">        --<span class="built_in">type</span> EMPSingleEndSequneces \</span><br><span class="line">--input-path EMP_single \</span><br><span class="line">--output-path EMP_single_sequences.qza</span><br><span class="line"></span><br><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> EMPPairEndSequences \</span><br><span class="line">--input-path EMP_pair \</span><br><span class="line">--output-path EMP_pair_sequences.qza</span><br></pre></td></tr></table></figure><h4 id="1-1-2-‘Fastq-manifest’-formats"><a href="#1-1-2-‘Fastq-manifest’-formats" class="headerlink" title="1.1.2 ‘Fastq manifest’ formats"></a>1.1.2 ‘Fastq manifest’ formats</h4><p>在fastq manifest格式中，manifest文件指定了fastq.gz/fastq文件的绝对路径，比如TCGA中的manifest文件。你可以自己生成这类文件。它通常是逗号分隔的文件，每行的第一个域是样品标识符以供qiime2使用，第二个域是对应文件的绝对路径，第三个域是read的方向。注释行用#开头。文件的首行如果不是空行和注释行的话，则必须是表头行，内容为sample-id,absolute-filepath,direction。对于single-end reads，每个sample-id只能有1行信息。而对于pair-end reads，每个sample-id则必须有2行信息，分别对应着forward或reverse。在direction这一个域(列)的值只能是forward或者reverse。在absolute-filepath中，你可以使用环境变量$HOME/$PWD来指定路径。</p><p>在这个格式中，由于质量值不确定，我们需要选择自己数据质量值对应的输出格式。并且由于我们的manifest是根据sample-id来定义的，导入后的数据格式同EMP的数据demuplexed后的数据是一致的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pair-end reads</span></span><br><span class="line">sample-id,absolute-filepath,direction</span><br><span class="line">sample-1,<span class="variable">$PWD</span>/path/sample1_R1.fastq.gz,forward</span><br><span class="line">sample-1,<span class="variable">$PWD</span>/path/sample1_R2.fastq.gz,reverse</span><br><span class="line"><span class="comment"># single-end reads</span></span><br><span class="line">sample-id,absolute-filepath,direction</span><br><span class="line">sample-1,<span class="variable">$PWD</span>/path/sample1_R1.fastq.gz,forward</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意，在旧版本中--input-format对应着--source-format</span></span><br><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'SampleData[SequencesWithQuality]'</span> \</span><br><span class="line">--input-format SingleEndFastqManifestPhred33 \</span><br><span class="line">--input-path ss-33-manifest \</span><br><span class="line">--output-path single-end-demux.qza</span><br><span class="line"></span><br><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'SampleData[PairedEndSequnecesWithQuality]'</span></span><br><span class="line">--input-format PairedEndFastqManifestPhred64</span><br><span class="line">--input-path pe-64-manifest \</span><br><span class="line">--output-path paired-end-demux.qza</span><br></pre></td></tr></table></figure><h4 id="1-1-3-Casava-1-8-demultiplexed-fastq"><a href="#1-1-3-Casava-1-8-demultiplexed-fastq" class="headerlink" title="1.1.3 Casava 1.8 demultiplexed fastq"></a>1.1.3 Casava 1.8 demultiplexed fastq</h4><p>在这种格式中，每个样品只有1个fastq.gz文件，文件名就包含了样品标识符。对于single样品来说，可能是类似于‘L2S357_15_L001_R1_001.fastq.gz’的形式，含义是sample-id_barcode_lane-number_read-number_set-number。而对于paired样品来说，就额外多了一个‘L2S357_15_L001_R2_001.fastq.gz’，其中R1，R2表明是2个reads。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># single-end</span></span><br><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'SampleData[SequencesWithQuality]'</span> \</span><br><span class="line">--input-path casava-1.8 \</span><br><span class="line">--input-format CasavaOneEightSingleLanePerSampleDirFmt \</span><br><span class="line">--output-path demux-single-end.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># paired-end</span></span><br><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'SampleData[PairedEndSequencesWithQuality]'</span> \</span><br><span class="line">--input-path casava-1.8 \</span><br><span class="line">--input-format CasavaOneEightSingleLanePerSampleDirFmt \</span><br><span class="line">--output-path demux-paired-end.qza</span><br></pre></td></tr></table></figure><h3 id="1-2-导入特征表数据"><a href="#1-2-导入特征表数据" class="headerlink" title="1.2 导入特征表数据"></a>1.2 导入特征表数据</h3><h4 id="1-2-1-biom"><a href="#1-2-1-biom" class="headerlink" title="1.2.1 biom"></a>1.2.1 biom</h4><p>具体的格式描述见<a href="http://biom-format.org/documentation/format_versions/biom-1.0.html" target="_blank" rel="noopener">biom v1.0.0</a>和<a href="http://biom-format.org/documentation/format_versions/biom-2.1.html" target="_blank" rel="noopener">biom v2.1.0</a>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># biom v1.0.0</span></span><br><span class="line">qiime tools import \</span><br><span class="line">--input-path feature-table-v100.biom \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'FeatureTable[Frequency]'</span> \</span><br><span class="line">--input-format BIOMV100Format \</span><br><span class="line">--output-path feature-table-v100.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># biom v2.1.0</span></span><br><span class="line">qiime tools import \</span><br><span class="line">--input-path feature-table-v210.biom \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'FeatureTable[Frequency]'</span> \</span><br><span class="line">--input-format BIOMV210Format \</span><br><span class="line">--output-path feature-table-v210.qza</span><br></pre></td></tr></table></figure><h3 id="1-3-导入特征序列数据"><a href="#1-3-导入特征序列数据" class="headerlink" title="1.3 导入特征序列数据"></a>1.3 导入特征序列数据</h3><p>这一类数据通常是代表序列数据，是fasta格式的DNA序列。有些没有经过比对的；所以不会含有-的gap形式。有些则是经过比对的代表序列数据，其中就会含有-，使得各个序列的长度一致。但是这2类数据可能有N这类简并碱基。有些qiime2命令不支持这类。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># unaligned representative sequences</span></span><br><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'FeatureData[Sequence]'</span> \</span><br><span class="line">--input-path sequences.fna \</span><br><span class="line">--output-path sequences.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># aligned representative sequences</span></span><br><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'FeatureData[AlignedSequence]'</span> \</span><br><span class="line">--input-path aligned-sequences.fna \</span><br><span class="line">--output-path aligned-sequences.qza</span><br></pre></td></tr></table></figure><h3 id="1-4-导入无根系统发育树"><a href="#1-4-导入无根系统发育树" class="headerlink" title="1.4 导入无根系统发育树"></a>1.4 导入无根系统发育树</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'Phylogeny[Unrooted]'</span></span><br><span class="line">--input-path unrooted-tree.tre \</span><br><span class="line">--output-path unrooted-tree.qza</span><br></pre></td></tr></table></figure><h3 id="1-5-导出特征表"><a href="#1-5-导出特征表" class="headerlink" title="1.5 导出特征表"></a>1.5 导出特征表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">qiime tools <span class="built_in">export</span> \</span><br><span class="line">--input-path feature-table.qza \</span><br><span class="line">--output-path exported-feature-table</span><br></pre></td></tr></table></figure><h3 id="1-6-导出发育树"><a href="#1-6-导出发育树" class="headerlink" title="1.6 导出发育树"></a>1.6 导出发育树</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">qiime tools <span class="built_in">export</span> \</span><br><span class="line">--input-path unrooted-tree.qza \</span><br><span class="line">--output-path exproted-tree</span><br></pre></td></tr></table></figure><h2 id="2-qiime2中的metadata"><a href="#2-qiime2中的metadata" class="headerlink" title="2 qiime2中的metadata"></a>2 qiime2中的metadata</h2><p>qiime的sample meatadata存储了关于实验的元信息，诸如各类技术细节，barcod、run、Subject、time point等。 Feature metadata通常是一个特征注释，比如能域序列变化或OTU对应的分类信息。下面是一些关于metadata的操作。</p><h3 id="2-1-可视化metadata"><a href="#2-1-可视化metadata" class="headerlink" title="2.1 可视化metadata"></a>2.1 可视化metadata</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">qiime metadata tabulate \</span><br><span class="line">--m-input-file sample-metadata.tsv \</span><br><span class="line">--o-visualization tabulated-sample-metadata.qzv</span><br><span class="line"></span><br><span class="line">qiime metadata tabulate \</span><br><span class="line">--m-input-file faith_pd_vector.qza \</span><br><span class="line">--o-visualization tabulated-faith-pd-metadata.qzv</span><br></pre></td></tr></table></figure><h3 id="2-2-合并两个metadata"><a href="#2-2-合并两个metadata" class="headerlink" title="2.2 合并两个metadata"></a>2.2 合并两个metadata</h3><p>你可以联合几个metadata进行可视化</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">qiime metadata tabulate \</span><br><span class="line">  --m-input-file rep-seqs.qza \</span><br><span class="line">  --m-input-file taxonomy.qza \</span><br><span class="line">  --o-visualization tabulated-feature-metadata.qzv</span><br><span class="line"></span><br><span class="line">qiime metadata tabulate \</span><br><span class="line">--m-input-file sample-metadata.tsv \</span><br><span class="line">--m-input-file faith_pd_vector.qza \</span><br><span class="line">--o-visualization tabulated-combined.qzv</span><br><span class="line"></span><br><span class="line">qiime emperor plot \</span><br><span class="line">--i-pcoa unweighted_unifrac_pcoa_results.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--m-metadata-file faith_pd_vector.qza \</span><br><span class="line">--o-visualization unweighted-unifrac-emperor-with-alpha.qzv</span><br></pre></td></tr></table></figure><h2 id="3-qiime2中数据的过滤"><a href="#3-qiime2中数据的过滤" class="headerlink" title="3 qiime2中数据的过滤"></a>3 qiime2中数据的过滤</h2><h3 id="3-1-过滤特征表"><a href="#3-1-过滤特征表" class="headerlink" title="3.1 过滤特征表"></a>3.1 过滤特征表</h3><p>特征表有两个维度：样品和特征，分别使用filter-samples和filter-features来实现。</p><ul><li>基于总体频率的过滤</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 比如我们要过滤frequeny低于1500的样品</span></span><br><span class="line">qiime feature-table filter-samples \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--p-min-frequency 1500 \</span><br><span class="line">--o-filtered-table sample-frequency-filtered-table.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># 过滤在所有样品中frequency总计少于10的features</span></span><br><span class="line">qiime feature-table filter-features \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--p-min-frequency 10 \</span><br><span class="line">--o-filtered-table feature-frequency-filtered-table.qza</span><br></pre></td></tr></table></figure><ul><li>基于偶然性的过滤</li></ul><p>在进行计算特征表时或者特征序列时，有些样品个数或者某个特征仅仅为1，这些是需要进行过滤，因为可能是由测序引起的假阳性。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">qiime feature-table filter-features \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--p-min-samples 2 \</span><br><span class="line">--o-filtered-table sample-contigency-filtered-table.qza</span><br><span class="line"></span><br><span class="line">qiime feature-table filter-samples \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--p-min-features 10 \</span><br><span class="line">--o-filtered-table feature-contigency-filtered-table.qza</span><br></pre></td></tr></table></figure><ul><li>基于id的过滤</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">qiime feature-table filter-samples \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--m-metadata-file samples-to-keep.tsv \</span><br><span class="line">--o-filtered-table id-filtered-table.qza</span><br></pre></td></tr></table></figure><ul><li>基于metadata的过滤</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 单个过滤</span></span><br><span class="line">qiime feature-table filter-samples \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--p-where <span class="string">"Subject='subject-1'"</span> \</span><br><span class="line">--o-filtered-table subject-1-filtered-table.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多个过滤</span></span><br><span class="line">qiime feature-table filter-samples \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--p-where <span class="string">"BodySite IN ('left palm', 'right palm')"</span> \</span><br><span class="line">--o-filtered-table subject-1-filtered-table.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># 联合过滤，支持SQL选择语句，AND，OR，AND NOT</span></span><br><span class="line">qiime feature-table filter-samples \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--p-where <span class="string">"Subject='subject-1' AND BodySite='gut'"</span></span><br><span class="line">--o-filtered-table subject-1-filtered-table.qza</span><br></pre></td></tr></table></figure><ul><li>基于分类的过滤</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">qiime taxa filter-table \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--i-taxonomy taxonomy.qza \</span><br><span class="line">--p-exclude mitochondria \</span><br><span class="line">--o-filtered-table table-no-mitochondria.qza</span><br><span class="line"></span><br><span class="line">qiime taxa filter-table \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--i-taxonomy taxonomy.qza \</span><br><span class="line">--p-include mitochondria, chloroplast \</span><br><span class="line">--o-filtered-table table-no-mitochondria.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存有phylum-level注释的特征，从中保存的结果中去掉mitochondria,chloroplast</span></span><br><span class="line">qiime taxa filter-table \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--i-taxonomy taxonomy.qza \</span><br><span class="line">--p-include p__ \</span><br><span class="line">--p-exclude mitochondria,chloroplast \</span><br><span class="line">--o-filtered-table table-with-phyla-no-mitochondria-no-chloroplast.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过指定匹配模式为extact进行过滤</span></span><br><span class="line">qiime taxa filter-table \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--i-taxonomy taxonomy.qza \</span><br><span class="line">--p-mode exact \</span><br><span class="line">--p-exclude <span class="string">"k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rickettsiales; f__mitochondria"</span> \</span><br><span class="line">--o-filtered-table table-no-mitochondria-exact.qza</span><br></pre></td></tr></table></figure><h3 id="3-2-过滤序列"><a href="#3-2-过滤序列" class="headerlink" title="3.2 过滤序列"></a>3.2 过滤序列</h3><p>在q2-feature-table中也有个filter-seqs，你可以用它进行多条件过滤。q2-quality-control里面的exclude-seqs也能进行序列过滤。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">qiime taxa filter-seqs \</span><br><span class="line">--i-sequences sequences.qza \</span><br><span class="line">--i-taxonomy taxonomy.qza \</span><br><span class="line">--p-include p__ \</span><br><span class="line">--p-exclude mitochondria,chloroplast \</span><br><span class="line">--o-filtered-sequences sequences-with-phyla-no-mitochondria-no-chloroplast.qza</span><br></pre></td></tr></table></figure><h3 id="3-3-过滤距离矩阵"><a href="#3-3-过滤距离矩阵" class="headerlink" title="3.3 过滤距离矩阵"></a>3.3 过滤距离矩阵</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">qiime diversity filter-distance-matrix \</span><br><span class="line">--i-distance-matrix distance-matrix.qza \</span><br><span class="line">--m-metadata-file samples-to-keep.tsv \</span><br><span class="line">--o-filtered-distance-matrix identifier-filtered-distance-matrix.qza</span><br><span class="line"></span><br><span class="line">qiime diversity filter-distance-matrix \</span><br><span class="line">--i-distance-matrix distance-matrix.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--p-where <span class="string">"Subject='subject-2'"</span> \</span><br><span class="line">--o-filtered-distance-matrix subject-2-filtered-distance-matrix.qza</span><br></pre></td></tr></table></figure><h2 id="4-qiime2中特征分类器的训练"><a href="#4-qiime2中特征分类器的训练" class="headerlink" title="4 qiime2中特征分类器的训练"></a>4 qiime2中特征分类器的训练</h2><p>我们使用greengenes的参考序列对Native Bayes classifier进行训练，然后对目标代表序列进行分类。我们已经预先训练好了<a href="https://docs.qiime2.org/2018.8/data-resources/" target="_blank" rel="noopener">多个分类器</a>，你可以直接使用。<strong>要想训练分类器的话，有2个必须的东西：参考序列和物种分类</strong>。真实情况下，一般使用97%及以上的相似度的参考OTU数据集进行训练。参考序列和物种分类应该是要对应起来的额。比如你使用的是Greengenes 99% OTU sequences，那么你应该使用99% OTU taxonomy。</p><h3 id="4-1-下载和导入数据"><a href="#4-1-下载和导入数据" class="headerlink" title="4.1 下载和导入数据"></a>4.1 下载和导入数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里作为演示，用的是85 otu。真实情况不能使用。</span></span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/training-feature-classifiers/85_otus.fasta</span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/training-feature-classifiers/85_otu_taxonomy.txt</span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/training-feature-classifiers/rep-seqs.qza</span><br><span class="line"></span><br><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'FeatureData[Sequence]'</span> \</span><br><span class="line">--input-path 85_otus.fasta \</span><br><span class="line">--output-path 85_otus.qza</span><br><span class="line"></span><br><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'FeatureData[Taxonomy]'</span> \</span><br><span class="line">--input-path 85_otu_taxonomy.txt \</span><br><span class="line">--output-path 85_otu_taxonomy.qza</span><br></pre></td></tr></table></figure><h3 id="4-2-提取参考reads"><a href="#4-2-提取参考reads" class="headerlink" title="4.2 提取参考reads"></a>4.2 提取参考reads</h3><p>在处理16s数据时，使用目标序列的特定区域训练朴素贝叶斯分类器会提高分类的准确度。在对ITS序列时，则不用这样，因为根据经验，在处理ITS的UNITE参考序列的预先训练时，进行提取或截断的效果并不是很好。所以对于ITS分析，使用全长更好。<br>在这里，我们先使用515F/806R primer把能匹配的reads提取出来，然后截断成120bp的长度。注意，只有当待分类的代表序列被截断成一致长度时，参考序列才需要截断成对应的长度(这里是120bp)。用于提取的primer应该是具有生物学意义的序列，不能是adapter、linker、barcode之类的，一般来讲，若是你的primer长于30 nt，肯定有非生物学序列在里面。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">qiime feature-classifier extract-reads \</span><br><span class="line">--i-sequences 85_otus.qza \</span><br><span class="line">--p<span class="_">-f</span>-primer GTGCCAGCMGCCGCGGTAA \</span><br><span class="line">--p-r-primer GGACTACHVGGGTWTCTAAT \</span><br><span class="line">--p-trunc-len 120 \</span><br><span class="line">--o-reads ref-seqs.qza</span><br></pre></td></tr></table></figure><h3 id="4-3-训练分类器"><a href="#4-3-训练分类器" class="headerlink" title="4.3 训练分类器"></a>4.3 训练分类器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">qiime feature-classifier fit-classifier-naive-bayes \</span><br><span class="line">--i-reference-reads ref-seqs.qza \</span><br><span class="line">--i-reference-taxonomy ref-taxonomy.qza \</span><br><span class="line">--o-classifier classifier.qza</span><br></pre></td></tr></table></figure><h3 id="4-4-测试分类器"><a href="#4-4-测试分类器" class="headerlink" title="4.4 测试分类器"></a>4.4 测试分类器</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">qiime feature-classifier classify-sklearn \</span><br><span class="line">--i-classifier classifier.qza \</span><br><span class="line">--i-reads rep-seqs.qza \</span><br><span class="line">--o-classification taxonomy.qza</span><br><span class="line"></span><br><span class="line">qiime metadata tabulate \</span><br><span class="line">--m-input-file taxonomy.qza \</span><br><span class="line">--o-visualization taxonomy.qzv</span><br></pre></td></tr></table></figure><h2 id="5-使用q2-quality-control进行质控和过滤"><a href="#5-使用q2-quality-control进行质控和过滤" class="headerlink" title="5 使用q2-quality-control进行质控和过滤"></a>5 使用q2-quality-control进行质控和过滤</h2><p>下面演示了q2-quality-control如何使用模拟群落/已知群落组成的已知样品来进行数据质控和过滤。</p><h3 id="5-1-下载数据"><a href="#5-1-下载数据" class="headerlink" title="5.1 下载数据"></a>5.1 下载数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://data.qiime2.org/2018.8/tutorials/quality-control/query-seqs.qza</span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/quality-control/reference-seqs.qza</span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/quality-control/query-table.qza</span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/quality-control/qc-mock-3-expected.qza</span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/quality-control/qc-mock-3-observed.qza</span><br></pre></td></tr></table></figure><h3 id="5-2-通过比对过滤序列"><a href="#5-2-通过比对过滤序列" class="headerlink" title="5.2 通过比对过滤序列"></a>5.2 通过比对过滤序列</h3><p>exclude-seqs将查询序列和参考序列进行比对，根据多个比对标准区分能比对上和不能比对上的序列。你可以用本步骤来去除已知的污染序列、排除宿主序列、或这其他非目标序列。<br>exclude-seqs目前支持blast、vsearch、blastn-short作为比对方法，如果查询序列短于30nt，应当使用blastn-short。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">qiime quality-control exclude-seqs \</span><br><span class="line">--i-query-sequences query-seqs.qza \</span><br><span class="line">--i-reference-sequences reference-seqs.qza \</span><br><span class="line">--p-method blast \</span><br><span class="line">--p-perc-identity 0.97 \</span><br><span class="line">--p-perc-query-aligned 0.97 \</span><br><span class="line">--o-sequence-hits hist.qza \</span><br><span class="line">--o-sequence-misses misses.qza</span><br><span class="line"></span><br><span class="line">qiime feature-table filter-features \</span><br><span class="line">--i-table query-table.qza \</span><br><span class="line">--m-metadata-file hits.qza \</span><br><span class="line">--o-filtered-table no-hits-filtered-table.qza \</span><br><span class="line">--p-exclude-ids</span><br></pre></td></tr></table></figure><h3 id="5-3-用已知组成的样品进行质控"><a href="#5-3-用已知组成的样品进行质控" class="headerlink" title="5.3 用已知组成的样品进行质控"></a>5.3 用已知组成的样品进行质控</h3><p>模拟群落的群落组成和丰度都是已知的，可以用于生信的基准测试(benchmarking bioinformatics methods)，比如测定某个方法或流程的处理准确度。<br>quality-control的evaluate-composition可以验证分类器分类结果的准确度。现有的模拟群落可在<a href="https://github.com/caporaso-lab/mockrobiota/blob/master/inventory.tsv" target="_blank" rel="noopener">mockrobiota查询</a>.<br>在结果中，预期和观测的物种丰度的TAR(taxon accuracy rate)、TDR(taxon detection rate)和linear regression scores都会计算，并根据每个物种水平进行作图。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">qiime quality-control evaluate-composition \</span><br><span class="line">--i-expected-features qc-mock-3-expected.qza \</span><br><span class="line">--i-observed-features qc-mock-3-observed.qza \</span><br><span class="line">--o-visualiation qc-mock-3-cmparison.qzv</span><br></pre></td></tr></table></figure><h3 id="5-4-序列质量的验证"><a href="#5-4-序列质量的验证" class="headerlink" title="5.4 序列质量的验证"></a>5.4 序列质量的验证</h3><p>evaluate-seqs将查询序列和参考序列进行比对验验证比对的质量。利用预测序列和观测序列可以验证desnoising或OTU picking结果的准确度。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">qiime quality-control evaluate-seqs \</span><br><span class="line">  --i-query-sequences query-seqs.qza \</span><br><span class="line">  --i-reference-sequences reference-seqs.qza \</span><br><span class="line">  --o-visualization <span class="built_in">eval</span>-seqs-test.qzv</span><br></pre></td></tr></table></figure><h2 id="6-使用q2-sample-classifier预测metadata"><a href="#6-使用q2-sample-classifier预测metadata" class="headerlink" title="6 使用q2-sample-classifier预测metadata"></a>6 使用q2-sample-classifier预测metadata</h2><p>正如多数统计方法一样，sample-classifier的预测功能也需要一定量的样本才能产生有意义的结果，一般来说，需要至少50个样品；样本太少产生的结果将会导致不准确的模型或者错误。用于预测的类别型元数据列的每个值都至少需要10个sample；用于回归的连续型元数据列不能有太多离群值或者分布不均匀。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://data.qiime2.org/2018.8/tutorials/moving-pictures/sample_metadata.tsv</span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/sample-classifier/moving-pictures-table.qza</span><br></pre></td></tr></table></figure><h3 id="6-1-预测类别型样品数据"><a href="#6-1-预测类别型样品数据" class="headerlink" title="6.1 预测类别型样品数据"></a>6.1 预测类别型样品数据</h3><p>这里我们将根据样品的微生物组成来预测这个样品时来源于哪个身体部位。按照classify-samples进行,内部步骤如下：</p><ol><li>把样品随机分成训练集和测试集；通过–p-test-size来指定测试集的大小。</li><li>选择一个估值器(estimator)，设置参数进行训练。</li><li>K-fold cross-validation进行模型优化，通过–p-cv设置K-fold值。</li><li>使用测试集进行预测</li><li>计算预测模型准确度</li></ol><h4 id="6-1-1-建立预测模型"><a href="#6-1-1-建立预测模型" class="headerlink" title="6.1.1 建立预测模型"></a>6.1.1 建立预测模型</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">qiime sample-classfifier classify-samples \</span><br><span class="line">--i-table moving-pictures-table.qza \</span><br><span class="line">--m-metadata-file moving-pictures-sample-metadata.tsv \</span><br><span class="line">--m-metadata-column BodySite \</span><br><span class="line">--p-optimize-feature-selection \</span><br><span class="line">--p-parameter-tuning \</span><br><span class="line">--p-estimator RandomForestClassifier \</span><br><span class="line">--p-n-estimators 20 \</span><br><span class="line">--output-dir moving-pictures-classifier</span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="comment"># sample_estimator.qza, feature_importance.qza, predictions.qza, accuracy_result.qzv, model_summary.qzv</span></span><br><span class="line"></span><br><span class="line">qiime metadata tabulate \</span><br><span class="line">--m-input-file moving-pictures-classifier/predictions.qza \</span><br><span class="line">--o-visualization moving-pictures-classifier/predictions.qzv</span><br><span class="line"></span><br><span class="line">qiime metadata tabulate \</span><br><span class="line">--m-input-file moving-pictures-classifier/feature_importance.qza \</span><br><span class="line">--o-visualization moving-pictures-classifier/feature_importance.qzv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用预测重要的feature过滤原始table</span></span><br><span class="line">qiime feature-table filter-features \</span><br><span class="line">--i-table moving-pictures-table.qza \</span><br><span class="line">--m-metadata-file moving-pictures-classifier/feature_importance.qza \</span><br><span class="line">--o-filtered-table moving-pictures-classifier/important-feature-table.qza</span><br></pre></td></tr></table></figure><h4 id="6-1-2-进行预测"><a href="#6-1-2-进行预测" class="headerlink" title="6.1.2 进行预测"></a>6.1.2 进行预测</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测新的metadata</span></span><br><span class="line">qiime sample-classifier predict-classification \</span><br><span class="line">  --i-table new-table.qza \</span><br><span class="line">  --i-sample-estimator moving-pictures-classifier/sample_estimator.qza \</span><br><span class="line">  --o-predictions moving-pictures-classifier/new_predictions.qza</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用新的样品重新测试模型的准确性</span></span><br><span class="line">qiime sample-classifier confusion-matrix \</span><br><span class="line">--i-predictions moving-pictures-classifier/new_predictions.qza \</span><br><span class="line">--m-truth-file moving-pictures-sample-metadata.tsv \</span><br><span class="line">--m-truth-column BodySite \</span><br><span class="line">--o-visualization moving-pictures-classifier/new_confusion_matrix.qzv</span><br></pre></td></tr></table></figure><h3 id="6-2-预测连续型样品数据"><a href="#6-2-预测连续型样品数据" class="headerlink" title="6.2 预测连续型样品数据"></a>6.2 预测连续型样品数据</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://data.qiime2.org/2018.8/tutorials/longitudinal/sample_metadata.tsv</span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/longitudinal/ecam_table_maturity.qza</span><br></pre></td></tr></table></figure><h4 id="6-2-1-训练模型"><a href="#6-2-1-训练模型" class="headerlink" title="6.2.1 训练模型"></a>6.2.1 训练模型</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">qiime sample-classifier regress-samples \</span><br><span class="line">--i-table ecam-table.qza \</span><br><span class="line">--m-metadata-file ecam-metadata.tsv \</span><br><span class="line">--m-metadata-column month \</span><br><span class="line">--p-estimator RandomForestRegressor \</span><br><span class="line">--p-n-estimators 20 \</span><br><span class="line">--output-dir ecam-regressor</span><br><span class="line"></span><br><span class="line"><span class="comment"># ouput</span></span><br><span class="line"><span class="comment"># sample_estimator.qza, feature_importance.qza, accuracy_results.qzv, model_summary.qzv</span></span><br></pre></td></tr></table></figure><h3 id="6-3-使用nested-cross-validation法进行预测"><a href="#6-3-使用nested-cross-validation法进行预测" class="headerlink" title="6.3 使用nested cross-validation法进行预测"></a>6.3 使用nested cross-validation法进行预测</h3><h4 id="6-3-1-类别型变量：训练模型"><a href="#6-3-1-类别型变量：训练模型" class="headerlink" title="6.3.1 类别型变量：训练模型"></a>6.3.1 类别型变量：训练模型</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">qiime sample-classifier classify-samples-ncv \</span><br><span class="line">--i-table moving-pictures-table.qza \</span><br><span class="line">--m-metadata-file moving-pictures-sample-metadata.tsv \</span><br><span class="line">--m-metadata-column BodySite \</span><br><span class="line">--p-estimator RandomForestClassifier \</span><br><span class="line">--p-n-estimators 20 \</span><br><span class="line">--o-predictions BodySite-predictions-ncv.qza \</span><br><span class="line">--o-feature-importance BodySite-importance-ncv.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看模型准确性</span></span><br><span class="line">qiime sample-classifier confusion-matrix \</span><br><span class="line">--i-predictions BodySite-predictions-ncv.qza \</span><br><span class="line">--m-truth-file moving-pictures-sample-metadata.tsv \</span><br><span class="line">--m-truth-column BodySite \</span><br><span class="line">--o-visualization ncv_confusion_matrix.qzv</span><br></pre></td></tr></table></figure><h4 id="6-3-2-连续型变量：训练模型"><a href="#6-3-2-连续型变量：训练模型" class="headerlink" title="6.3.2 连续型变量：训练模型"></a>6.3.2 连续型变量：训练模型</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">qiime sample-classifier regress-samples-ncv \</span><br><span class="line">--i-table ecam-table.qzv \</span><br><span class="line">--m-metadata ecam-metadata.tsv \</span><br><span class="line">--m-metadata-column month \</span><br><span class="line">--p-n-estimators 20 \</span><br><span class="line">--p-estimator RandomForestRegressor \</span><br><span class="line">--o-predictions ecam-predictions-ncv.qza \</span><br><span class="line">--o-feature-importance ecam-importance-ncv.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看结果准确性</span></span><br><span class="line">qiime sample-classifier scatterplot \</span><br><span class="line">--i-predictions ecam-predictions-ncv.qza \</span><br><span class="line">--m-truth-file ecam-metadata.tsv \</span><br><span class="line">--m-truth-column month \</span><br><span class="line">--o-visualization ecam-scatter.qzv</span><br></pre></td></tr></table></figure><h3 id="6-4-最佳实践：你不应该做q2-sample-classifier做的事"><a href="#6-4-最佳实践：你不应该做q2-sample-classifier做的事" class="headerlink" title="6.4.最佳实践：你不应该做q2-sample-classifier做的事"></a>6.4.最佳实践：你不应该做q2-sample-classifier做的事</h3><ul><li>数据泄漏</li><li>过拟合</li></ul><h2 id="7-使用q2-longitudinal进行纵向和成对差异比较"><a href="#7-使用q2-longitudinal进行纵向和成对差异比较" class="headerlink" title="7 使用q2-longitudinal进行纵向和成对差异比较"></a>7 使用q2-longitudinal进行纵向和成对差异比较</h2><p>q2-longitudinal可以用来进行纵向研究设计和成对样品的统计和可视化，以探究样品是如何在可观测的状态之间变化的。可观测的状态通常是时间或者环境梯度，也可以是不同时间点的成对分析比如成对的距离和差异分析；比如在治疗前后的临床研究。可观测的状态也可以是方法上的，在同个时间点上采用不同方法的结果的比较。比如q2-longitudinal可以比较不同样品收集方法、存储方法、DNA提取方法对单个样品的微生物群落特征组成影响。</p><p>在q2-longitudinal中的操作多数以某个度量值作为输入，这通常是metadata里面的某个列、alpha diversity vectors、PCoA results或者是feature ID。合法的度量值名字可以通过qiime metadata tabulate命令查看得到，feature name也可以通过qiime feature-data summarize命令查看得到。</p><h3 id="7-1-成对差异比较"><a href="#7-1-成对差异比较" class="headerlink" title="7.1 成对差异比较"></a>7.1 成对差异比较</h3><p>成对差异比较探究的是成对样品之间某个特定的度量值是否具有显著性变化；目前支持的比较类型有：</p><ul><li>特征丰度的比较(comparison of feature abundance): 比如在特征表中微生物序列变体或者变化率</li><li>元数据值的比较(comparison of metadata values): 比如将alpha/beta diversity values作为度量值，结合某个元数据值进行比较</li></ul><p>下面的命令是探究以delivery mode作为分组，不同的两个时间点上(state-column)两组的shannon diversity index(alpha diversity)是否发现显著变化。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">qiime longitudinal pairwise-differences \</span><br><span class="line">--m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">--m-metadata-file shannon.qza \</span><br><span class="line">--p-metric shannon \</span><br><span class="line">--p-group-column delivery \</span><br><span class="line">--p-state-column month \</span><br><span class="line">--p-state-1 0 \</span><br><span class="line">--p-state-2 12 \</span><br><span class="line">--p-individual-id-column studyid \</span><br><span class="line">--p-replicate-handling random \</span><br><span class="line">--o-visualization pairwise-differences.qzv</span><br></pre></td></tr></table></figure><h3 id="7-2-成对距离比较"><a href="#7-2-成对距离比较" class="headerlink" title="7.2 成对距离比较"></a>7.2 成对距离比较</h3><p>成对距离比较探究的也是成对样品之间某个特定的度量值是否具有显著性变化，但是，相对于使用metadata的某个列或者qiime artifact作为输入，成对距离比较以距离矩阵作为输入，来探究成对样品在pre和post下的距离变化，并显示其差异是否显著。<br>下面的命令是探究以delivery作为分组，正常分娩和剖腹产在12个月后对微生物组成的稳定性的影响。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">qiime longitudinal pairwise-distances \</span><br><span class="line">--i-distance-matrix unweighted_unifrac_distance_matrix.qza \</span><br><span class="line">--m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">--p-group-column delivery \</span><br><span class="line">--p-state-column month \</span><br><span class="line">--p-state-1 0 \</span><br><span class="line">--p-state-2 12 \</span><br><span class="line">--p-individual-id-column studyid \</span><br><span class="line">--p-replicate-handling random \</span><br><span class="line">--o-visualization pairwise-distances.qzv</span><br></pre></td></tr></table></figure><h3 id="7-3-线性混合效应模型"><a href="#7-3-线性混合效应模型" class="headerlink" title="7.3 线性混合效应模型"></a>7.3 线性混合效应模型</h3><p>线性混合效应模型(linear mixed effects models, LME)探究单个因变量和一至多个自变量之间的关系；因变量的观测值通常在跨相关样本中获得，比如在重复测量的抽样实验中。该模型以至少一个数字型state-column(如时间)或者一至多个逗号分隔的group-columns作为自变量，然后绘出因变量(metric,某个度量)的回归曲线。此外，individual-id-column参数应该是个可以指明样品重复情况的metadata column。因变量可以是metadata的某列(column)，也可以是feature table的feature ID。逗号分隔的多个随机效应值可以作为该模型的输入；模型默认每个个体都有随机的截距；如果用户为每个个体提供随机的斜率(slope)的话，可以使用state-column值来作为random-effects的值。</p><p>注意，判断某个因素是为固定效应还是随机效应比较复杂。一般来说，如果一个因子的不同水平(metadata column values)可以代表所有的离散值的话，该因子应该是固定效应；例如delivery mode、sex、diet在下面的分析中就是固定效应。那相反地，如果一个因子的值是代表群体内的随机样品，那么这个因子就是随机效应；比如body-weight、daily-kcal-from-breastmilk等，这些值只能代表从人群中的某些人，并不能代表所有的情况。</p><p>这里我们使用LME来探究shannon diversity index是否会随时间、delivery mode、diet、sex发生变化。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">qiime longitudinal linear-mixed-effects \</span><br><span class="line">--m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">--m-metadata-file shannon.qza \</span><br><span class="line">--p-metric shannon \</span><br><span class="line">--p-group-columns delivery,diet,sex \</span><br><span class="line">--p-state-column month \</span><br><span class="line">--p-individual-id-column studyid \</span><br><span class="line">--o-visualization linear-mixed-effects.qzv</span><br></pre></td></tr></table></figure><p>产生的可视化文件包含多个图。首先是输入参数显示在最上方。然后是model summary显示LME模型的训练信息。主要的结果是第三个，所谓model results table。它显示了每个固定效应和效应之间的互作对因变量(shannon diversity)的影响，它还显示了其他信息如参数估计、估计标准差、z-score、p-values等。从该表可以看出shannon diversity受month、diet和其他几个交互因子影响明显。最后是依据各个group column制作的散点图和线性回归曲线。如果–p-lowess指定了，还会显示加权平均值。第一类散点图只是进行了一下快速统计，可以使用volatility进行交互式地统计和作图。第二类散点图显示每个样品的观测残差值和度量预测值之间的关系：度量预测值应该在0值附近，与残差值没有相关性。如果观察到U形或者非随机分布图，说明你的预测变量(group_columns, random_effects)不能很好地表征数据。</p><h3 id="7-4-波动分析-volatility-anaylsis"><a href="#7-4-波动分析-volatility-anaylsis" class="headerlink" title="7.4 波动分析(volatility anaylsis)"></a>7.4 波动分析(volatility anaylsis)</h3><p>波动分析(volatility analysis)可产生交互式的折线图以探究因变量在单组或多组之间的连续型自变量的依赖关系。多个metadata file(alpha,beta diversity)和FeatureTable[RelativeFrequency]可以作为输入，也可以选择不同的因变量作为图的y轴。<br>这里我们探究一下shannon diversity和其他metadata是如何随时间变化的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">qiime longitudinal volatility \</span><br><span class="line">--m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">--m-metadata-file shannon.qza \</span><br><span class="line">--p-default-metric shannon \</span><br><span class="line">--p-default-group-column delivery \</span><br><span class="line">--p-state-column month \</span><br><span class="line">--p-individual-id-column studyid \</span><br><span class="line">--o-visualization volatility.qzv</span><br></pre></td></tr></table></figure><h3 id="7-5-用一阶差分来追踪变化率"><a href="#7-5-用一阶差分来追踪变化率" class="headerlink" title="7.5 用一阶差分来追踪变化率"></a>7.5 用一阶差分来追踪变化率</h3><p>观察时间序列数据的另一个方法就是计算变化率随时间的变化，要实现这个目的就需要计算一阶差分，它表征了在连续时间点之间的变化大小。delta Yt = Y(t) -Y(t-1),这个变换在first-differences/first-distances中用到。对于生成的结果文件，你可以进行波动分析。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># alpha diversity or metadata column (metric)</span></span><br><span class="line">qiime longitudinal first-differences \</span><br><span class="line">  --m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">  --m-metadata-file shannon.qza \</span><br><span class="line">  --p-state-column month \</span><br><span class="line">  --p-metric shannon \</span><br><span class="line">  --p-individual-id-column studyid \</span><br><span class="line">  --p-replicate-handling random \</span><br><span class="line">  --o-first-differences shannon-first-differences.qza</span><br><span class="line"><span class="comment"># beta diversity (matrix)</span></span><br><span class="line">qiime longitudinal first-distances \</span><br><span class="line">  --i-distance-matrix unweighted_unifrac_distance_matrix.qza \</span><br><span class="line">  --m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">  --p-state-column month \</span><br><span class="line">  --p-individual-id-column studyid \</span><br><span class="line">  --p-replicate-handling random \</span><br><span class="line">  --o-first-distances first-distances.qza</span><br><span class="line"><span class="comment"># 经过计算，beta diversity也可以进行LME分析</span></span><br><span class="line">qiime longitudinal linear-mixed-effects \</span><br><span class="line">  --m-metadata-file first-distances.qza \</span><br><span class="line">  --m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">  --p-metric Distance \</span><br><span class="line">  --p-state-column month \</span><br><span class="line">  --p-individual-id-column studyid \</span><br><span class="line">  --p-group-columns delivery,diet \</span><br><span class="line">  --o-visualization first-distances-LME.qzv</span><br></pre></td></tr></table></figure><p>你也可以从固定时间点开始追踪变化率的大小变化。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">qiime longitudinal first-distances \</span><br><span class="line">  --i-distance-matrix unweighted_unifrac_distance_matrix.qza \</span><br><span class="line">  --m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">  --p-state-column month \</span><br><span class="line">  --p-individual-id-column studyid \</span><br><span class="line">  --p-replicate-handling random \</span><br><span class="line">  --p-baseline 5 \</span><br><span class="line">  --o-first-distances first-distances-baseline-0.qza</span><br></pre></td></tr></table></figure><h3 id="7-6-微生物相互依赖性非参数检验"><a href="#7-6-微生物相互依赖性非参数检验" class="headerlink" title="7.6 微生物相互依赖性非参数检验"></a>7.6 微生物相互依赖性非参数检验</h3><p>在微生物群落中，微生物种群并不会独立存在，而是以生态互作网存在。而这些互作网是否会在同组个体之家产生临时效应将指明不同的研究方向。微生物相互依赖性非参数检验(non-parametric microbial interdependence test, NMIT)将评估同组的同个群落内的特征相互依赖性(比如种类、序列变体、OTU)如何依据时间不同而不同。MNIT评估纵向样本相似性。对于每个个体，NMIT计算成对特征的相关性；然后基于NMIT矩阵计算成对个体的距离。该方法只对纵向数据有用，例如时间序列数据。为使检验结果鲁棒，我们建议每个个体最少要测5个时间点的数据；但它不要求所有的样品数据都在同个时间点测得。</p><p>NMIT的检验结果是一个距离矩阵，你可以像处理beta diversity的结果数据一样进行处理。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">wget https://data.qiime2.org/2018.8/tutorials/longitudinal/ecam_table_taxa.qza</span><br><span class="line"></span><br><span class="line">qiime longitudinal nmit \</span><br><span class="line">  --i-table ecam-table-taxa.qza \</span><br><span class="line">  --m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">  --p-individual-id-column studyid \</span><br><span class="line">  --p-corr-method pearson \</span><br><span class="line">  --o-distance-matrix nmit-dm.qza</span><br><span class="line"></span><br><span class="line">qiime diversity beta-group-significance \</span><br><span class="line">  --i-distance-matrix nmit-dm.qza \</span><br><span class="line">  --m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">  --m-metadata-column delivery \</span><br><span class="line">  --o-visualization nmit.qzv</span><br><span class="line"></span><br><span class="line">qiime diversity pcoa \</span><br><span class="line">  --i-distance-matrix nmit-dm.qza \</span><br><span class="line">  --o-pcoa nmit-pc.qza</span><br><span class="line"></span><br><span class="line">qiime emperor plot \</span><br><span class="line">  --i-pcoa nmit-pc.qza \</span><br><span class="line">  --m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">  --o-visualization nmit-emperor.qzv</span><br></pre></td></tr></table></figure><h3 id="7-7-特征波动分析"><a href="#7-7-特征波动分析" class="headerlink" title="7.7 特征波动分析"></a>7.7 特征波动分析</h3><p>特征波动分析是一个监回归方法，可以确定某个数字型metadata column、state-column的值，并绘出不同state的相对频率图。state-column通常是个时间度量值，不过它也可以时任何数字型column；但是它不能和individual-id-column相同。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">wget -O ecam-table.qza https://data.qiime2.org/2018.8/tutorials/longitudinal/ecam_table_maturity.qza</span><br><span class="line"></span><br><span class="line">qiime longitudinal feature-volatility \</span><br><span class="line">  --i-table ecam-table.qza \</span><br><span class="line">  --m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">  --p-state-column month \</span><br><span class="line">  --p-individual-id-column studyid \</span><br><span class="line">  --p-n-estimators 10 \</span><br><span class="line">  --p-random-state 123 \</span><br><span class="line">  --output-dir ecam-feat-volatility</span><br></pre></td></tr></table></figure><h3 id="7-8-成熟指数预测"><a href="#7-8-成熟指数预测" class="headerlink" title="7.8 成熟指数预测"></a>7.8 成熟指数预测</h3><p>这个分析在对各个时间点样品数目分布均匀时的分析结果较好; 对于某些时间点有缺失值的情况下无法进行分析；此外，本分析还需要大量数据才能正常分析，特别是对照组在各个时间点需要足够的生物学重复。这个分析基于特征数据(feature data)构建回归模型，计算微生物成熟指数，一次来预测给定连续型metadata column的值，例如给定微生物组成预测个体的年龄。这个分析域标准监督回归分析不同在于它量化了多个组之间随时间变化的相对速率。</p><p>下面我们比较在不同年龄下，剖腹产和自然分娩之间微生物群落的成熟度。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">qiime longitudinal maturity-index \</span><br><span class="line">  --i-table ecam-table.qza \</span><br><span class="line">  --m-metadata-file ecam-sample-metadata.tsv \</span><br><span class="line">  --p-state-column month \</span><br><span class="line">  --p-group-by delivery \</span><br><span class="line">  --p-individual-id-column studyid \</span><br><span class="line">  --p-control Vaginal \</span><br><span class="line">  --p-test-size 0.4 \</span><br><span class="line">  --output-dir maturity</span><br></pre></td></tr></table></figure><h2 id="8-qiime2中嵌合体的去除"><a href="#8-qiime2中嵌合体的去除" class="headerlink" title="8 qiime2中嵌合体的去除"></a>8 qiime2中嵌合体的去除</h2><p>qiime2中的嵌合体检测基于FeatureTable[Frequency]和FeatureData[Sequences]，它整合了Uchime de novo和vsearch这两个软件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://data.qiime2.org/2018.8/tutorials/chimera/atacama-table.qza</span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/chimera/atacama-rep-seqs.qza</span><br></pre></td></tr></table></figure><h3 id="8-1-de-novo-chimera-checking"><a href="#8-1-de-novo-chimera-checking" class="headerlink" title="8.1 de novo chimera checking"></a>8.1 de novo chimera checking</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">qiime vsearch uchime-denovo \</span><br><span class="line">--i-table atacama-table.qza \</span><br><span class="line">--i-sequences atacama-rep-seqs.qza \</span><br><span class="line">--output-dir uchime-dn-out</span><br><span class="line"><span class="comment"># out</span></span><br><span class="line"><span class="comment"># nonchimeras.qza, chimeras.qza, stats.qza</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化统计结果</span></span><br><span class="line">qiime metadata tabulate \</span><br><span class="line">--m-input-file uchime-dn-out/stats.qza \</span><br><span class="line">--o-visualization uchime-dn-out/stats.qzv</span><br></pre></td></tr></table></figure><h3 id="8-2-对输入的tables和序列进行过滤"><a href="#8-2-对输入的tables和序列进行过滤" class="headerlink" title="8.2 对输入的tables和序列进行过滤"></a>8.2 对输入的tables和序列进行过滤</h3><ul><li>去除chimeras和borderline chimeras</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">qiime feature-table filter-features \</span><br><span class="line">  --i-table atacama-table.qza \</span><br><span class="line">  --m-metadata-file uchime-dn-out/nonchimeras.qza \</span><br><span class="line">  --o-filtered-table uchime-dn-out/table-nonchimeric-wo-borderline.qza</span><br><span class="line"></span><br><span class="line">qiime feature-table filter-seqs \</span><br><span class="line">  --i-data atacama-rep-seqs.qza \</span><br><span class="line">  --m-metadata-file uchime-dn-out/nonchimeras.qza \</span><br><span class="line">  --o-filtered-data uchime-dn-out/rep-seqs-nonchimeric-wo-borderline.qza</span><br><span class="line"></span><br><span class="line">qiime feature-table summarize \</span><br><span class="line">  --i-table uchime-dn-out/table-nonchimeric-wo-borderline.qza \</span><br><span class="line">  --o-visualization uchime-dn-out/table-nonchimeric-wo-borderline.qzv</span><br></pre></td></tr></table></figure><ul><li>去除嵌合体，但是保留 borderline chimeras</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">qiime feature-table filter-features \</span><br><span class="line">  --i-table atacama-table.qza \</span><br><span class="line">  --m-metadata-file uchime-dn-out/chimeras.qza \</span><br><span class="line">  --p-exclude-ids \</span><br><span class="line">  --o-filtered-table uchime-dn-out/table-nonchimeric-w-borderline.qza</span><br><span class="line"></span><br><span class="line">qiime feature-table filter-seqs \</span><br><span class="line">  --i-data atacama-rep-seqs.qza \</span><br><span class="line">  --m-metadata-file uchime-dn-out/chimeras.qza \</span><br><span class="line">  --p-exclude-ids \</span><br><span class="line">  --o-filtered-data uchime-dn-out/rep-seqs-nonchimeric-w-borderline.qza</span><br><span class="line">  </span><br><span class="line">qiime feature-table summarize \</span><br><span class="line">  --i-table uchime-dn-out/table-nonchimeric-w-borderline.qza \</span><br><span class="line">  --o-visualization uchime-dn-out/table-nonchimeric-w-borderline.qzv</span><br></pre></td></tr></table></figure><h2 id="9-qiime2中的reads合并与去噪"><a href="#9-qiime2中的reads合并与去噪" class="headerlink" title="9 qiime2中的reads合并与去噪"></a>9 qiime2中的reads合并与去噪</h2><p>这里描述的方法并不是说要代替DADA2中的合并序列、去噪过程。相反地，这里的方法的关注点在于分析 paired-end reads的其他方法。如果你对使用DADA2进行合并和去噪感兴趣的话，<a href="https://docs.qiime2.org/2018.8/tutorials/atacama-soils/" target="_blank" rel="noopener">atacama soil</a>写明了如何使用qiime dada2 denoise-paired实现；如果使用dada2的话，请不要预先进行合并序列。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -O demux.qza https://data.qiime2.org/2018.8/tutorials/<span class="built_in">read</span>-joining/atacama-seqs.qza</span><br></pre></td></tr></table></figure><h3 id="9-1-joining-reads"><a href="#9-1-joining-reads" class="headerlink" title="9.1 joining reads"></a>9.1 joining reads</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">qiime vsearch join-pairs \</span><br><span class="line">--i-demultiplexed-seqs demux.qza \</span><br><span class="line">--o-joined-sequences demux-joined.qza</span><br><span class="line"></span><br><span class="line">qiime demux summarize \</span><br><span class="line">--i-data demux-joined.qza \</span><br><span class="line">--o-visualization demux-joined.qzv</span><br></pre></td></tr></table></figure><h3 id="9-2-sequence-quality-control"><a href="#9-2-sequence-quality-control" class="headerlink" title="9.2 sequence quality control"></a>9.2 sequence quality control</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">qiime quality-filter q-score-joined \</span><br><span class="line">--i-demux demux-joined.qza \</span><br><span class="line">--o-filtered-sequences demux-joined-filtered.qza \</span><br><span class="line">--o-filter-stats demux-joined-filter-stats.qza</span><br></pre></td></tr></table></figure><h3 id="9-3-deblur"><a href="#9-3-deblur" class="headerlink" title="9.3 deblur"></a>9.3 deblur</h3><p>在第二步之后，你可以选择使用deblur进一步质控，也可以进行去重复序列然后进行聚类。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">qiime deblur denoise-16S \</span><br><span class="line">  --i-demultiplexed-seqs demux-joined-filtered.qza \</span><br><span class="line">  --p-trim-length 250 \</span><br><span class="line">  --p-sample-stats \</span><br><span class="line">  --o-representative-sequences rep-seqs.qza \</span><br><span class="line">  --o-table table.qza \</span><br><span class="line">  --o-stats deblur-stats.qza</span><br><span class="line"></span><br><span class="line">qiime feature-table summarize \</span><br><span class="line">  --i-table table.qza \</span><br><span class="line">  --o-visualization table.qzv</span><br></pre></td></tr></table></figure><h3 id="9-4-导入预合并的reads"><a href="#9-4-导入预合并的reads" class="headerlink" title="9.4 导入预合并的reads"></a>9.4 导入预合并的reads</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">wget https://data.qiime2.org/2018.8/tutorials/<span class="built_in">read</span>-joining/fj-joined.zip</span><br><span class="line">unzip fj-joined.zip</span><br><span class="line"></span><br><span class="line">qiime tools import \</span><br><span class="line">  --input-path fj-joined/manifest \</span><br><span class="line">  --output-path fj-joined-demux.qza \</span><br><span class="line">  --<span class="built_in">type</span> SampleData[JoinedSequencesWithQuality] \</span><br><span class="line">  --input-format SingleEndFastqManifestPhred33</span><br><span class="line"></span><br><span class="line">qiime demux summarize \</span><br><span class="line">  --i-data fj-joined-demux.qza \</span><br><span class="line">  --o-visualization fj-joined-demux.qzv</span><br></pre></td></tr></table></figure><h2 id="10-qiime2中的OTU聚类"><a href="#10-qiime2中的OTU聚类" class="headerlink" title="10 qiime2中的OTU聚类"></a>10 qiime2中的OTU聚类</h2><p>在qiime2中，de novo, closed-reference, open-reference clustering均已支持。在拆分序列、质控、去重复后，可以使用vsearch进行序列/特征聚类成OTUs。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://data.qiime2.org/2018.8/tutorials/otu-clustering/seqs.fna</span><br><span class="line">wget https://data.qiime2.org/2018.8/tutorials/otu-clustering/85_otus.qza</span><br><span class="line"></span><br><span class="line">qiime tools import \</span><br><span class="line">--input-path seqs.fna \</span><br><span class="line">--output-path seqs.qza \</span><br><span class="line">--<span class="built_in">type</span> <span class="string">'SampleData[Sequences]'</span></span><br></pre></td></tr></table></figure><h3 id="10-1-对序列进行去重复"><a href="#10-1-对序列进行去重复" class="headerlink" title="10.1 对序列进行去重复"></a>10.1 对序列进行去重复</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">qiime vsearch dereplicate-sequences \</span><br><span class="line">--i-sequences seqs.qza \</span><br><span class="line">--o-dereplicated-table table.qza \</span><br><span class="line">--o-dereplicated-sequences rep-seqs.qza</span><br></pre></td></tr></table></figure><h3 id="10-2-clustering"><a href="#10-2-clustering" class="headerlink" title="10.2 clustering"></a>10.2 clustering</h3><ul><li>de novo clustering</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">qiime vsearch cluster-features-de-novo \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--i-sequences rep-seqs.qza \</span><br><span class="line">--p-perc-identity 0.99 \</span><br><span class="line">--o-clustered-table table-dn-99.qza \</span><br><span class="line">--o-clustered-sequences rep-seqs-dn-99.qza</span><br></pre></td></tr></table></figure><ul><li>closed-reference clustering</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">qiime vsearch cluster-features-closed-reference \</span><br><span class="line">--i-table tablq.qza \</span><br><span class="line">--i-sequences rep-seqs.qza \</span><br><span class="line">--i-reference-sequences 85_otus.qza \</span><br><span class="line">--p-perc-identity 0.85 \</span><br><span class="line">--o-clustered-table table-cr-85.qza \</span><br><span class="line">--o-clustered-sequences  rep-seqs-cr-85.qza \</span><br><span class="line">--o-unmatched-sequences unmatched-cr-85.qza</span><br></pre></td></tr></table></figure><ul><li>open-reference clustering</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">qiime vsearch cluster-features-open-reference \</span><br><span class="line">--i-table tablq.qza \</span><br><span class="line">--i-sequences rep-seqs.qza \</span><br><span class="line">--i-reference-sequences 85_otus.qza \</span><br><span class="line">--p-perc-identity 0.85 \</span><br><span class="line">--o-clustered-table table-or-85.qza \</span><br><span class="line">--o-clustered-sequences  rep-seqs-or-85.qza \</span><br><span class="line">--o-new-reference-sequences new-ref-seqs-or-85.qza</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 扩增子 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>扩增子测序 mothur使用示例</title>
      <link href="/2018/10/15/%E6%89%A9%E5%A2%9E%E5%AD%90%E5%88%86%E6%9E%90-mothur%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/"/>
      <url>/2018/10/15/%E6%89%A9%E5%A2%9E%E5%AD%90%E5%88%86%E6%9E%90-mothur%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="1-初始说明"><a href="#1-初始说明" class="headerlink" title="1 初始说明"></a>1 初始说明</h2><ul><li>测序数据类型</li></ul><p>Illumina Miseq paired-end reads</p><ul><li>实验设计</li></ul><p>断奶后365天(dpw 365)的小鼠排泄物，比较初始10天(dpw 10)和中间10天(dpw140-150)的排泄物的微生物组的稳定性(肠道微生物组的变化情况)。为了简化操作，只用到一只小鼠的十个时间点(前5后5)的数据。这里还有模拟了由21种细菌组成的菌群的全基因组测序数据。先用小鼠的排泄物测序数据学习分析微生物群落，然后用模拟的菌落判断分析的错误率和它在其他分析中的作用。</p><ul><li>关于软件</li></ul><p>mothur既提供交互模式(像python)，也提供命令行模式；后者可以进行批量操作。</p><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解析模式一</span></span><br><span class="line">mothur <span class="comment"># 进入解析模式</span></span><br><span class="line">make.files(....)</span><br><span class="line">quit() <span class="comment"># 退出解析模式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令行模式</span></span><br><span class="line">mothur <span class="string">'#make.config(file=stability.files, processors=8)'</span></span><br><span class="line"><span class="comment"># 批量操作,把多个命令写入cmd.batch文件里</span></span><br><span class="line">mothur cmd.batch</span><br></pre></td></tr></table></figure><h2 id="2-进入mothur交互模式"><a href="#2-进入mothur交互模式" class="headerlink" title="2 进入mothur交互模式"></a>2 进入mothur交互模式</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mothur</span><br><span class="line">set.dir(tempdefault=MiSeq_SOP)</span><br><span class="line">set.dir(inputdir=MiSeq_SOP)</span><br><span class="line"><span class="built_in">help</span>(query_cmd)</span><br></pre></td></tr></table></figure><h2 id="3-stability-files"><a href="#3-stability-files" class="headerlink" title="3 stability.files"></a>3 stability.files</h2><p>这个文件记录了每个样品对应的read1和read2文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make.file(inputdir=MiSeq_SOP, <span class="built_in">type</span>=fastq, prefix=metadata)</span><br></pre></td></tr></table></figure><h2 id="4-序列合并和质控：减少测序和PCR错误"><a href="#4-序列合并和质控：减少测序和PCR错误" class="headerlink" title="4 序列合并和质控：减少测序和PCR错误"></a>4 序列合并和质控：减少测序和PCR错误</h2><p>使用make.configs合并序列,合并逻辑是先对两个reads比对，找到overlap；根据overla的base quality score，如果是base-gap，那么base的质量值要大于25才取base否则认为该位置没有base；如果是base-base，base的质量值要大于6才取base；否则置为N。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 合并序列</span></span><br><span class="line">make.contigs(file=metadata.files, processor=8)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.[fasta,qual]</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.scrap.contigs.[fasta, qual]</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.contigs.[report, groups]</span></span><br><span class="line"><span class="comment"># 2. 统计合并后的序列</span></span><br><span class="line">summary.seqs(fasta=metadata.trim.contigs.fasta)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.summary</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 筛选合并后的序列, 排除含有N和长度大于275的序列</span></span><br><span class="line">screen.seqs(fasta=metadata.trim.contigs.fasta, </span><br><span class="line">        summary=metadata.trim.contigs.summary, </span><br><span class="line">        group=metadata.contigs.groups, </span><br><span class="line">        maxambig=0, maxlength=275)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.contigs.[pick, good].groups</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.[good.summary, good.fasta, bad.accnos]</span></span><br></pre></td></tr></table></figure><h2 id="5-序列的去冗余"><a href="#5-序列的去冗余" class="headerlink" title="5 序列的去冗余"></a>5 序列的去冗余</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.去测序冗余</span></span><br><span class="line">unique.seqs(fasta=metadata.trim.contigs.good.fasta)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.[names, unique.fasta]</span></span><br><span class="line"><span class="comment"># 2.生成count矩阵</span></span><br><span class="line">count.seqs(name=metadata.trim.contigs.good.names, </span><br><span class="line">        group=metadata.contigs.good.groups)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.count_table</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.对count矩阵进行统计</span></span><br><span class="line">summary.seqs(fasta=metadata.trim.contigs.good.unique.fasta, </span><br><span class="line">        count=metadata.trim.contigs.good.count_table)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.summary</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.去非扩增区域冗余; 通过设置参考数据库中你的PCR扩增区域来去除非扩增区域的序列，以减少比对量</span></span><br><span class="line"><span class="comment">#   你可以使用oligos来指定primer文件进行去除，keepprimer</span></span><br><span class="line">pcr.seqs(fasta=../silva.bacteria/silva.bacteria.fasta, start=11894, end=25319, keepdots=F, processors=8)</span><br><span class="line"><span class="comment"># silva.bacteria/silva.bacteria.pcr.fasta</span></span><br><span class="line">rename.file(input=../silva.bacteria/silva.bacteria.pcr.fasta, new=silva.v4.fasta)</span><br><span class="line"><span class="comment"># MiSeq_SOP/silva.v4.fasta</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 对silva.v4.fasta进行统计</span></span><br><span class="line">summar.seqs(fasta=silva.v4.fasta)</span><br><span class="line"><span class="comment"># MiSeq_SOP/silva.v4.summary</span></span><br></pre></td></tr></table></figure><h2 id="6-序列的预聚类"><a href="#6-序列的预聚类" class="headerlink" title="6 序列的预聚类"></a>6 序列的预聚类</h2><p>要进行预聚类，我们需要先进行序列比对，获得相似序列。</p><h3 id="6-1-序列比对"><a href="#6-1-序列比对" class="headerlink" title="6.1 序列比对"></a>6.1 序列比对</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.比对并统计</span></span><br><span class="line">align.seqs(fasta=metadata.trim.contigs.good.unique.fasta, reference=silva.v4.fasta)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.align.['', report]</span></span><br><span class="line">summary.seqs(fasta=metadata.trim.contigs.good.unique.align,</span><br><span class="line">        count=metadata.trim.contigs.good.count_table)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.summary</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 根据比对统计结果，大部分序列比对在1968-11550, polymer最大为8；再进行一次筛选序列</span></span><br><span class="line">screen.seqs(fasta=metadata.trim.contigs.good.unique.align, count=metadata.trim.contigs.good.count_table, summary=metadata.trim.contigs.good.unique.summary, start=1968, end=11550, maxhomop=8)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.summary</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.align</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.accnos</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.good.count_table</span></span><br><span class="line">summary.seqs(fasta=current, count=current)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.summary</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 把比对结果中未必对上部分序列和表示gap的-去掉</span></span><br><span class="line">filter.seqs(fasta=metadata.trim.contigs.good.unique.good.align, vertical=T, trump=.)</span><br><span class="line"><span class="comment"># Length of filtered alignment: 376 </span></span><br><span class="line"><span class="comment"># Number of columns removed: 13049</span></span><br><span class="line"><span class="comment"># Length of the original alignment: 13425</span></span><br><span class="line"><span class="comment"># Number of sequences used to construct filter: 16299</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.fasta</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.filter</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 去冗余, 在上一步剪切序列时可能产生</span></span><br><span class="line">unique.seqs(fasta=metadata.trim.contigs.good.unique.good.filter.fasta, count=metadata.trim.contigs.good.good.count_table)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.count_table</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.unique.fasta</span></span><br></pre></td></tr></table></figure><h3 id="6-2-预聚类"><a href="#6-2-预聚类" class="headerlink" title="6.2 预聚类"></a>6.2 预聚类</h3><p>这里使用pre.cluster进行预聚类。它首先根据group对序列分组，然后依据序列丰度进行排序，最后把差异在2个核苷酸及以内的序列进行合并。一般是100bp取1个核苷酸的差异,这里的序列长度是250左右，所以为2。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pre.cluster(fasta=metadata.trim.contigs.good.unique.good.filter.unique.fasta, count=metadata.trim.contigs.good.unique.good.filter.count_table, diffs=2)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.unique.precluster.[SampleID].map</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.unique.precluster.[fasta,count_table]</span></span><br></pre></td></tr></table></figure><h2 id="7-去除嵌合体-chimeras"><a href="#7-去除嵌合体-chimeras" class="headerlink" title="7 去除嵌合体 chimeras"></a>7 去除嵌合体 chimeras</h2><p>chimera.vsearch将会把数据按样品分组，检测嵌合体的存在。我们倾向于使用高丰度序列作为reference。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 检测嵌合体序列；输出的count_table依据去除了</span></span><br><span class="line">chimera.vsearch(fasta=metadata.trim.contigs.good.unique.good.filter.unique.precluster.fasta,</span><br><span class="line">        count=metadata.trim.contigs.good.unique.good.filter.unique.precluster.count_table, </span><br><span class="line">        dereplicate=T)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.[pick.count_table, chimeras,accnos]</span></span><br><span class="line"><span class="comment"># 2. 去除嵌合体序列</span></span><br><span class="line">remove.seqs(fasta=metadata.trim.contigs.good.unique.good.filter.unique.precluster.fasta,</span><br><span class="line">        accnos=metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.accnos)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.fasta</span></span><br><span class="line"><span class="comment"># 3. 统计</span></span><br><span class="line">summary.seqs(fasta=current, count=current)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.summary</span></span><br></pre></td></tr></table></figure><h2 id="8-进行聚类（分类）"><a href="#8-进行聚类（分类）" class="headerlink" title="8 进行聚类（分类）"></a>8 进行聚类（分类）</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 分类</span></span><br><span class="line">classify.seqs(fasta=metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.fasta,</span><br><span class="line">        count=metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.count_table,</span><br><span class="line">        reference=../trainset9_032012.pds.fasta, </span><br><span class="line">        taxonomy=trainset9_032012.pds.tax, cutoff=80)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.[taxonomy, tax.summary]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 去除污染; 这里的unknown是在上一步分类时无法根据训练集和准确进行准确分类的一类</span></span><br><span class="line">remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.taxonomy</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.count_table</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 统计</span></span><br><span class="line">summary.tax(taxonomy=current, count=current)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.tax.summary</span></span><br></pre></td></tr></table></figure><h2 id="9-检测错误率"><a href="#9-检测错误率" class="headerlink" title="9 检测错误率"></a>9 检测错误率</h2><p>如果你在测序的时候有一些模拟群落的数据的话，你就可以检测一下你的数据的错误率。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 提取出mock的分组</span></span><br><span class="line">get.groups(count=current, fasta=current, groups=Mock)</span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.pick.count_table</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.fasta</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 检测错误率</span></span><br><span class="line">seq.error(fasta=current, count=current, reference=HMP_MOCK.v35.fasta, aligned=F)</span><br><span class="line"><span class="comment"># Overall error rate:6.5108e-05</span></span><br><span class="line"><span class="comment"># MiSeq_SOP/metadata.trim.contigs.good.unique.good.filter.unique.</span></span><br><span class="line"><span class="comment"># precluster.pick.pick.pick.error.[summary,seq,chimera,seq.forward, seq.reverse, count, matrix, ref]</span></span><br></pre></td></tr></table></figure><h2 id="10-生成Mock-OTUs"><a href="#10-生成Mock-OTUs" class="headerlink" title="10 生成Mock OTUs"></a>10 生成Mock OTUs</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 计算距离</span></span><br><span class="line">dist.seqs(fasta=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.fasta,</span><br><span class="line">    cutoff=0.03)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.dist</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.进行聚类</span></span><br><span class="line">cluster(column=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.dist,</span><br><span class="line">    count=metadata.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.pick.count_table)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.[list, steps, sensspec]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 生成shared文件</span></span><br><span class="line">make.shared(list=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.list,</span><br><span class="line">    count=metadata.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.pick.count_table, </span><br><span class="line">    label=0.03)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.shared</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 稀释</span></span><br><span class="line">rarefaction.single(shared=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.shared)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.groups.rarefaction</span></span><br></pre></td></tr></table></figure><h2 id="11-准备分析"><a href="#11-准备分析" class="headerlink" title="11 准备分析"></a>11 准备分析</h2><p>接下来我们有2件事要做。第一件就是把序列与OTU对应起来，第二件是把序列和系统发育表型对应起来。<br>当前我们需要把mock数据从我们的数据集里面去掉。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">remove.groups(fasta=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.fasta,</span><br><span class="line">    count=metadata.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.count_table,</span><br><span class="line">    taxonomy=metadata.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.taxonomy, </span><br><span class="line">    groups=Mock)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.fasta</span></span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.pick.count_table</span></span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.pick.taxonomy</span></span><br></pre></td></tr></table></figure><h2 id="12-生成OTUs"><a href="#12-生成OTUs" class="headerlink" title="12 生成OTUs"></a>12 生成OTUs</h2><p>对于较小的数据集，可以使用dist.seqs和cluster来进行，就像前面Mock OTUs一样。 对于大的数据集，使用cluster.split。在该方法中，会先根据分类信息对序列进行分箱，然后在各个箱内进行聚类。对于指定的分类水平，可以通过指定taxlevel=level来实现。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 生成OTUs</span></span><br><span class="line"><span class="comment"># dist.seqs + cluster</span></span><br><span class="line">dist.seqs(fasta=curent, count=current)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.dist</span></span><br><span class="line"></span><br><span class="line">cluster(column=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.dist, count=current)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.[list,steps,sensspec]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cluster.split</span></span><br><span class="line">cluster.split(fasta=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.fasta,</span><br><span class="line">    count=metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.pick.count_table,</span><br><span class="line">    taxonomy=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.pick.taxonomy, </span><br><span class="line">    splitmethod=classify, cutoff=0.03, taxlevel=4)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.[list,steps,sensspec]</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2. 生成shared文件(每个样品为行，每个OTU为列，OTU数目矩阵)</span></span><br><span class="line">makd.shared(list=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.list,</span><br><span class="line">    count=metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.pick.count_table, </span><br><span class="line">    label=0.03)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.shared</span></span><br></pre></td></tr></table></figure><p>然后使用classify.otu给每个OTU同对应的物种分类联系起来。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3. otu被观察到的次数（OTU丰度）和对应的物种分类信息</span></span><br><span class="line">classify.otu(list=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.list,</span><br><span class="line">    count=metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.pick.count_table, </span><br><span class="line">    label=0.03)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.</span></span><br><span class="line"><span class="comment"># pick.pick.pick.opti_mcc.0.03.cons.[taxonomy, tax.summary]</span></span><br></pre></td></tr></table></figure><h2 id="13-生成phylotypes-系统发育表型信息"><a href="#13-生成phylotypes-系统发育表型信息" class="headerlink" title="13 生成phylotypes 系统发育表型信息"></a>13 生成phylotypes 系统发育表型信息</h2><p>你可以使用phylotype来对序列按照他们的物种分类分箱成系统发育表型。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 生成系统发育表型表</span></span><br><span class="line">phylotype(taxnomy=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.taxonomy)<span class="comment"># current</span></span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.</span></span><br><span class="line"><span class="comment"># precluster.pick.pds.wang.pick.pick.tx.[sabund, rabund, list]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 生成shared文件，这里生成level6，genus的;这里设置label是从1-7对应着genus-kingdom</span></span><br><span class="line">make.shared(list=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.pick.tx.list,</span><br><span class="line">    count=metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.pick.count_table,</span><br><span class="line">    label=1)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.pick.tx.shared</span></span><br><span class="line"><span class="comment"># label   Group   numOtus Otu01   Otu02   Otu03   Otu04</span></span><br><span class="line"><span class="comment"># 1       F3D0    62      1663    2626    216     57</span></span><br><span class="line"><span class="comment"># 1       F3D1    62      1959    1249    246     35</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 生成OTU丰度、对应的物种分类信息</span></span><br><span class="line">classify.otu(list=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pds.wang.pick.pick.tx.list,</span><br><span class="line">    count=metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.pick.count_table, </span><br><span class="line">    label=1)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.</span></span><br><span class="line"><span class="comment"># precluster.pick.pds.wang.pick.pick.tx.1.cons.[taxonomy,tax.summary]</span></span><br><span class="line"><span class="comment"># OTU     Size    Taxonomy</span></span><br><span class="line"><span class="comment"># Otu01   22183   Bacteria(100);...;Lachnospiraceae_unclassified(100);</span></span><br><span class="line"><span class="comment"># Otu02   54221   Bacteria(100);...;"Porphyromonadaceae"_unclassified(100);</span></span><br></pre></td></tr></table></figure><h2 id="14-生成系统发育树"><a href="#14-生成系统发育树" class="headerlink" title="14 生成系统发育树"></a>14 生成系统发育树</h2><p>我们可以使用clearcut来生成系统发育树，它既可以以比对后的序列作为输入，也可以以序列距离来作为输入。这里以序列距离作为输入。如果以比对后的序列作为输入，你需要指定序列是DNA还是蛋白。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 计算距离; fasta和计算OTUs的是一致的</span></span><br><span class="line">dist.seqs(fasta=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.fasta, </span><br><span class="line">        output=lt, processors=8)</span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.phylip.dist</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 生成树</span></span><br><span class="line">clearcut(phylip=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.phylip.dist)<span class="comment"># current</span></span><br><span class="line"><span class="comment"># metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.phylip.tre</span></span><br></pre></td></tr></table></figure><h2 id="15-准备分析-OTU-based"><a href="#15-准备分析-OTU-based" class="headerlink" title="15 准备分析: OTU-based"></a>15 准备分析: OTU-based</h2><p>下面我们要进行基于OTU的分析，基于phylotype的分析也是一样的操作. 为了简化，我们要把current的各个相关的默认参数指定为OTU的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里这样设置后，...0.03.cons.taxonomy就成了metadata.taxonomy</span></span><br><span class="line">rename.files(taxonomy=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.0.03.cons.taxonomy,</span><br><span class="line">    shared=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.opti_mcc.shared)</span><br></pre></td></tr></table></figure><p>如果要知道每个样品有多少条序列，可以这么做. 然后对样品进行稀释抽样</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 对序列进行分组计数；得到样品的最小总序列数是2390</span></span><br><span class="line">count.groups(shared=metadata.opti_mcc.shared)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.count.summary</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 进行稀释抽样，抽样大小是2390</span></span><br><span class="line">sub.sample(shared=metadata.opti_mcc.shared, size=2390)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.shared</span></span><br></pre></td></tr></table></figure><h2 id="16-基于OTU的分析-alpha-diversity"><a href="#16-基于OTU的分析-alpha-diversity" class="headerlink" title="16 基于OTU的分析: alpha diversity"></a>16 基于OTU的分析: alpha diversity</h2><ul><li>稀释曲线</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成的稀释表，需要你自己去画图</span></span><br><span class="line"><span class="comment"># calc指定计算哪个alpha diversity index, 有多个的话，sobs-chao-ace</span></span><br><span class="line"><span class="comment">#  ace, bootstrap, chao, coverage, default, heip, invsimpson, jack, npshannon, nseqs, shannon, shannoneven, shannonrange, simpson, simpsoneven, smithwilson, sobs</span></span><br><span class="line">rarefection.single(shared=metadata.opti_mcc.shared, calc=sobs, freq=100)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.groups.rarefaction</span></span><br></pre></td></tr></table></figure><ul><li>生成一个含序列数目、sample converage, observed OTUs, inverse simpson diversity estimation的表</li></ul><p>基于这里的ave-std.summary，你还可以进行repeated-measures ANOVA进行分组的组间差异比较</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">summary.single(shared=metadata.opti_mcc.shared, calc=nseqs-coverage-sobs-invsimpson, subsample=2390)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.groups.ave-std.summary</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.groups.summary</span></span><br></pre></td></tr></table></figure><h2 id="17-基于OTU的分析-beta-diversity"><a href="#17-基于OTU的分析-beta-diversity" class="headerlink" title="17 基于OTU的分析: beta diversity"></a>17 基于OTU的分析: beta diversity</h2><p>现在我们要比较样品的关系和组成了。</p><ul><li>OTU 相对丰度热图</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 你可以直接使用metadata.opti_mcc.0.03.subsample.shared在R里面画热图</span></span><br><span class="line">heatmap.bin(shared=metadata.opti_mcc.0.03.subsample.shared, scale=log2, numotu=50)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.0.03.heatmap.bin.svg</span></span><br></pre></td></tr></table></figure><ul><li>计算样品的关系和组成相似性</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dist.shared(shared=metadata.opti_mcc.shared, calc=thetayc-jclass, subsample=2390)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.thetayc.0.03.lt.[dist, ave.dist,std.dist]</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.jclass.0.03.lt.[dist, ave.dist,std.dist]</span></span><br><span class="line"></span><br><span class="line">heatmap.sim(calc=jcalss-thetayc)</span><br><span class="line"><span class="comment">#heatmap.sim(phylip=metadata.opti_mcc.jclass.0.03.lt.ave.dist)</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.thetayc.0.03.lt.ave.heatmap.sim.svg</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.jclass.0.03.lt.ave.heatmap.sim.svg</span></span><br></pre></td></tr></table></figure><ul><li>venn图</li></ul><p>当组别在5以内时，利用veen才方便。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用生成的.sharedotus到R里面画图</span></span><br><span class="line">venn(shared=metadata.opti_mcc.0.03.subsample.shared, groups=F3D0-F3D1-F3D2-F3D3)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.0.03.sharedsobs.F3D0-F3D1-F3D2-F3D3.svg</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.0.03.sharedsobs.F3D0-F3D1-F3D2-F3D3.sharedotus</span></span><br></pre></td></tr></table></figure><ul><li>系统发育树</li></ul><p>这里利用tree.shared来画系统发育树，以可视化样品之间的相似性。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里选择jclass</span></span><br><span class="line">tree.shared(phylip=metadata.opti_mcc.jclass.0.03.lt.ave.dist)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.jclass.0.03.lt.ave.tre</span></span><br></pre></td></tr></table></figure><ul><li>基于系统发育树的差异比较</li></ul><p>parsimony, unifrac.unweighted, unifrac.weighted.<br>我们需要构建一个design文件，以指示那个样品属于哪个组；然后进行计算</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parsimony(tree=metadata.opti_mcc.jclass.0.03.lt.ave.tre, group=mouse.time.desin, groups=all)</span><br><span class="line"><span class="comment"># Tree#   Groups  ParsScore       ParsSig</span></span><br><span class="line"><span class="comment"># 1       Early-Late      1       &lt;0.001</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.jclass.0.03.lt.ave.tre.parsimony</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.jclass.0.03.lt.ave.tre.psummary</span></span><br></pre></td></tr></table></figure><ul><li>PCoA和nmds分析/可视化</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pcoa(phylip=metadata.opti_mcc.jclass.0.03.lt.ave.dist)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.jclass.0.03.lt.ave.pcoa.[axes, loadings]</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.jclass.0.03.lt.ave.pcoa.loadings</span></span><br><span class="line"></span><br><span class="line">nmds(phylip=metadata.opti_mcc.jclass.0.03.lt.ave.dist)</span><br><span class="line"><span class="comment"># Number of dimensions:   2</span></span><br><span class="line"><span class="comment"># Lowest stress : 0.142764</span></span><br><span class="line"><span class="comment"># R-squared for configuration:    0.918996</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.thetayc.0.03.lt.ave.nmds.[iters, stress, axes]</span></span><br></pre></td></tr></table></figure><ul><li>AMOVA分析/HOMOVA分析</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">amova(phylp=metadata.opti_mcc.thetayc.0.03.lt.ave.dist, design=mouse.time.design)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.thetayc.0.03.lt.ave.amova</span></span><br><span class="line"></span><br><span class="line">homova(phylip=metadata.opti_mcc.thetayc.0.03.lt.ave.dist, design=mouse.time.desin)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.thetayc.0.03.lt.ave.homova</span></span><br></pre></td></tr></table></figure><ul><li>核心OTU分析：导致差异的OTU</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成的corr.axes文件可用biplot图可视化</span></span><br><span class="line">corr.axes(axes=metadata.opti_mcc.jclass.0.03.lt.ave.pcoa.axes, </span><br><span class="line">        shared=metadata.opti_mcc.0.03.subsample.shared, </span><br><span class="line">        method=spearman, numaxes=3)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.spearman.corr.axes</span></span><br><span class="line"></span><br><span class="line">corr.axes(axes=metadata.opti_mcc.jclass.0.03.lt.ave.pcoa.axes, </span><br><span class="line">        metadata=mouse.dpw.metadata, </span><br><span class="line">        method=spearman, numaxes=3)</span><br><span class="line"><span class="comment"># mouse.dpw.spearman.corr.axes</span></span><br></pre></td></tr></table></figure><ul><li>是否可以将数据分成不同的群落类型？</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 得到的表Laplace最小值对应k=2。所以可以分为2个类型</span></span><br><span class="line">get.communitytype(shared=metadata.opti_mcc.0.03.subsample.shared)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.0.03.dmm.mix.fit</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.0.03.dmm.[1-5].mix.posterior</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.0.03.dmm.[1-5].mix.relabund</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.0.03.dmm.mix.design，指明各个样品所属类型</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.0.03.dmm.mix.parameters</span></span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.0.03.dmm.mix.summary，指明主要是哪个OTU导致的分类型</span></span><br></pre></td></tr></table></figure><h2 id="18-群体水平的分析"><a href="#18-群体水平的分析" class="headerlink" title="18 群体水平的分析"></a>18 群体水平的分析</h2><ul><li>metastats</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">metastats(shared=metadata.opti_mcc.0.03.subsample.shared, </span><br><span class="line">        design=mouse.time.design)</span><br><span class="line"><span class="comment"># metadata.opti_mcc.0.03.subsample.0.03.Late_Early.metastats</span></span><br></pre></td></tr></table></figure><ul><li>lefse</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lefse(shared=metadata.opti_mcc.0.03.subsample.shared, design=mouse.time.design)</span><br></pre></td></tr></table></figure><h2 id="19-基于系统发育的分析-phylogeny-based-analysis"><a href="#19-基于系统发育的分析-phylogeny-based-analysis" class="headerlink" title="19 基于系统发育的分析 phylogeny-based analysis"></a>19 基于系统发育的分析 phylogeny-based analysis</h2><h3 id="19-1-alpha-diversity"><a href="#19-1-alpha-diversity" class="headerlink" title="19.1 alpha diversity"></a>19.1 alpha diversity</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rename.file(tree=metadata.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.pick.phylip.tre)</span><br><span class="line">rename.file(count=metadata.trim.contigs.good.unique.good.filter.unique.precluster.denovo.vsearch.pick.pick.pick.count_table)</span><br><span class="line">phylo.diversity(tree=metadata.tre, count=metadata.count_table, rarefy=T)</span><br><span class="line"><span class="comment"># metadata.1.phylodiv.summary</span></span><br><span class="line"><span class="comment"># phylodiv.rarefaction</span></span><br></pre></td></tr></table></figure><h3 id="19-2-beta-diversity"><a href="#19-2-beta-diversity" class="headerlink" title="19.2 beta diversity"></a>19.2 beta diversity</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成.ave.dist是距离矩阵，可以像OTU-based analysis那样进行分析那些PCOA之类的。</span></span><br><span class="line">unifrac.unweighted(tree=metadata.tre, count=metadata.count_table, distance=lt, processors=2, random=F, subsample=2390)</span><br><span class="line">unifrac.weighted(tree=metadata.tre, count=metadata.count_table, distance=lt, processors=2, random=F, subsample=2390)</span><br><span class="line"><span class="comment"># metadata.uwsummary</span></span><br><span class="line"><span class="comment"># metadata.1.unweighted.ave.dist</span></span><br><span class="line"><span class="comment"># metadata.1.unweighted.std.dist</span></span><br><span class="line"><span class="comment"># metadata.tre1.unweighted.phylip.dist</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 扩增子 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>扩增子测序 理论基础</title>
      <link href="/2018/10/15/%E6%89%A9%E5%A2%9E%E5%AD%90%E6%B5%8B%E5%BA%8F-%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"/>
      <url>/2018/10/15/%E6%89%A9%E5%A2%9E%E5%AD%90%E6%B5%8B%E5%BA%8F-%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="一、-基础概念"><a href="#一、-基础概念" class="headerlink" title="一、 基础概念"></a>一、 基础概念</h2><p><img src="https://media.nature.com/full/nature-assets/nrurol/journal/v12/n2/images/nrurol.2014.361-f1.jpg" alt="microbiota, microbiome, metagenome"></p><a id="more"></a><h3 id="1-1-微生物群-microbiota"><a href="#1-1-微生物群-microbiota" class="headerlink" title="1.1 微生物群,  microbiota"></a>1.1 微生物群,  microbiota</h3><p>16s rRNA surveys are used to taxonomically identify the microorganisms in the environment. A microbiota is an “ecological community of commensal, symbiotic and pathogenic microorganisms” found in and on all multicellular organisms studied to date from plants to animals. 从方法上看，采用16s rRNA的研究方法从分类上对环境中的微生物进行研究，这一过程称为微生物组。从宿主上看，微生物组研究的是动植物体上共生或者病理性的微生物生态群体。这其中包含细菌、古菌、原生动物、真菌和病毒，他们在宿主的免疫、代谢、激素等方面作用巨大。microbiota侧重的是鉴定微生物种类。</p><h3 id="1-2-宏基因组-metagenome"><a href="#1-2-宏基因组-metagenome" class="headerlink" title="1.2 宏基因组, metagenome"></a>1.2 宏基因组, metagenome</h3><p>The genes and genomes of the microbiota, including plasmids, highlighting the genetic potential of the population. 宏基因组也称微生物环境基因组或者元基因组，指生境中群补微小遗传物质的总和，包含可培养和当前不可培养的微生物基因组。也就是说，宏基因组可以认为是微生物中的基因和基因组的总称，强调群体中基因的遗传潜在性。目前主要指环境样品中的细菌和真菌基因组的总和。</p><h3 id="1-3-微生物组-microbiome"><a href="#1-3-微生物组-microbiome" class="headerlink" title="1.3 微生物组, microbiome"></a>1.3 微生物组, microbiome</h3><p>Microbiome, the synonymous term of microbiota, describes either the collective genomes of the microorganisms that reside in an environmental niche or the microorganisms themselves. 与microbiota意思相近，但更加偏向与从环境整体中的基因和基因组入手研究，偏向的是环境中所有的基因和基因组。</p><h3 id="1-4-分类单元"><a href="#1-4-分类单元" class="headerlink" title="1.4 分类单元"></a>1.4 分类单元</h3><p>分类单元指分类学中的各个分类级别，从大的级别讲，分为七级，就是我们常说的界(kingdom),门(phylum, 亚门),纲(class,总纲,亚纲),目(order,总目,亚目),科(familay,总科,亚科),属(genus,亚属),种(species,变种). 也有用非七以外的多级分类。在对新种进行命名时，常使用双命名法：属名加上种名加词，如果有新种/属的话,则在种属缩写后添加.nov表示，如sp.nov表示新种.</p><h3 id="1-5-微生物组研究的科学问题"><a href="#1-5-微生物组研究的科学问题" class="headerlink" title="1.5 微生物组研究的科学问题"></a>1.5 微生物组研究的科学问题</h3><table><thead><tr><th>组学</th><th>目的</th><th>组学</th><th>目的</th></tr></thead><tbody><tr><td>培养组学</td><td>什么菌可以培养</td><td>扩增子</td><td>微生物组的种群组成及其成分的相对丰度</td></tr><tr><td>宏基因组</td><td>微生物组中有什么功能基因</td><td>宏转录组</td><td>有哪些基因表达了</td></tr><tr><td>宏病毒组</td><td>有哪些DNA/RNA病毒</td><td>宏蛋白组</td><td>有哪些基因翻译成蛋白</td></tr><tr><td>宏代谢组</td><td>有哪些种类的代谢产物</td><td>宏表观组</td><td>有哪些表观修饰</td></tr><tr><td>单菌基因组</td><td>目标菌有哪些基因</td><td>泛基因组</td><td>某种菌与亲缘菌之间的异同 </td></tr></tbody></table><h3 id="1-6-扩增子测序"><a href="#1-6-扩增子测序" class="headerlink" title="1.6 扩增子测序"></a>1.6 扩增子测序</h3><p>原核生物如细菌的rRNA分类经常会根据rRNA的沉降系数进行，分别为5s, 16s, 23s rRNA. 其中16s rRNA是核糖体RNA的一个亚基，16s rDNA是编码该亚基的基因，其长度约为1.5kb。它是细菌的系统分类研究中最为有用和常用的分子钟，种类少，含量多，大小适中，在结构与功能上具有高度保守性。类似地，真核生物生物的rRNA分为4类，5s，5.8s，18s，28s rRNA，其中18s与16s大小相近，作用类似。在真核生物中核糖体DNA由ETS(外部转录间隔区),18s gene, ITS1(内部转录间隔区1), 5.8s gene, ITS2, 28s gene和IGS(基因间隔序列)组成, 在进化中，18s，5.8s，28s较为保守, ITS变化性较大。所以可以选择ITS鉴别不同种类。</p><p>扩增子测序就是针对原核生物的16s、真核生物的18s/ITS区域设计引物扩增目标区域，产物就是扩增子，然后对扩增子进行测序，基于测序数据的分析结果对扩增子进行微生物组成分析或其他目的。</p><h3 id="1-7-OTUs"><a href="#1-7-OTUs" class="headerlink" title="1.7 OTUs"></a>1.7 OTUs</h3><p>OTUs，operational taxonomic units, 操作分类单元，是在系统发生学研究或群体遗传学研究中，为了便于进行分析，人为给某一个分类单元设置的同一标志。在生物信息分析中，一般来说，测序得到的每一条序列来自一个菌。要了解一个样品测序结果中的菌种、菌属等数目信息，需要对序列进行聚类（cluster）。OTU的聚类方法很多，如Uclust，cd-hit，BLAST，mothur，usearch，prefix/suffix等，均可在QIIME实现。通过聚类，把序列按照彼此的相似性（97%）分归为许多小组，一个小组就是一个OTU。在实际归类时，算法通过一定的距离度量方法计算两两不同序列之间的距离度量火相似性，继而设定特定的分类阈值（97%），获得同一阈值下的距离矩阵，进行聚类操作，形成不同的分类单元。在聚类完成后，通常会选择OTU中丰度最高的序列作为代表序列。使用该代表序列与RDP、Sliva、GreenGene等数据库比对，进行物种注释。但是，OTU聚类只是低分辨率的分析方法，它的分析只能到属的水平；OTU也无法与具体的菌对应；不同批次的实验结果无法比较。 由于高通量测序获得的16s rDNA序列非常多，无法对每条序列都进行物种注释；引入OTU的话，基于分类单元进行后续的物种注释可以简化工作量、提高分析效率和准确性。</p><h3 id="1-8-扩增子分析的公共数据库"><a href="#1-8-扩增子分析的公共数据库" class="headerlink" title="1.8 扩增子分析的公共数据库"></a>1.8 扩增子分析的公共数据库</h3><p>对于扩增子数据库来说，一般要求两点：第一是数据库内步的序列要完整，非冗余的序列是越多越好；第二是注释信息要准确。目前有多种数据库可供选择，应该根据扩增子种类不同选择相应数据库，数据库介绍如下。</p><h4 id="1-8-1-rRNA基因数据库"><a href="#1-8-1-rRNA基因数据库" class="headerlink" title="1.8.1 rRNA基因数据库"></a>1.8.1 rRNA基因数据库</h4><ul><li><p><strong>RDP</strong> 全称‘ribosomal database project’，隶属于密歇根州立大学，包含数据库和分析工具两个部分。前者提供高质量、已注释的细菌、古菌16s rRNA基因和真菌28s rRNA基因序列。</p></li><li><p><strong>Silva</strong> 一个rRNA基因序列的综合数据库，收录原核和真核微生物的各个亚基rRNA基因序列（SSU，即16和18s rRNA；LSU，23s和28s rRNA），该数据库最大最全，也就意味着假阳性率可能会偏高。该数据库的物种注释采用的是14级，而非常用的7级注释，彼此不能转换比较。</p></li><li><p><strong>NCBI taxdmp</strong> 由于NCBI数据比较乱，假阳性率或错误比较多，需要你仔细甄别。注释时需要将序列blast到ncbi的NR的核酸火蛋白数据库中，得到相似序列后，根据该序列的GI号转成Taxonomy( <a href="http://mp.weixin.qq.com/s/v2ktKQi0C1soQ6_j4xeLWQ" target="_blank" rel="noopener">http://mp.weixin.qq.com/s/v2ktKQi0C1soQ6_j4xeLWQ</a> )</p></li><li><p><strong>GreenGene</strong> 较为有名的16s物种数据库，人工整理，较为准确，分类采用常用的七级（界门纲目科属种）。PICRUSt基于该数据库，QIIME的默认数据库。</p></li><li><p><strong>EzBioCloud</strong> 与Greengenes数据库类似，专门针对细菌、古菌16s rRNA基因的数据库，其特点是以可培养的细菌、古菌为主。</p></li><li><p><strong>PR2</strong> 针对18s 测序分析比较好用的数据库。</p></li><li><p><strong>PhytoREF</strong> 针对质体(plastid)中16s rRNA基因的数据库，包括陆地植物、海洋、淡水的大型和微型藻类等含质体生物。</p></li><li><p><strong>PFR2</strong> 专门针对浮游有孔虫界18SrRNA基因的数据库。</p></li></ul><h4 id="1-8-2-ITS序列数据库"><a href="#1-8-2-ITS序列数据库" class="headerlink" title="1.8.2 ITS序列数据库"></a>1.8.2 ITS序列数据库</h4><ul><li><p><strong>UNITE</strong> 该数据库是专门针对真菌ITS序列（含ITS1和2区）最全最好的数据库。</p></li><li><p><strong>ITS2</strong> ITS2专门真核微生物ITS2序列的数据库。</p></li></ul><h4 id="1-8-3-功能基因数据库"><a href="#1-8-3-功能基因数据库" class="headerlink" title="1.8.3 功能基因数据库"></a>1.8.3 功能基因数据库</h4><ul><li><p><strong>FunGene</strong> 该数据库是RDP延伸的一个针对微生物功能基因序列的数据库。按照功能分为抗生素抗性、植物致病基因、生物地球化学循环、系统进化标志、生物降解、金属循环及其他七个类别。可用于功能marker基因高通量促销后的比对、功能基因引物设计等用途。</p></li><li><p><strong>ARDB</strong> 主要包含细菌、病原菌的多种抗性基因数据，结合GO、KEGG等信息，通过该数据库的注释，可以找到耐药性相关基因的名称，所耐受的抗生素种类等信息。核心功能主要分为：基因信息查询、序列比对注释以及同源序列对比。</p></li><li><p><strong>CARD</strong> 包含了ARDB数据库中所有的抗性信息。CARD以Antibiotic Resistance Ontology（ARO）为分类单位的形式所构建，其中ARO是数据库所构建term，用于关联抗生素模块及其目标、抗性机制、基因变异等信息。同时，数据库还针对ARO的功能，专门开发了一款名为Resistance Gene Identifier（RGI）的软件程序， 用于基因组数据的抗性基因预测。</p></li></ul><h2 id="二、增子的分析类别"><a href="#二、增子的分析类别" class="headerlink" title="二、增子的分析类别"></a>二、增子的分析类别</h2><p>在1972年，Whittaker提出了微生物多样性的三个种类:</p><ul><li>α多样性，某个群落或生境内部的物种的多样性</li><li>β多样性，在一个梯度上，从一个生境到另一个生境所发生的种的多样性变化的速率和范围，研究群落之间的种多度关系</li><li>γ多样性，在一个地理区域内一系列生境中种的多样性，是α和β多样性的综和。γ = α * β。</li></ul><h3 id="2-1-α多样性"><a href="#2-1-α多样性" class="headerlink" title="2.1 α多样性"></a>2.1 α多样性</h3><p>alpha diversity，α多样性指在给定的一个微生物群落中微生物组成的多样性，通常以该群落中微生物种类的数量和各个种类的相对丰度来表示，它反映着群落内物种间通过竞争资源火利用同种生境而共产生的共存结果。alpha多样性是相对于样本本身来说的，一个样本就可以计算alpha多样性。而alpha diversity index，α多样性指数则是用来度量α多样性的一种测量。目前α多样性指数包含三类：</p><ul><li>物种丰富度指数: 物种种的多少（数目），用统计数Margalef、Menhinick丰富度指数、chao1指数进行表征</li><li>物种均匀度指数：各个种的相对密度，用统计数Pielou、Sheldon、hill、heip、Alatalo均匀度指数进行表征</li><li>物种多样性指数；用统计数shannon-wienner、SimpsonHill多样性指数或者种间相遇概率（PIE）进行表征</li></ul><h4 id="2-1-1-chao1指数"><a href="#2-1-1-chao1指数" class="headerlink" title="2.1.1 chao1指数"></a>2.1.1 chao1指数</h4><p>S1=Sobs + (singleton^2) / (doblueton^2)。</p><p>由于测序深度有限，不可能把一个样本的所有物种都测出来，那么就需要通过‘预估’每个样本中的所有物种种类，才能准确比较样品之间的α多样性。chao1则可以用于估算样品物种总量的计算值。Chao1的意义是，在对群落样本进行抽样的时候，如果还有没被发现的新物种，那么抽样中会一直发现Singleton。直到不再观察到Singleton的时候（也就是观察到的某物种的数目至少为2），可以认为此时的物种数目观察值为样本的理论最高值。因此，Chao1是主要利用Singleton和Doubleton来判断群落的物种丰富度，它对单个物种的变化更为敏感。它的数值越大，表示物种种类越多。</p><h4 id="2-1-2-ACE指数"><a href="#2-1-2-ACE指数" class="headerlink" title="2.1.2 ACE指数"></a>2.1.2 ACE指数</h4><p>Sace = Scommon + Srare / Cace + F1 / Cace * γace^2, Scommon是样本中出现超过10次的物种的数目；Srare是出现不多于10次的物种的数目，Cace=1-(F_1/n_race)表示所有低丰度（出现&lt;=10次）的物种中非singleton的比例, γace^2是变异系数。</p><p>ACE指数也是用于估算样本物种丰度的指数。ACE指数是通过Singleton和稀有物种(出现&lt;=10次)来估算还有多少没被发现的物种。为什么会介入稀有物种这么一个概念？其中一个重要原因是，在实际生态学分析中，低丰度的物种（如doubleton）很容易随着测量的误差错误而产生，而稀有物种的测量则相对稳定，因此在计算上更容易排除测序误差等干扰。当测序中singleton的比例越大，ACE值越大，样本的真实物种种类越多。</p><h4 id="2-1-3-Shannon指数"><a href="#2-1-3-Shannon指数" class="headerlink" title="2.1.3 Shannon指数"></a>2.1.3 Shannon指数</h4><p>H = - sum( Percent(i) * log2(Percent(i)) )</p><p>香浓指数常用于盒形图分析，稀释曲线分析等分析条目当中。Shannon指数与Chao1和ACE两个指数不一样，Chao1和ACE主要用于计算物种的丰富度（Richness），更在乎样本是否有这个物种。而Shannon指数不只关心物种丰富度，而且同时关心物种的均匀度（Evenness），所以是对群落结构的更综合性的反应。例如在群落丰富度一致时，群落均匀度更低的群落香浓指数更低，α多样性也就更低。</p><h4 id="2-1-4-Simpson指数"><a href="#2-1-4-Simpson指数" class="headerlink" title="2.1.4 Simpson指数"></a>2.1.4 Simpson指数</h4><p>D = 1 - Sum( Probablity(i) ^ 2 )</p><p>Simpson指数本质也是综合考虑样本中物种的丰富度与均匀度，它是在1949年由Edward H. Simpson提出来。具体理念是，在足够大的样本中，有放回地先后抽取两个样本，这两个样本是同一个种的概率是多少？其实答案很简单，假如我们已知Pi是样品中属于第 i 种的个体的比例，那么抽取到两个都是种 i 的概率是   。基于这个理念，如果我们将所有物种的概率相加，就得到Simpson指数。在应用时，上述公式常有变体，比如没有使用1-，或者使用的是1/。所以具体的Simpson的值的变化如何表征多样性的变化需要看使用的是哪种变体。</p><h4 id="2-1-5-Good’s-Coverage"><a href="#2-1-5-Good’s-Coverage" class="headerlink" title="2.1.5 Good’s Coverage"></a>2.1.5 Good’s Coverage</h4><p>C = 1 - F1 / N, F1表示Singleton的数目，N表示样本中所有OTU的总数</p><p>Good’s Coverage数值的计算与Cace有点类似。只是Cace取用的是出现次数不超过10的物种（或OTU）进行计算，而Good’s Coverage利用的是全部OTU的丰度，它表示所有非singleton在总样本中的比值.理论上，在测序深度不断增加时，随着新Singleton的出现减少，表明已经接近测出所有物种；通过检查Singleton在样品中的比值，就可以知道测序深度是否足够。C的数值越大，在测序数据量一样的情况下，样本的物种丰富度越小。</p><h3 id="2-2-β多样性"><a href="#2-2-β多样性" class="headerlink" title="2.2 β多样性"></a>2.2 β多样性</h3><p>beta多样性是生态系统之间的物种多样性，包含分类单位的比较。即衡量群落之间的差别。beta多样性不仅描述生境内生物物种的数量，同时也考虑到这些种类的相同性及其彼此之间的位置。用于不同样品之间、不同条件之间的比较，单个样品无法进行计算; 它可以指示生境被物种隔离的程度；其测定值可用来比较不同低端的额生境多样性。常见的指数有Whittaker指数、cody、wilson、shmida指数等。β多样分析通常是计算样品间的距离，针对距离来分析不同群落之间的差别，这些分析就包含pca分析、PCoA分析，NMDS分析等。那么如何计算样品间的距离？常用的有Bray-Curtis距离、unifrac距离等。</p><h4 id="2-2-1-Bray-Curtis-distance"><a href="#2-2-1-Bray-Curtis-distance" class="headerlink" title="2.2.1 Bray-Curtis distance"></a>2.2.1 Bray-Curtis distance</h4><p>Bray-Curtis distances又叫做Bray-Curtis dissimilarity。它是基于物种丰度(abundance)或者read count data来计算获得，用于比较两个样品之间的微生物物种丰度的差异，其取值在[0,1]，1表示两个样品的物种丰度完全不同。它将不同的OTU视为没有关联的两个单位。</p><h4 id="2-2-2-Jaccard-distance"><a href="#2-2-2-Jaccard-distance" class="headerlink" title="2.2.2 Jaccard distance"></a>2.2.2 Jaccard distance</h4><p>Jaccard distance基于物种存在与否计算距离，所以没有把物种丰度信息包含在内；它通常比较的是两个样品之间的微生物物种组成的不同。取值在[0,1],1表示样品之间物种组成完全不同。</p><h4 id="2-2-3-Unifrac-distance"><a href="#2-2-3-Unifrac-distance" class="headerlink" title="2.2.3 Unifrac distance"></a>2.2.3 Unifrac distance</h4><p>Unifrac距离是基于OTU之间的进化关系计算获得，即发育树上序列的距离。取值为[0,1],1表示两个样品之间微生物群落在进化上完全独立。根据有没有考虑OTU丰度的区别，unifrac分析可以分为加权（weighted unifrac）和非加权（unweighted unifrac）两种方法。其中， unweighted UniFrac只考虑了物种有无的变化，而weighted UniFrac则同时考虑物种有无和物种丰度的变化。在环境样本的检测中，研究者更关心群落间的变化，因此往往采用非加权方法。如果要研究对照与实验处理组之间的关系，例如研究青霉素处理后，人肠道的菌落变化情况，由于处理后群落的组成不会发生大改变，但群落的丰度可能会发生大变化，因此更适合用加权方法去计算。</p><h3 id="2-3-扩增子的群落功能预测"><a href="#2-3-扩增子的群落功能预测" class="headerlink" title="2.3 扩增子的群落功能预测"></a>2.3 扩增子的群落功能预测</h3><p>有越来越多的研究表明，相比于物种组成，微生物的群落功能组成与环境的关系更为密切(Gibbons S M. Microbial community ecology: Function over phylogeny[J].  NatureEcology &amp; Evolution, 2017, 1: 0032)。由于宏基因组和宏转录组的分析费用较高，学者自然在扩增子测序上下了一番功夫, 现有许多软件可以根据扩增子的测序结果去做微生物群落的功能预测。</p><table><thead><tr><th>软件</th><th>marker gene</th><th>database</th><th>function</th></tr></thead><tbody><tr><td>PICRUSt</td><td>16s</td><td>greengene</td><td>KEGG功能预测</td></tr><tr><td>Tax4Fun</td><td>16s</td><td>SILVA</td><td>KEGG功能预测</td></tr><tr><td>FUNGuild</td><td>ITS</td><td>UNIT,ITS2</td><td>Guild预测</td></tr><tr><td>FAPROTAX</td><td>16s</td><td>SILVA,greengene</td><td>生态功能预测</td></tr><tr><td>BugBase</td><td>16s</td><td>greengene</td><td>表型分类</td></tr></tbody></table><h3 id="2-4-微生物分析方法的比较"><a href="#2-4-微生物分析方法的比较" class="headerlink" title="2.4 微生物分析方法的比较"></a>2.4 微生物分析方法的比较</h3><p>前面我们提到，不同的组学分析有不同的分析目的，那反过来，根据不同的分析目的，我们要选择合适的分析方法。目前微生物的分析方法大体分为3种：扩增子测序(16s/18s/ITS), 宏基因组测序, 宏转录组测序，他们三者的研究深度应该是递进的。具体可以看下表。</p><table><thead><tr><th>项目</th><th>扩增子测序</th><th>宏基因组测序</th><th>宏转录组测序</th></tr></thead><tbody><tr><td>主要关注问题</td><td>有什么物种</td><td>各个物种有什么功能</td><td>怎样行使功能</td></tr><tr><td>分析手段</td><td>物种组成,α/β多样性,群落功能预测</td><td>基因功能注释,代谢通路研究</td><td>差异表达基因,代谢通路研究</td></tr><tr><td>成本</td><td>较低</td><td>较高</td><td>较高</td></tr><tr><td>缺点</td><td>PCR偏好性</td><td>无法得到基因表达信息</td><td>RNA不稳定,建库难,基因信息有缺失</td></tr><tr><td>优点</td><td>适合大样本</td><td>DNA信息完整</td><td>研究内容全面</td></tr></tbody></table><p>从上表来看，扩增子测序应该作为研究第一步要考虑的分析方式。它价格便宜，可以帮助我们分析不同样本间微生物的组成和差异，有助于我们发现可能的靶样本。然后根据扩增子测序的结果选择有代表性的样本进行后续的宏基因组测序、宏转录组测序，深入阐明群落的功能，说明生物群落与环境的关系。</p><h3 id="2-5-扩增子分析简要流程"><a href="#2-5-扩增子分析简要流程" class="headerlink" title="2.5 扩增子分析简要流程"></a>2.5 扩增子分析简要流程</h3><p><img src="https://s1.ax1x.com/2018/10/15/iUgnJA.png" alt="扩增子分析"><br><img src="https://s1.ax1x.com/2018/10/15/iUguRI.png" alt="16s rDNA结构及引物"><br><img src="https://s1.ax1x.com/2018/10/15/iUgKzt.png" alt="扩增区域及平台选择"></p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
            <tag> 扩增子 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>扩增子测序 QIIME1</title>
      <link href="/2018/10/15/%E6%89%A9%E5%A2%9E%E5%AD%90%E6%B5%8B%E5%BA%8F-QIIME1/"/>
      <url>/2018/10/15/%E6%89%A9%E5%A2%9E%E5%AD%90%E6%B5%8B%E5%BA%8F-QIIME1/</url>
      
        <content type="html"><![CDATA[<h2 id="1-构建mapping-file-并验证是否有误"><a href="#1-构建mapping-file-并验证是否有误" class="headerlink" title="1 构建mapping file,并验证是否有误"></a>1 构建mapping file,并验证是否有误</h2><p>mapping file记录着样品对应的barcode、primer、treatment group等信息，以tab作为列分割符。各列名如下：</p><table><thead><tr><th>column name</th><th>Description </th></tr></thead><tbody><tr><td>SampleID</td><td>样品名，数字、字母、点号</td></tr><tr><td>BarcodeSequence</td><td>barcode序列，区分样本</td></tr><tr><td>LinkerPrimerSequence</td><td>5’端引物</td></tr><tr><td>ReversePrimerSequence</td><td>3’端反向引物,如果有的话</td></tr><tr><td>Treatment</td><td>分组信息</td></tr><tr><td>Description</td><td>样品详细注释</td></tr><tr><td>DOB</td><td>日期或其他信息</td></tr></tbody></table><p>下机reads组成：AdapterA - BarcodeSequence - LinkerPrimerSequence - Target - ReversePrimer - AdapterB</p><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mapping.tsv</span></span><br><span class="line"><span class="comment"># SampleIDBarcodeSequenceLinkerPrimerSequenceTreatmentReversePrimer Description</span></span><br><span class="line"><span class="comment"># Example mapping file for the QIIME analysis package.</span></span><br><span class="line">PC.354AGCACGAGCCTAYATGCTGCCTCCCGTAGGAGTControl GCGCACGGGTGAGTAControl_mouse__I.D._354</span><br><span class="line">PC.355AACTCGTCGATGYATGCTGCCTCCCGTAGGAGTControl GCGCACGGGTGAGTAControl_mouse__I.D._355</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">validate_mapping_file -m mapping.tsv -o 01_map_out</span><br></pre></td></tr></table></figure><h2 id="2-拆分和质控-demultiplex-and-QC"><a href="#2-拆分和质控-demultiplex-and-QC" class="headerlink" title="2 拆分和质控(demultiplex and QC)"></a>2 拆分和质控(demultiplex and QC)</h2><p>扩增子测序通常是混池测序，所以我们要对序列拆分到各自所属样品，并进行质控。执行这一步的脚本为split_libaries_fastq.py，质控在里面默认进行。输入的文件格式可以是 fastq.gz 也可以是 fastq。</p><h3 id="2-0-只进行质控"><a href="#2-0-只进行质控" class="headerlink" title="2.0 只进行质控"></a>2.0 只进行质控</h3><p>把split_libaries_fastq.py的参数–barcode_type 设置为’not-barcoded’即可。</p><h3 id="2-1-Illumina-paired-end-fastq"><a href="#2-1-Illumina-paired-end-fastq" class="headerlink" title="2.1 Illumina paired end fastq"></a>2.1 Illumina paired end fastq</h3><p>使用joined_paired_ends.py合并双端数据，如果后续进行拆分序列的话，你需要提供barcodes.fastq文件。这个由extract_barcodes来实现，见3.2.8.<br>joined_paired_ends内部使用fast-join或SeqPrep来进行，默认为前者，-m SeqPrep可以指定后者。<br>后续拆分同Illumina single end fastq，见3.2.2.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">join_paired_ends.py -f forward_reads.fastq -r reverse_reads.fastq -b barcodes.fastq -o join_fastq/</span><br></pre></td></tr></table></figure><h3 id="2-2-Illumina-single-end-fastq"><a href="#2-2-Illumina-single-end-fastq" class="headerlink" title="2.2 Illumina single end fastq"></a>2.2 Illumina single end fastq</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果有多个的话，用逗号分隔输入, 指定--rev_comp_mapping_barcodes是使用barcode.fastq.gz与mapping里面的方向反向互补了(3‘端的单端barcode)。</span></span><br><span class="line">split_libraries_fastq.py -i read1.fastq.gz -b barcode.fastq.gz --rev_comp_mapping_barcodes -o slout_q20/ -m map.txt -q 19</span><br></pre></td></tr></table></figure><h3 id="2-3-Illumina-fastq：multiple-lane"><a href="#2-3-Illumina-fastq：multiple-lane" class="headerlink" title="2.3 Illumina fastq：multiple lane"></a>2.3 Illumina fastq：multiple lane</h3><p>若想同时拆分Illumina的多个lane的数据，可以按下列命令进行，但是要指定每个lane对应的barcode和mapping file.所有的拆分结果将写入seqs.fna中，但log和histogram file是按lane区分. split_libraries_log.txt记录了运行的各项参数，如果结果不满意可调整参数重新运行。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">split_libraries_fastq.py -i s_6_sequence.fastq,s_7_sequence.fastq,s_8_sequence.fastq \</span><br><span class="line">        -o sl_out/ -b s_6_barcode.fastq,s_7_barcode.fastq,s_8_barcode.fastq \</span><br><span class="line">        -m s_6_map.txt,s_7_map.txt,s_8_map.txt</span><br></pre></td></tr></table></figure><h3 id="2-4-Illumina-qseq"><a href="#2-4-Illumina-qseq" class="headerlink" title="2.4 Illumina qseq"></a>2.4 Illumina qseq</h3><p>首先你需要知道你的barcode位于哪个reads上，长度多少。可以查看一个样品的不同reads文件。<br>然后使用process_qseq.py生成fastq文件，每个lane生成一个single fastq文件。<br>最后才是使用split_libraries_fastq.py进行拆分，类似于2.2.3。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设文件为s_1_1_0001_qseq.txt，s_1_2_0001_qseq.txt</span></span><br><span class="line">head -n 1 s_1_1_0001_qseq.txt</span><br><span class="line"><span class="comment"># 如果结果类似如下，第八列表示是read2, 且barcode长度为12bases。</span></span><br><span class="line"><span class="comment"># 如果不是，查看s_1_2_0001_qseq.txt</span></span><br><span class="line">M10     68      1       1       28680   29475   0       2       ACTCACGGTATTA   \_J\Sa^Y[ZYK`   0</span><br><span class="line">M10     68      1       1       19607   29475   0       2       AGACTGAGTACTA   PP\JJ\JQ`\RK^   1</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用process_qseq.py生成fastq</span></span><br><span class="line"><span class="comment"># read1</span></span><br><span class="line">process_qseq.py -i input_dir/ -o output_dir -r 1</span><br><span class="line"><span class="comment"># read2,并且截断了12个bases,12是因为你的barcode长12 bases；只处理barcode序列</span></span><br><span class="line">process_qseq.py -i input_dir/ -o output_dir -r 2 -b 12</span><br></pre></td></tr></table></figure><h3 id="2-5-iseq"><a href="#2-5-iseq" class="headerlink" title="2.5 iseq"></a>2.5 iseq</h3><p>使用process_iseq.py进行处理, 每个lane将产生一个single read；后续使用split_libraries_fastq.py进行拆分，类似于2.2.3。</p><ul><li>如果barcode与序列在一起(较为常见)</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># s_6_1_sequences.txt,s_7_1_sequences.txt都是含barcode的；barcode长度为12</span></span><br><span class="line"><span class="comment"># HWI-ST753_50:6:1101:15435:9071#0/1:ACCAGACGATGCTACGGAGGGAGCTAG...</span></span><br><span class="line">process_iseq.py -i s_6_1_sequences.txt,s_7_1_sequences.txt -o out_dir/ -b 12</span><br></pre></td></tr></table></figure><ul><li>如果barcode在header里面</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ACAGCTA长为7,但是你的barcode为ACAGCT为6，可以指定--barcode-length</span></span><br><span class="line"><span class="comment"># HWI-6X_9267:1:1:12:410#ACAGCTA/1:TACGTAGGGTGCGAGCGTTAATCGGAATTACTGGGCGTAAAGCGTGCG</span></span><br><span class="line">process_iseq.py -i s_6_1_sequences.txt,s_7_1_sequences.txt -o out_dir/ --barcode-length 6 --barcode_in_header</span><br></pre></td></tr></table></figure><h3 id="2-6-LEA-Seq数据"><a href="#2-6-LEA-Seq数据" class="headerlink" title="2.6 LEA-Seq数据"></a>2.6 LEA-Seq数据</h3><p>使用split_libraries_lea_seq.py来处理.</p><h3 id="2-7-处理已经拆分的数据"><a href="#2-7-处理已经拆分的数据" class="headerlink" title="2.7 处理已经拆分的数据"></a>2.7 处理已经拆分的数据</h3><ul><li>multiple_split_libraries_fastq.py: 进行质控</li><li>multiple_join_paired_ends.py:    合并已经拆分的paired ends</li><li>multiple_extract_barcodes.py: 去除已经拆分的fastq内部的barcode</li></ul><h3 id="2-8-处理不同的barcode策略"><a href="#2-8-处理不同的barcode策略" class="headerlink" title="2.8 处理不同的barcode策略"></a>2.8 处理不同的barcode策略</h3><ul><li>single fastq starts with the barcode sequence(单个fastq单个barcode)</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设in_seqs.fastq的前10个碱基是barcode</span></span><br><span class="line"><span class="comment"># 如果你想反向互补barcode的话，设置--rev_comp_bc1</span></span><br><span class="line">extract_barcodes.py -f in_seqs.fastq --bc1_len 10 -o parsed_barcodes/ --input_type barcode_single_end</span><br></pre></td></tr></table></figure><ul><li>two fastqs each starts with part of barcode: paired-end(双端fasta,单个barcode)</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设barcode部分分布在reads1,6 bases；部分分布在reads2,8 bases。</span></span><br><span class="line">extract_barcodes.py --input_type barcode_paired_end -f reads1.fastq -r reads2.fastq --bc1_len 6 --bc2_len 8 -o parsed_barcodes/</span><br><span class="line"><span class="comment"># 如果你想反向互补barcode的话，--rev_comp_bc1, --rev_comp_bc2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 有时候，reads的方向不确定，你需要根据mapping file里面的primer来确定reads的方向</span></span><br><span class="line">extract_barcodes.py --input_type barcode_paired_end -m mapping_file.txt \</span><br><span class="line">        -a -f reads1.fastq -r reads2.fastq \</span><br><span class="line">        --bc1_len 6 --bc2_len 8 -o parsed_barcodes/</span><br></pre></td></tr></table></figure><ul><li>two index/barcode reads and two fastq reads (双端fastq, 2个barcode)</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里已经得到分离的barcode了，所以用不上read文件</span></span><br><span class="line"><span class="comment"># index1.fastq,index2.fastq是barcode文件。每个barcode长度为6.</span></span><br><span class="line">extract_barcodes.py --input_type barcode_paired_end -f index1.fastq \</span><br><span class="line">        -r index2.fastq --bc1_len 6 --bc2_len 6 -o parsed_barcodes/</span><br></pre></td></tr></table></figure><ul><li>single stitched read with barcodes on each end (单个fastq, 双端barcode)</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">extract_barcodes.py --input_type barcode_paired_stitched -f reads.fastq --bc1_len 6 --bc2_len 6 -o parsed_barcodes/</span><br></pre></td></tr></table></figure><ul><li>barcode在fastq文件的描述行内</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @MCIC-SOLEXA_0051_FC:1:1:4065:1039#CGATGT/1</span></span><br><span class="line"><span class="comment"># NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN</span></span><br><span class="line"><span class="comment"># +MCIC-SOLEXA_0051_FC:1:1:4065:1039#CGATGT/1</span></span><br><span class="line"><span class="comment"># KPPPQWWWWWQQ________BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB</span></span><br><span class="line"><span class="comment"># 这里barcode开头是#，长度为6</span></span><br><span class="line">extract_barcodes.py --input_type barcode_in_label --char_delineator <span class="string">"#"</span> -f in_seqs.fastq --bc1_len 6 -o parsed_barcodes/</span><br></pre></td></tr></table></figure><h3 id="2-9-处理Joint-Genome-Institute-fastq-文件"><a href="#2-9-处理Joint-Genome-Institute-fastq-文件" class="headerlink" title="2.9 处理Joint Genome Institute fastq 文件"></a>2.9 处理Joint Genome Institute fastq 文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @MISEQ03:64:000000000-A2H3D:1:1101:14358:1530 1:N:0:TCCACAGGAGT</span></span><br><span class="line"><span class="comment"># TNCAGAGGGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAGCGCGCGTAGGTGGTTTGTTA</span></span><br><span class="line"><span class="comment"># + </span></span><br><span class="line"><span class="comment"># .....</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># TCCACAGGAGT为barcode，长为11</span></span><br><span class="line">extract_reads_from_interleaved_file.py -i reads_to_extract.fastq -o extracted_reads</span><br><span class="line">extract_barcodes.py -f extracted_reads/forward_reads.fastq -o barcode_reads -c barcode_in_label --char_delineator <span class="string">'1:N:0:'</span> -l 11</span><br></pre></td></tr></table></figure><h2 id="3-去除嵌合体和OTU聚类"><a href="#3-去除嵌合体和OTU聚类" class="headerlink" title="3 去除嵌合体和OTU聚类"></a>3 去除嵌合体和OTU聚类</h2><p><a href="http://qiime.org/scripts/pick_otus.html?highlight=pick_otus" target="_blank" rel="noopener">pick_otus.py</a>整合十多种算法用于聚类OTU。<br>输出结果的第一列为OTU ID，第二列为该OTU的种子序列。以usearch为例,程序内部执行的基本过程如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1. 根据序列长度排序(rank)          2. 去除重复序列(去冗余)</span></span><br><span class="line"><span class="comment">#3. 根据序列丰度进行排序            4. 对序列进行去噪</span></span><br><span class="line"><span class="comment">#5. 去除嵌合体,先是de novo, 然后是ref-based</span></span><br><span class="line"><span class="comment">#6. 对序列进行合并                  7. 再根据丰度进行拍醋</span></span><br><span class="line"><span class="comment">#8. 基于排序进行聚类                9. 为聚类的结果添加对应的序列id</span></span><br><span class="line"><span class="comment">#10.对序列完成分类</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">pick_otus.py -i split_library_output/seqs.fna -o picked_otus_default</span><br><span class="line"><span class="comment"># 较为重要的参数</span></span><br><span class="line"><span class="comment"># -i &lt;input_fasta&gt;</span></span><br><span class="line"><span class="comment"># -m &lt;method&gt;使用blast, uclust_ref, usearch_ref, usearch61_ref时需要指定-r参数.默认为uclust.</span></span><br><span class="line"><span class="comment"># -o &lt;out_dir&gt;, -r &lt;ref_seq&gt;</span></span><br><span class="line"><span class="comment"># -s &lt;similarity&gt;默认为0.97</span></span><br><span class="line"><span class="comment"># -j &lt;ErrorRate&gt;</span></span><br><span class="line"><span class="comment"># -g &lt;min_count_in_cluster&gt; 当cluster的序列count数低于设定值时，该cluster被忽略</span></span><br><span class="line"><span class="comment"># -f &lt;chimeric_ref_seq&gt;当-m usearch时需要指定</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># uclust-ref</span></span><br><span class="line">pick_otus.py -i seqs.fna -r refseqs.fasta -m uclust_ref --denovo_otu_id_prefix qiime_otu_</span><br><span class="line"></span><br><span class="line"><span class="comment"># cdhit</span></span><br><span class="line"><span class="comment"># -n 100将会执行预聚类，前100个bp完全相同的序列将被预聚类;使用-t参数则不指定-n num</span></span><br><span class="line">pick_otus.py -i seqs.fna -m cdhit -o cdhit_picked_otus/ -n 100</span><br><span class="line"></span><br><span class="line"><span class="comment"># blast</span></span><br><span class="line"><span class="comment"># 如果参考序列时预构建的blast序列,使用-b代替-r进行指定; -s指定相似度; -e指定错误发现率(blast专有)</span></span><br><span class="line">pick_otus.py -i seqs.fna -o blast_picked_otus_90_percent/ -m blast -r refseqs.fasta -s 0.90 -e 1e-30</span><br><span class="line"></span><br><span class="line"><span class="comment"># prefix-suffix</span></span><br><span class="line"><span class="comment"># 前50个bp后25个bp完全相同的序列将会被预聚类</span></span><br><span class="line">pick_otus.py -i seqs.fna -o prefix_suffix_picked_otus/ -m prefix_suffix -p 50 -u 25</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mothur</span></span><br><span class="line"><span class="comment"># -c 指定聚类算法, mothur专有,取值furtherest, neareast, average</span></span><br><span class="line">pick_otus.py -i seqs.aligned.fna -o mothur_picked_otus_nn/ -m mothur -c nearest</span><br><span class="line"></span><br><span class="line"><span class="comment"># usearch</span></span><br><span class="line"><span class="comment"># --suppress_reference_chimera_detection禁止基于参考序列的嵌合体发现</span></span><br><span class="line">pick_otus.py -i seqs.fna -m usearch --word_length 64 --db_filepath refseqs.fasta -o usearch_qf_results/ --minsize 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># swarm</span></span><br><span class="line">pick_otus.py -i <span class="variable">$PWD</span>/seqs.fna -m swarm -o <span class="variable">$PWD</span>/picked_otus_swarm</span><br></pre></td></tr></table></figure><h2 id="4-选取OTU代表性序列"><a href="#4-选取OTU代表性序列" class="headerlink" title="4 选取OTU代表性序列"></a>4 选取OTU代表性序列</h2><p>输出为代表序列out_rep_seq.fasta。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pick_rep_set.py -f split_library_output/seqs.fna -m most_abundant -i seqs_outs.txt -o out_rep_seq.fasta</span><br><span class="line"></span><br><span class="line"><span class="comment"># -i &lt;input_otus_file&gt;</span></span><br><span class="line"><span class="comment"># -f &lt;all_seqs_fna&gt;</span></span><br><span class="line"><span class="comment"># -m &lt;method&gt; random, longest, most_abundant, first(default)</span></span><br></pre></td></tr></table></figure><h2 id="5-进行物种分类"><a href="#5-进行物种分类" class="headerlink" title="5 进行物种分类"></a>5 进行物种分类</h2><p>使用assign_taxonomy.py进行物种分类；对于给定的序列集，该脚本会尝试对每条序列确定其分类，当前支持方法有BLAST、RDP分类器、RTAX、mothur和uclust。输出目录默认为methodname_assigned_taxonomy, 输出的结果文件第一列是序列ID，第二列是该序列所属物种分类，第三列是质量分数，以及其他信息，依据方法不同而不同。使用的参考序列最新版本可在qiime的resources页面下载。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># default：uclust</span></span><br><span class="line">assign_taxonomy.py -i repr_set_seqs.fasta -r ref_seq_set.fna -t id_to_taxonomy.txt</span><br><span class="line"><span class="comment"># SortMeRNA</span></span><br><span class="line">assign_taxonomy.py -i repr_set_seqs.fasta -r ref_seq_set.fna -t id_to_taxonomy.txt -m sortmerna</span><br><span class="line"><span class="comment"># Blast</span></span><br><span class="line"><span class="comment"># -e maximum e-value to record an assignment</span></span><br><span class="line">assign_taxonomy.py -i repr_set_seqs.fasta -r ref_seq_set.fna -t id_to_taxonomy.txt -e 0.01 -m blast</span><br><span class="line"><span class="comment"># RDP classifier</span></span><br><span class="line"><span class="comment"># 训练集默认为-t和-r指定的taxonomy和otus；如未指定，使用默认设置</span></span><br><span class="line"><span class="comment"># -c minimum confidence to record an assignment</span></span><br><span class="line">assign_taxonomy.py -i repr_set_seqs.fasta -m rdp -c 0.80</span><br><span class="line"><span class="comment"># RTAX</span></span><br><span class="line">assign_taxonomy.py -i rtax_repr_set_seqs.fasta -m rtax \</span><br><span class="line"> --read_1_seqs_fp read_1.seqs.fna \</span><br><span class="line"> --read_2_seqs_fp read_2.seqs.fna \</span><br><span class="line"> -r rtax_ref_seq_set.fna \</span><br><span class="line"> -t rtax_id_to_taxonomy.txt</span><br><span class="line"><span class="comment"># mothur</span></span><br><span class="line">assign_taxonomy.py -i mothur_repr_set_seqs.fasta -m mothur -r mothur_ref_seq_set.fna -t mothur_id_to_taxonomy.txt</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -o &lt;out_dir&gt; 输出结果路径</span></span><br><span class="line"><span class="comment"># -i &lt;otu_rep_set.fasta&gt;输入的代表序列</span></span><br><span class="line"><span class="comment"># -t &lt;id_to_taxonomy&gt; 分类时参考序列ID对应的物种分类信息。</span></span><br><span class="line"><span class="comment"># -r &lt;ref_otu.fasta&gt;分类时的参考序列</span></span><br><span class="line"><span class="comment"># -p &lt;rdp_train_set&gt; 指定RDP的训练数据集，会覆盖-r,-t指定的参数</span></span><br><span class="line"><span class="comment"># -m &lt;method&gt; 选取某个方法进行分类</span></span><br><span class="line"><span class="comment"># -b &lt;blast_db&gt; 指定使用blast时的数据库, 与-r同义</span></span><br><span class="line"><span class="comment"># -e &lt;max_E_value&gt; 使用blast时的最大错误值</span></span><br><span class="line"><span class="comment"># -c &lt;min_confidence&gt;RDP分类时的最小置信值,超过该值才会认为属于该分类</span></span><br></pre></td></tr></table></figure><hr><h2 id="6-生成OTU表-biom文件"><a href="#6-生成OTU表-biom文件" class="headerlink" title="6 生成OTU表(biom文件)"></a>6 生成OTU表(biom文件)</h2><p>make_otu_table.py将对OTU进行汇总和注释，生成biom格式的OTU表。</p><h3 id="6-1-生成OTU表"><a href="#6-1-生成OTU表" class="headerlink" title="6.1 生成OTU表"></a>6.1 生成OTU表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">make_otu_table.py -i otu_map.txt \</span><br><span class="line"> -t tax_assignments.txt \</span><br><span class="line"> -o otu_table.biom \</span><br><span class="line"> -m mapping_file.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># -i &lt;input_otu_map&gt;   指定输入的OTU map，通常是pick_otus.py的结果文件</span></span><br><span class="line"><span class="comment"># -o &lt;out_biom_dir&gt; 输出结果文件</span></span><br><span class="line"><span class="comment"># -m &lt;mapping_file&gt; 指定mapping file,如果有的话</span></span><br><span class="line"><span class="comment"># -e &lt;id_file&gt;指定排除OTU的identifiers文件</span></span><br></pre></td></tr></table></figure><h3 id="6-2-生成OTU表同时进行过滤"><a href="#6-2-生成OTU表同时进行过滤" class="headerlink" title="6.2 生成OTU表同时进行过滤"></a>6.2 生成OTU表同时进行过滤</h3><p>为了便于后续操作，一般会对OTU表进行过滤等操作.有两种方式，第一种方式是在构建的时候进行过滤，这通常是过滤嵌合体或未比对序列.另一种方式是生成otu表后，再进行过滤。其他过滤操作见3.7。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># identify_chimeric_seqs.py, align_seqs.py 生成不要的seqs对应的文件exclude.txt，然后在make_otu_table.py中以-e参数指定exclude.txt</span></span><br></pre></td></tr></table></figure><h2 id="7-对OTU表-biom-进行操作-过滤、拆分等"><a href="#7-对OTU表-biom-进行操作-过滤、拆分等" class="headerlink" title="7 对OTU表(biom)进行操作: 过滤、拆分等"></a>7 对OTU表(biom)进行操作: 过滤、拆分等</h2><h3 id="7-1-过滤"><a href="#7-1-过滤" class="headerlink" title="7.1 过滤"></a>7.1 过滤</h3><ul><li>Even sampling, rarefaction (稀释)</li></ul><p>这里的抽样方式有单次抽样、多次等差抽样(稀释抽样)、多次平均抽样。single_rareefaction.py只进行一次抽样, multiple_rarefactions.py进行多次抽样(每次抽样深度不同), multiple_rarefactions_even_depth.py进行多次抽样(每次抽样深度相同)。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从otu-table中按每个样品100条序列随机抽取，并输出</span></span><br><span class="line">single_rarefaction.py -i otu_table.biom -o otu_table_even100.biom -d 100</span><br><span class="line"><span class="comment"># -k &lt;bool&gt;指定是否保留全0的OTU,default:fasle</span></span><br><span class="line"><span class="comment"># --subsample_multinomial &lt;bool&gt; 是否是放回抽样,default:fasle</span></span><br><span class="line"></span><br><span class="line">multiple_rarefactions.py -i otu_table.biom -m 10 -x 140 -s 10 -n 2 -o rarefied_otu_tables/</span><br><span class="line"><span class="comment"># -m &lt;min_num&gt;指定多次抽样的最低抽样数,seqs/sample, 抽样深度</span></span><br><span class="line"><span class="comment"># -x &lt;max_num&gt;指定多次抽样的最大抽样数</span></span><br><span class="line"><span class="comment"># -s &lt;step_num&gt;指定2次抽样的抽样次数的步长,差值</span></span><br><span class="line"><span class="comment"># -n &lt;num_reps&gt; 每一步抽样的重复次数</span></span><br><span class="line"><span class="comment"># -k，--subsample_nultinomial 同单次抽样</span></span><br><span class="line"></span><br><span class="line">multiple_rarefactions_even_depth.py -i otu_table.biom -o rarefied_otu_tables/ -d 100 -n 10</span><br></pre></td></tr></table></figure><ul><li>过滤OTUs/observations</li></ul><p>过滤时可以根据mapping file的某列值进行过滤，也可以根据OTU的count数来过滤(singletons, doubletons…),丰度过滤。 根据run_number的切分和过滤有点相似，但是切分是所有run切分。过滤可以只过滤某个值。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保留mapping file中某列的值等于指定值的OTUs, "Sample_Type:*,!Control_Blank"则表示删除</span></span><br><span class="line">filter_samples_from_otu_table.py -i split_otu_tables/otu_table_1.biom -o otu_table_run1_blank_samples.biom -m map.txt -s <span class="string">"Sample_Type:Control_Blank"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 排除singleton</span></span><br><span class="line">filter_otus_from_otu_table.py -i otu_table.biom -o filtered_otu_table.biom -n 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># -n &lt;min_count&gt;如果该OTU的total counts低于指定值,排除该OTU</span></span><br><span class="line"><span class="comment"># -x &lt;max_count&gt; 如果该OTU的total counts高于指定值,排除该OTU</span></span><br><span class="line"><span class="comment"># -s &lt;min_samples&gt;如果属于该OTU的样品数低于指定值,排除该OTU</span></span><br><span class="line"><span class="comment"># -y &lt;max_samples&gt; 如果属于该OTU的样品数超过指定值,排除该OTU</span></span><br><span class="line"><span class="comment"># -e &lt;out_ids_to_exclude_file&gt;排除指定id的OTUs</span></span><br></pre></td></tr></table></figure><ul><li>过滤样本</li></ul><p>过滤样本可以基于丰度过滤，也可以基于metadata过滤，还可以基于ID过滤。过滤样本与过滤OTUs是相类似的.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保留total OTUs counts在[100,150]的样品</span></span><br><span class="line">filter_samples_from_otu_table.py -i otu_table.biom -o filtered_otu_table.biom -n 100 -x 150</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留mapping file中某列的值等于指定值的样品</span></span><br><span class="line">filter_samples_from_otu_table.py -i otu_table.biom -o filtered_otu_table.biom -m map.txt -s <span class="string">'Treatment:Control'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留mapping file中某列的值==不等于==指定值的样品</span></span><br><span class="line">filter_samples_from_otu_table.py -i otu_table.biom -o filtered_otu_table.biom -m map.txt -s <span class="string">'Treatment:*,!Control'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留在ids.txt的样品; 如果设定了--negate_sample_id_fp,则是删除在ids.txt的样品</span></span><br><span class="line">filter_samples_from_otu_table.py -i otu_table.biom -o filtered_otu_table.biom --sample_id_fp ids.txt</span><br></pre></td></tr></table></figure><ul><li>过滤分类群: 保留属于特定分类的OTU</li></ul><p>过滤分类群时，你可以有3种逻辑的过滤方式：or, not or, not but</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保留属于__Bacteroidetes 或者 p__Firmicutes</span></span><br><span class="line">filter_taxa_from_otu_table.py -i otu_table.biom -o otu_table_bac_firm_only.biom -p p__Bacteroidetes,p__Firmicutes</span><br><span class="line"><span class="comment"># 保留不属于__Bacteroidetes和 p__Firmicutes</span></span><br><span class="line">filter_taxa_from_otu_table.py -i otu_table.biom -o otu_table_non_bac_firm.biom -n p__Bacteroidetes,p__Firmicutes</span><br><span class="line"><span class="comment"># 保留不属于c__Clostridia但是属于p__Firmicutes</span></span><br><span class="line">filter_taxa_from_otu_table.py -i otu_table.biom -o otu_table_all_firm_but_not_clos.biom -p p__Firmicutes -n c__Clostridia</span><br><span class="line"></span><br><span class="line"><span class="comment"># -p &lt;list, comma&gt; 保留</span></span><br><span class="line"><span class="comment"># -n &lt;list, comma&gt; 排除</span></span><br><span class="line"><span class="comment"># --metadata_field 指定用于过滤的metadata的列名</span></span><br></pre></td></tr></table></figure><h3 id="7-2-拆分和合并"><a href="#7-2-拆分和合并" class="headerlink" title="7.2 拆分和合并"></a>7.2 拆分和合并</h3><ul><li>基于mapping/metadata进行拆分</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">split_otu_table.py -i otu_table.biom -m Fasting_Map.txt -f Treatment -o per_study_otu_tables</span><br><span class="line">split_otu_table.py -i otu_table.biom -m Fasting_Map.txt -f Treatment,Color -o ./per_study_otu_tables/</span><br></pre></td></tr></table></figure><ul><li>基于taxonomy(物种分类)进行拆分</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将otu_table依据Level3进行拆分</span></span><br><span class="line">split_otu_table_by_taxonomy.py -i otu_table.biom -L 3 -o ./L3/</span><br></pre></td></tr></table></figure><ul><li>合并</li></ul><p>在进行合并时，你要保证合并的两个OTUs表的OTU id和sample id是兼容的；如果两个表有重叠内容，将会计算重叠内容的值的和。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">merge_otu_tables.py -i otu_table1.biom,otu_table2.biom -o merged_otu_table.biom</span><br></pre></td></tr></table></figure><h3 id="7-3-统计汇总"><a href="#7-3-统计汇总" class="headerlink" title="7.3 统计汇总"></a>7.3 统计汇总</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按样品进行统计汇总,取总的observations的所有counts</span></span><br><span class="line">biom summarize-table -i rich_sparse_otu_table.biom -o rich_sparse_otu_table_summary.txt</span><br><span class="line"><span class="comment"># 按样品进行汇总，但只取唯一的observations的counts</span></span><br><span class="line">biom summarize-table -i rich_sparse_otu_table.biom --qualitative-o rich_sparse_otu_table_summary.txt</span><br></pre></td></tr></table></figure><h3 id="7-4-对OTU表进行排序"><a href="#7-4-对OTU表进行排序" class="headerlink" title="7.4 对OTU表进行排序"></a>7.4 对OTU表进行排序</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照sample id进行排序, 字母排序</span></span><br><span class="line">sort_otu_table.py -i otu_table.biom -o sorted_otu_table.biom</span><br><span class="line"><span class="comment"># 按照mapping/metadata file的某个列排序</span></span><br><span class="line">sort_otu_table.py -i otu_table.biom -o dob_sorted_otu_table.biom -m Fasting_Map.txt -s Age</span><br><span class="line"><span class="comment"># 按照给定顺序的sample id进行排序</span></span><br><span class="line">sort_otu_table.py -i otu_table.biom -o sorted_otu_table.biom -l sample_id_list.txt</span><br></pre></td></tr></table></figure><h3 id="7-5-biom文件的其他处理"><a href="#7-5-biom文件的其他处理" class="headerlink" title="7.5 biom文件的其他处理"></a>7.5 biom文件的其他处理</h3><ul><li>添加metadata信息到biom文件中</li></ul><p>见<a href="http://biom-format.org/documentation/adding_metadata.html" target="_blank" rel="noopener">网页tutorial</a></p><ul><li>转换biom到其他格式</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># json/hdf5</span></span><br><span class="line">biom convert -i table.txt -o table.from_txt_json.biom --table-type=<span class="string">"OTU table"</span> --to-json</span><br><span class="line">biom convert -i table.txt -o table.from_txt_hdf5.biom --table-type=<span class="string">"OTU table"</span> --to-hdf5</span><br><span class="line"><span class="comment"># tsv, 并添加taxonomy物种分类信息; 指定--output-metadata-id "ConsensusLineage"可以把添加的taxonomy列名改为ConsensusLineage</span></span><br><span class="line">biom convert -i table.biom -o table.from_biom.txt --to-tsv --header-key taxonomy</span><br><span class="line"><span class="comment"># 把tsv转换回去</span></span><br><span class="line">biom convert -i otu_table.txt -o new_otu_table.biom --to-hdf5 --table-type=<span class="string">"OTU table"</span> --process-obs-metadata taxonomy</span><br></pre></td></tr></table></figure><h2 id="8-物种分类分析-群落组成分析-otu"><a href="#8-物种分类分析-群落组成分析-otu" class="headerlink" title="8 物种分类分析 /群落组成分析(otu)"></a>8 物种分类分析 /群落组成分析(otu)</h2><h3 id="8-1-OTU聚类分析和分类学分析"><a href="#8-1-OTU聚类分析和分类学分析" class="headerlink" title="8.1 OTU聚类分析和分类学分析"></a>8.1 OTU聚类分析和分类学分析</h3><p>此处是OTU聚类表(OTU table),OTU在每个样品中的分布信息就是OTU聚类分析；后续添加的分类注释信息就是分类学信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1. 生成OTU聚类表, 见2.6</span></span><br><span class="line"><span class="comment">#2. 把表转换为tsv格式, 见2.7.5</span></span><br></pre></td></tr></table></figure><h3 id="8-2-OTU物种注释统计、OTU物种组成图"><a href="#8-2-OTU物种注释统计、OTU物种组成图" class="headerlink" title="8.2 OTU物种注释统计、OTU物种组成图"></a>8.2 OTU物种注释统计、OTU物种组成图</h3><p>使用summeriza_taxa_through_plot.py对OTU聚类表进行统计, 以各个分类水平进行统计每个样品在该分类水平上的OTU总数,并进行可视化. 该脚本由summarize_taxa.py和plot_taxa_summary.py组成。生成的otu_table_L*.txt文件是各个Level的水平物种丰度统计表。taxa_summary_plots文件夹则是物种丰度绘制图。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">summeriza_taxa_through_plots.py -o taxa_summary -i otu_table_w_tax.biom -m Fasting_Map.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># -i &lt;input_otu_table&gt; 指定input文件, otu_table需要包含物种信息</span></span><br><span class="line"><span class="comment"># -p &lt;param_file&gt; 指定特定中间过程脚本的参数</span></span><br><span class="line"><span class="comment"># -m &lt;mapping_file&gt;如果指定了-c,-m必须指定</span></span><br><span class="line"><span class="comment"># -c &lt;mapping_category&gt;指定进行统计的分组信息(按组统计)</span></span><br><span class="line"><span class="comment"># -s &lt;bool&gt; 指定是否排序otu table,default: false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># summeriza_taxa_through_plots.py内部依序执行的命令</span></span><br><span class="line">summarize_taxa.py -i otus/otu_table.biom -o taxa_summary</span><br><span class="line">plot_taxa_summary.py -i taxa_summary/otu_table_L2.txt,taxa_summary/otu_table_L3.txt,taxa_summary/otu_table_L4.txt,taxa_summary/otu_table_L5.txt,taxa_summary/otu_table_L6.txt -o taxa_summary/taxa_summary_plots/</span><br></pre></td></tr></table></figure><h3 id="8-3-OTU进化树分析-系统发育树"><a href="#8-3-OTU进化树分析-系统发育树" class="headerlink" title="8.3 OTU进化树分析(系统发育树)"></a>8.3 OTU进化树分析(系统发育树)</h3><p>构建OTU系统发育树分为三个步骤，分别使用三个脚本进行.生成的树可以用meta、Figtree等软件进行查看。系统发育树的构建有多种方法,可见<a href="http://www.biotrainee.com/thread-2253-1-1.html" target="_blank" rel="noopener">biotrainee</a></p><ol><li>序列比对</li></ol><p>可以选择多种方法进行序列比对,生成的文件夹命名为method_aligned的文件夹里,含有method_aligned.fasta, method_failures.fasta, method_log.txt</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">align_seqs.py -i otu_rep_set.fasta -o pynast_aligend/</span><br><span class="line"></span><br><span class="line"><span class="comment"># -m &lt;align_method&gt; 指定比对序列的算法, pynast(default), infernal, clustalW, muscle, mafft</span></span><br><span class="line"><span class="comment"># -a &lt;pairwse_align&gt; 指定在PyNAST中成对比对的算法, muscle, pair_hmm, clustal, blast, uclust(default), mafft</span></span><br><span class="line"><span class="comment"># -e &lt;min_length&gt;进行比对的序列最短长度</span></span><br><span class="line"><span class="comment"># -p &lt;min_percent_id&gt; blast中最低的一致性占比(default:0.75)</span></span><br><span class="line"><span class="comment"># -d &lt;blast_db&gt;当-m pynast时, 进行blast的数据库</span></span><br><span class="line"><span class="comment"># -t &lt;template_align&gt; 指定预比对的文件;可在http://greengenes.lbl.gov/下载获得</span></span><br><span class="line"><span class="comment"># --muscle_max_memory</span></span><br><span class="line"></span><br><span class="line">align_seqs.py -i <span class="variable">$PWD</span>/unaligned.fna -t core_set_aligned.fasta.imputed -o <span class="variable">$PWD</span>/pynast_aligned/ -e 500 -p 95.0</span><br></pre></td></tr></table></figure><ol start="2"><li>过滤比对结果中的高变异区</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">filter_alignment.py -i pynast_aligned/otu_rep_set_aligned.fasta -o pynast_aligned/ --remove_outliers -g 0.95</span><br><span class="line"></span><br><span class="line"><span class="comment"># -m &lt;lane_mask_file&gt; 指定在构建树时保留位点的lanemask文件</span></span><br><span class="line"><span class="comment"># -s &lt;suppress_lane_mask_filter&gt;</span></span><br><span class="line"><span class="comment"># -g &lt;allow_grap_frac&gt; 指定某个位点所允许的最少gap数</span></span><br><span class="line"><span class="comment"># -t &lt;threshold&gt; 指定认定为outlier的偏离标准偏差倍数, default=3</span></span><br><span class="line"><span class="comment"># -r &lt;remove_outliers&gt;指定过滤outlier</span></span><br></pre></td></tr></table></figure><ol start="3"><li>生成树</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">make_phylogeny.py -i pynast_aligned/otu_rep_set_aligned_pfilter.fasta -o rep_set.tre</span><br><span class="line"></span><br><span class="line"><span class="comment"># -t &lt;tree_method&gt; 指定进行建树的方法, clustalw, raxml_v730, muscle, fasttree(default), clearcut</span></span><br><span class="line"><span class="comment"># -l &lt;log_fp&gt;log的存储位置, 不指定的话不会创建log</span></span><br><span class="line"><span class="comment"># -r &lt;root_method&gt; 指定构建树的根(root)的方法, midpoint, tree_method_default(default)</span></span><br></pre></td></tr></table></figure><h3 id="8-4-OTU-Heatmap绘制（物种分类热图"><a href="#8-4-OTU-Heatmap绘制（物种分类热图" class="headerlink" title="8.4 OTU Heatmap绘制（物种分类热图)"></a>8.4 OTU Heatmap绘制（物种分类热图)</h3><p>使用make_otu_heatmap.py就对OTU表绘制热图，热图的每一行对应着一个OTU，每一列对应着一个样本。颜色代表了对应样本(列)的对应OTU(行)的丰度(counts).默认情况下，OTUs(行)将会使用UPGMA层次聚类，样品(列)将会按照在OTU表中出现的顺序进行排列。用户可以按照聚类树对行/列进行排序，也可以按照mapping file排序样品，对于后者，样品将会进行分组并聚类。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># default</span></span><br><span class="line">make_otu_heatmap.py -i otu_table.biom -o heatmap.pdf</span><br><span class="line"></span><br><span class="line"><span class="comment"># -t &lt;otu_tree&gt; 指定用于OTUs排序的OTU tree</span></span><br><span class="line"><span class="comment"># -m &lt;mapping_file&gt; 指定用于样品排序的meta/mapping file</span></span><br><span class="line"><span class="comment"># -c &lt;category&gt;指定用于样品排序的mapping file 列(分组)。</span></span><br><span class="line"><span class="comment"># -s &lt;sample_tree&gt; 指定用于样品排序的sample_tree,可来源于upgma_cluster.py的输出</span></span><br><span class="line"><span class="comment"># -g &lt;image_type&gt; 输出热图的格式, png, svg, pdf(default)</span></span><br><span class="line"><span class="comment"># --no_log_transform 不进行log转换, 0值被设为最小值的1/2</span></span><br><span class="line"><span class="comment"># --suppress_row/column_clustering 不进行upgma聚类,-t/-m设定了,不聚类的设定被忽略</span></span><br><span class="line"><span class="comment"># --absolute_abundance 不进行百分比化</span></span><br><span class="line"><span class="comment"># --color_scheme 指定颜色主题</span></span><br><span class="line"><span class="comment"># --width,--height,--dpi 指定热图图片相关格式</span></span><br><span class="line"><span class="comment"># --obs_md_category observation metadata category to plot</span></span><br><span class="line"><span class="comment"># --obs_md_level The level of observation metadata to plot for hierarchical metadata</span></span><br></pre></td></tr></table></figure><h3 id="8-5-OTU-network分析"><a href="#8-5-OTU-network分析" class="headerlink" title="8.5 OTU network分析"></a>8.5 OTU network分析</h3><p>make_otu_network.py可以利用OTU和metadata/mapping file生成用于cytoscape可视化的网络文件，并对网络进行统计。进行网络分析是因为他可以展示和分析样品之间OTUs的分布，这对于展示大数据中样本的相似性和差别十分便捷。可视化结果展示的是根据样品之间共有OTUs数目的聚类结果，网络的加权值是每个OTU所含有的序列数。然后根据网络节点间的关联来统计其聚类模式，这其中用到G-test(我不懂啊)。</p><p>基于network分析的样品比较与基于tree的PCoA分析相得益彰。在多数研究中，这两个方法的结果总是相一致的，但是反映这数据的不同方面。network分析提供了系统发育的可视化呈现，PCoA-unifrac聚类提供了发育的聚类水平，这有可能在network观察到。从技术上讲，OTUs和样品是network中的两种节点, OTU-node通过edges同sample-node连接，这些edges就是samples在OTUs中的序列。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">make_otu_network.py -i otu_table.biom -m Fasting_Map.txt -o otu_network</span><br><span class="line"><span class="comment"># -b &lt;color_by&gt; 指定依据mapping_file的特定列进行着色,可逗号分隔指定多个</span></span><br><span class="line"><span class="comment"># -k &lt;bg_color&gt; 指定网络的背景色</span></span><br></pre></td></tr></table></figure><h2 id="9-α多样性分析-alpha-diversity-analysis"><a href="#9-α多样性分析-alpha-diversity-analysis" class="headerlink" title="9 α多样性分析 (alpha diversity analysis)"></a>9 α多样性分析 (alpha diversity analysis)</h2><p>α多样性的分析主要是通过计算<a href="http://scikit-bio.org/docs/latest/generated/skbio.diversity.alpha.html" target="_blank" rel="noopener">各项α多样性指数</a>来表征α多样性的, 比如Shannon指数、ACE指数、Chao1指数等。</p><h3 id="9-1-计算指数和对应的指数稀释曲线"><a href="#9-1-计算指数和对应的指数稀释曲线" class="headerlink" title="9.1 计算指数和对应的指数稀释曲线"></a>9.1 计算指数和对应的指数稀释曲线</h3><p>alpha diversity index and rarefaction curve. 在alpha_rarefaction.py中，可以生成稀释OTU table，基于稀释表计算α多样性矩阵，然后画出稀释曲线图。可计算的α多样性指数有：ace, berger_parker_d, brillouin_d, chao1, chao1_ci, dominance, doubles, enspie, equitability, esty_ci, fisher_alpha, gini_index, goods_coverage, heip_e, kempton_taylor_q, margalef, mcintosh_d, mcintosh_e, menhinick, michaelis_menten_fit, observed_otus, observed_species, osd, simpson_reciprocal, robbins, shannon, simpson, simpson_e, singles, strong, PD_whole_tree</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定需要计算的α多样性指数</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'alpha_diversity:metrics simpson,shannon,PD_whole_tree,chao1,observed_species'</span> &gt; alpha_params.txt</span><br><span class="line">alpha_rarefaction.py -i otu_table.biom -o arare_max100/ -t rep_set.tre -m Fasting_Map.txt -e 100 -p alpha_params.txt</span><br><span class="line"><span class="comment"># -p &lt;parameter_fp&gt; 指定过程脚本对应的参数</span></span><br><span class="line"><span class="comment"># -n &lt;num_steps&gt; 指定进行抽样时的步数,不是步长, 是生成稀释OTU表的大小</span></span><br><span class="line"><span class="comment"># -w 只打印过程脚本，不运行</span></span><br><span class="line"><span class="comment"># -a 指定进行多线程</span></span><br><span class="line"><span class="comment"># -t &lt;tree_file&gt;指定计算系统发育指数的tree</span></span><br><span class="line"><span class="comment"># --min_rare_depth &lt;num&gt;指定抽样时的最小深度</span></span><br><span class="line"><span class="comment"># -e,--max_rare_depth &lt;num&gt; 指定抽样时的最大深度</span></span><br><span class="line"><span class="comment"># -O &lt;jobs_to_start&gt; 指定跳转到第几步开始执行,重新执行时十分有用</span></span><br><span class="line"><span class="comment"># -f 指定强制覆写文件</span></span><br><span class="line"><span class="comment"># --retain_intermediate_files 指定保留中间过程文件</span></span><br><span class="line"></span><br><span class="line">multiple_rarefactions.py -i ../04_pick_open_ref_otus/otu_table_mc2.biom \</span><br><span class="line">-m 10 -x 100 \</span><br><span class="line">-s 9 -o ./alpha/rarefaction/</span><br><span class="line">alpha_diversity.py -i ./alpha/rarefaction/ </span><br><span class="line">-o ./alpha/alpha_div/ \</span><br><span class="line">--metrics simpson,shannon,PD_whole_tree,chao1,observed-species \</span><br><span class="line">-t ../04_pick_open_ref_otus/rep_set.tre</span><br><span class="line">collate_alpha.py -i ./alpha/alpha_div/ \</span><br><span class="line">-o ./alpha/alpha_div_collated/</span><br><span class="line">rm -r ./alpha/rarefaction/ ./alpha/alpha_div/</span><br><span class="line">make_rarefaction_plots.py -i ./alpha/alpha_div_collated/ \</span><br><span class="line">-m ../map.tsv \</span><br><span class="line">-o ./alpha/alpha_rarefaction_plots/</span><br></pre></td></tr></table></figure><h3 id="9-2-Rank-abundance曲线"><a href="#9-2-Rank-abundance曲线" class="headerlink" title="9.2 Rank-abundance曲线"></a>9.2 Rank-abundance曲线</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 比较多个样品的排序-丰度曲线图；如果想比较一个OTU表里面的所有样品, -s '*' 即可</span></span><br><span class="line">plot_rank_abundance_graph.py -i otu_table.biom -s <span class="string">'PC.354,PC.481,PC.364'</span> -x -v -o rank_abundance.pdf</span><br><span class="line"><span class="comment"># -s &lt;sample_name&gt;画图的样品名</span></span><br><span class="line"><span class="comment"># -a,--absolute_counts 指定图中使用的数据是绝对丰度,</span></span><br><span class="line"><span class="comment"># -n,--no_legend 指定图中不画图例</span></span><br><span class="line"><span class="comment"># -x,--x_linear_scale 指定x轴要进行线性缩放</span></span><br><span class="line"><span class="comment"># -y,--y_linear_scale 指定y轴要进行线性缩放</span></span><br><span class="line"><span class="comment"># -f &lt;file_type&gt; 指定输出图的类型, pdf(default), svg, png, eps</span></span><br><span class="line"><span class="comment"># -v 输出过程信息</span></span><br></pre></td></tr></table></figure><h3 id="9-3-α多样性指数差异分析"><a href="#9-3-α多样性指数差异分析" class="headerlink" title="9.3 α多样性指数差异分析"></a>9.3 α多样性指数差异分析</h3><p>基于样品的多样性指数，可以检验组间样品的alpha diversity是否存在显著差异，检验方法可以是Wilcoxon秩和检验(2组样品)或者Kruskal-Willis秩和检验(多于两组).</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 汇总计算的所有alpha diversity index, 如果是执行了3.9.1,则不必执行本命令;</span></span><br><span class="line">collate_alpha.py -i alpha_div/ -o alpha_div_collated/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 比较alpha diversity index，按SampleType作为分组，得到每个diversity index下的成对组间统计</span></span><br><span class="line">ls alpha/alpha_div_collated/*.txt | <span class="keyword">while</span> <span class="built_in">read</span> div;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">name=`basename <span class="variable">$div</span> .txt`</span><br><span class="line">compare_alpha_diversity.py -i <span class="variable">$div</span> -m ../map.tsv -c SampleType -d 100 -o compare_alpha_div/<span class="variable">$name</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment"># 如果想把各个diversity index合在一张图,需要用额外的R代码</span></span><br></pre></td></tr></table></figure><h3 id="9-4-物种累积曲线-species-accumulation-curves"><a href="#9-4-物种累积曲线-species-accumulation-curves" class="headerlink" title="9.4 物种累积曲线  (species accumulation curves)"></a>9.4 物种累积曲线  (species accumulation curves)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># 可以使用R的vegan包</span><br></pre></td></tr></table></figure><h2 id="10-β-多样性分析-beta-diversity-analysis"><a href="#10-β-多样性分析-beta-diversity-analysis" class="headerlink" title="10 β 多样性分析  (beta diversity analysis)"></a>10 β 多样性分析  (beta diversity analysis)</h2><p><a href="http://www.omicshare.com/forum/thread-3251-1-1.html" target="_blank" rel="noopener">微生物群落差异分析方法大揭秘</a></p><h3 id="10-0-一步法进行PCoA分析"><a href="#10-0-一步法进行PCoA分析" class="headerlink" title="10.0 一步法进行PCoA分析"></a>10.0 一步法进行PCoA分析</h3><p>beta_diversity_through_plot.py可以进行β多样性分析、主坐标轴分析，并画出3D PCoA图. 首先该脚本会随机对输入的otu_table.biom进行抽样，以达到抽平每个样品的序列数目的目的。然后计算各个表征β多样性的距离矩阵。最后基于这些距离矩阵进行主坐标轴分析，并对结果进行可视化。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">beta_diversity_through_plots.py -i otu_table.biom -m map.tsv -o beta_diversity -e 100</span><br><span class="line"><span class="comment"># -t &lt;tree_fp&gt; 指定树的文件</span></span><br><span class="line"><span class="comment"># -p &lt;param_fp&gt; 指定中间命令的参数文件</span></span><br><span class="line"><span class="comment"># -f,-w 强制覆写和只打印命令不运行</span></span><br><span class="line"><span class="comment"># -a 指定多线程运行</span></span><br><span class="line"><span class="comment"># -e &lt;seqs_per_sample&gt; 进行样品抽平的覆盖深度</span></span><br><span class="line"><span class="comment"># --supress_emperor_plots</span></span><br><span class="line"><span class="comment"># -O,--jobs_to_start 跳转到第几步开始运行。</span></span><br></pre></td></tr></table></figure><h3 id="10-1-计算β多样性距离矩阵"><a href="#10-1-计算β多样性距离矩阵" class="headerlink" title="10.1 计算β多样性距离矩阵"></a>10.1 计算β多样性距离矩阵</h3><p>beta_diversity.py支持计算多种距离矩阵, 使用-s参数查看支持的矩阵.由于unifrac，还需要提供发育树作为输入。一般来讲，由于unifrac有用到系统发育信息，所以一般推荐使用unifrac。定量的距离矩阵(weighted)更适合用于揭示由于群落物种丰度引起的群落差异,而定性的距离矩阵更适用于因环境不同所导致的群落差异。</p><p><strong>2.10.2-2.10.5等分析均基于本步骤生成的距离矩阵进行后续的分析。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看支持的矩阵类型,然后选择想要计算的距离矩阵</span></span><br><span class="line">beta_diversity.py -s</span><br><span class="line">metrics=unweighted_unifrac,weighted_unifrac,bray_curtis,binary_jaccard</span><br><span class="line">beta_diversity.py -i 04_pick_open_ref_otus/otu_table_mc2.biom \</span><br><span class="line">   -o 05_beta_diversity \</span><br><span class="line">   --metrics <span class="variable">$metrics</span> \</span><br><span class="line">   -t 04_pick_open_ref_otus/rep_set.tre</span><br><span class="line"></span><br><span class="line">mv 05_beta_diversity/weighted_unifrac_otu_table_mc2.txt 05_beta_diversity/weighted_unifrac_distance_matrix.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># -i &lt;otu_table&gt; 指定输入otu_table, 可以以文件夹的形式指定多个</span></span><br><span class="line"><span class="comment"># -r &lt;rows&gt; 指定只计算指定行的距离矩阵,应该传入样品名,例如'S1,S3'之类的</span></span><br><span class="line"><span class="comment"># -m &lt;metrics&gt; 指定要计算的beta diversity matrix类型, 可以用逗号分隔指定多个,默认: unweighted_unifrac,weighted_unifrac</span></span><br><span class="line"><span class="comment"># -s &lt;show_metrics&gt; 显示支持的距离矩阵类型</span></span><br><span class="line"><span class="comment"># -t &lt;tree_file&gt; 指定输入的系统发育树</span></span><br><span class="line"><span class="comment"># -f &lt;full_tree&gt; 指定使用全部的系统树;OTU table与系统树不对应的话,使用全部整个系统树会导致很多额外的结果.</span></span><br></pre></td></tr></table></figure><h3 id="10-2-PCoA分析"><a href="#10-2-PCoA分析" class="headerlink" title="10.2 PCoA分析"></a>10.2 PCoA分析</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -i,-o还可以是文件夹用以进行批量计算</span></span><br><span class="line">principal_coordinates.py -i 05_beta_diversity/weighted_unifrac_dm.txt \</span><br><span class="line">-o 05_beta_diversity/weighted_unifrac_pc.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画2d图</span></span><br><span class="line">make_2d_plots.py -i weighted_unifrac_pc.txt -m map.tsv -o 2d_plots</span><br><span class="line"><span class="comment"># -b &lt;color_by&gt;以逗号分隔的metadata分类/组列名,用以指定着色分组。可以使用'col1&amp;&amp;col2'指定一致着色</span></span><br><span class="line"><span class="comment"># -k &lt;bg_color&gt;</span></span><br><span class="line"><span class="comment"># --ellipsoid_opacity 指定透明度,只在jackknifed beta diversity中有用</span></span><br><span class="line"><span class="comment"># --ellipsoid_method指定绘制的数据类型, IQR (default) 和 sdev, 只在jackknifed beta diversity中有用</span></span><br><span class="line"><span class="comment"># --master_pcoa</span></span><br><span class="line"><span class="comment"># --scree 绘制碎石图</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 画3d图</span></span><br><span class="line">make_emperor.py -i 05_beta_diversity/weighted_unifrac_pc.txt \</span><br><span class="line">-o 05_beta_diversity/weighted_unifrac_emperor_pcoa_plot/ \</span><br><span class="line">-m map.tsv</span><br><span class="line"></span><br><span class="line">make_emperor.py -i weighted_unifrac_pc.txt -m map.tsv \</span><br><span class="line">-b <span class="string">'Treatment&amp;&amp;DOB,Treatment'</span> \ <span class="comment"># 依据metadata进行着色</span></span><br><span class="line">-a DOB \ <span class="comment"># 指定一个轴为DOB</span></span><br><span class="line">-x <span class="string">'DOB:20060000'</span> \ <span class="comment"># 当自定义轴DOB出现缺失值或值错误时,指定为20060000</span></span><br><span class="line">-o emperor_colored</span><br><span class="line"><span class="comment"># 见https://biocore.github.io/emperor/build/html/scripts/make_emperor.html</span></span><br></pre></td></tr></table></figure><h3 id="10-3-PCA分析"><a href="#10-3-PCA分析" class="headerlink" title="10.3 PCA分析"></a>10.3 PCA分析</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PCA分析基于OTU表，运用方差分解，将样本间的差异反映在二维坐标图上，坐标轴是两个主成分。样本组成越相似在图中则越聚集。</span><br><span class="line">待续.</span><br></pre></td></tr></table></figure><h3 id="10-4-NMDS分析"><a href="#10-4-NMDS分析" class="headerlink" title="10.4 NMDS分析"></a>10.4 NMDS分析</h3><p>与 PCoA 一样， 非度量多维尺度分析（ NMDS, nonmetric multidimensional scaling） 可以基于任何类型的距离/非相似性矩阵对对象（样本） 进行排序，其区别在于 NMDS 不再是特征根排序技术，也不再以排序轴承载更多的方差为目的，因此 NMDS 排序图可以任意旋转、中心化和倒置。 NMDS 分析在多维空间内构建对象的初始结构， 并用迭代程序不断地调整对象位置， 目标是尽可能的最小化应力函数（ stress function， 取值 0~1），应力函数是排序空间内对象结果与原始距离矩阵之间相异程度的度量。如果预先设定的排序轴数量比较少（如二维、三维），则在相同轴数的情况下， NMDS往往能够获得比 PCoA 更少失真的对象之间的关系。</p><p>R包vegan可以进行NMDS分析和作图。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nmds.py -i unweighted_unifrac_dm.txt -d 3 -o unweighted_unifrac_nmds.txt</span><br><span class="line"># -i,-o 如果-i指定的是文件夹，那么就进行批量分析</span><br><span class="line"># -d &lt;dimensions&gt; 指定NMDS分析的排序轴数量</span><br></pre></td></tr></table></figure><h3 id="10-5-ADONIS、ANOSIM分析"><a href="#10-5-ADONIS、ANOSIM分析" class="headerlink" title="10.5 ADONIS、ANOSIM分析"></a>10.5 ADONIS、ANOSIM分析</h3><p>通过compare_categories.py，我们可以比较不同组样品的聚类结果是否有显著性差异，该脚本提供多种方法，根据方法不同输出结果不同，但大多数是tsv文件。</p><p><strong>adonis</strong>, 又叫permanova, 是一种非参数检验方法。能够给出不同分组因素对样品差异的解释度（R值）与分组显著性（P值），它首先计算数据的相关性重心，然后计算这些重心点的平方偏差(R^2);最后基于原始数据的排列平方和进行F-test; 它以距离矩阵和mapping file作为输入，比如Unifrac聚类矩阵，通过指定分组列来进行比较。</p><p><strong>anosim</strong>,相似性分析，也是检验多组样本之间是否具有显著性差异，与adonis相似。但是它只对类别性变量有用，如果数据是连续型变量，推荐使用Mantel。它的计算公式为R=(rb-rw)/(N(N-1)/4)。其中rb指组间的所有距离的平均排名，rw指组内所有距离的平均排名。</p><p>adnois和anosim分析都只能衡量组与组之间整体是否有显著差异, 无法找到是哪个具体的OTU导致的该差异。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 看HOST_SUBJECT_ID分组的组间结果是否会有差异</span></span><br><span class="line">compare_categories.py --method adonis -i unweighted_unifrac_dm.txt -m map.txt -c HOST_SUBJECT_ID -o adonis_out -n 999</span><br><span class="line"><span class="comment"># --method &lt;method&gt; 指定统计方法, adonis,anosim</span></span><br><span class="line"><span class="comment"># -i  &lt;distance_matrix&gt; 指定输入的距离矩阵</span></span><br><span class="line"><span class="comment"># -m &lt;mapping_file&gt; 指定输入的mapping file</span></span><br><span class="line"><span class="comment"># -c &lt;group/category&gt;指定进行差异分析的分组方式</span></span><br><span class="line"><span class="comment"># -n &lt;permutations_num&gt;指定进行计算p-value的排名数(前多少名)</span></span><br></pre></td></tr></table></figure><h3 id="10-6-样本聚类树图"><a href="#10-6-样本聚类树图" class="headerlink" title="10.6 样本聚类树图"></a>10.6 样本聚类树图</h3><p>样本聚类树可以从整体上描述和比较样本/分组见的相似性和差异性. 采用的聚类方法是UPGMA (unweighted pair group method with arithmetic mean, <a href="http://www.nmsr.org/upgma.htm)" target="_blank" rel="noopener">http://www.nmsr.org/upgma.htm)</a>, 这里以使用unweighted_unifrac聚类矩阵为例.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># unweighted_unifrac_dm.txt来源于3.10.1</span><br><span class="line">upgma_cluster.py -i unweighted_unifrac_dm.txt -o unweighted_unifrac_cluster.tre</span><br><span class="line"></span><br><span class="line"># 如果要探究生成的聚类树的健壮性的话，就进行jackknifed_beta_diversity分析</span><br><span class="line"># otu_table.biom是unweighted_unifrac_dm.txt的计算来源table</span><br><span class="line">jackknifed_beta_diversity.py -i otu_table.biom -o bdiv_jk100 -e 100 -m map.tsv -t rep_set.tre</span><br></pre></td></tr></table></figure><h3 id="10-7-Lefse分析"><a href="#10-7-Lefse分析" class="headerlink" title="10.7 Lefse分析"></a>10.7 Lefse分析</h3><p>线性判别分析（ LDA）效应量方法<br><a href="http://www.omicshare.com/forum/forum.php?mod=viewthread&amp;tid=563&amp;extra=page%3D1%26filter%3Dtypeid%26typeid%3D31" target="_blank" rel="noopener">http://www.omicshare.com/forum/forum.php?mod=viewthread&amp;tid=563&amp;extra=page%3D1%26filter%3Dtypeid%26typeid%3D31</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">conda install lefse -y</span><br><span class="line">conda install rpy2=2.8.6 -y</span><br><span class="line"><span class="comment"># 如果出现rpy2与matplotlib有conflict,删除matplotlib,先安装rpy2,后安装matplotlib</span></span><br><span class="line">conda remove matplotlib --force</span><br><span class="line"><span class="comment"># 如果有某个包总是断网下载不下来（得到该包的版本）,先安装这个包，再去安装rpy2</span></span><br><span class="line"><span class="comment"># https://anaconda.org/，下载对应包的对应版本</span></span><br><span class="line">conda install --use-local package_name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 先转化biom为TSV文件, 注意--header-key是taxonomy,非Taxonomy</span></span><br><span class="line">biom convert -i illumina/04_pick_open_ref_otus/otu_table_mc2_w_tax.biom -o otu_consensus.txt --to-tsv --header-key taxonomy --output-metadata-id <span class="string">"Consensus Lineage"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 转化为lefse的初始格式,设定分组、亚组和个体信息; 这里十分重要</span></span><br><span class="line">qiime2lefse.py --<span class="keyword">in</span> otu.txt \</span><br><span class="line">    --md illumina/map.tsv \</span><br><span class="line">    --out otu_lefse.txt \</span><br><span class="line">    -c SampleType \</span><br><span class="line">    -u Subject</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 3. 转换为lefse接受的格式</span></span><br><span class="line">lefse-format_input.py otu_lefse.txt otu_lefse.in -c 1 -s -1 -u 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 走正常的分析流程</span></span><br><span class="line">run_lefse.py otu_lefse.in otu_lefse.res</span><br><span class="line">lefse-plot_res.py otu_lefse.res otu_lefse.png</span><br><span class="line">lefse-plot cladogram.py otu_lefse_res otu_lefse.cladogram.png --format png</span><br><span class="line">mkdir biomarkers_raw_image</span><br><span class="line">lefse-plot_features.py otu_lefse.in otu_lefse.res biomarkers_raw_images/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 扩增子 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>扩增子测序 QIIME2使用示例</title>
      <link href="/2018/10/15/%E6%89%A9%E5%A2%9E%E5%AD%90%E6%B5%8B%E5%BA%8F-QIIME2%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/"/>
      <url>/2018/10/15/%E6%89%A9%E5%A2%9E%E5%AD%90%E6%B5%8B%E5%BA%8F-QIIME2%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<p><strong>如果数据来源是分批次的话，需要分别导入，在去噪和生成特征表之后，把这些表进行合并，再进行后续分析。也就是说 1-3 对于分批次数据要分批次跑。</strong></p><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget -O sample_metadata.tsv https://data.qiime2.org/2018.6/tutorials/moving-pictures/sample_metadata.tsv</span><br><span class="line">mkdir emp-single-end-sequences</span><br><span class="line">wget -O emp-single-end-sequences/barcodes.fastq.gz https://data.qiime2.org/2018.6/tutorials/moving-pictures/barcodes.fastq.gz</span><br><span class="line">wget -O emp-single-end-sequences/sequences.fastq.gz https://data.qiime2.org/2018.6/tutorials/moving-pictures/sequences.fastq.gz</span><br></pre></td></tr></table></figure><h2 id="1-导入数据到QIIME2"><a href="#1-导入数据到QIIME2" class="headerlink" title="1 导入数据到QIIME2"></a>1 导入数据到QIIME2</h2><p>注意，metadata要放在input-path外部，同级存放。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">qiime tools import \</span><br><span class="line">--<span class="built_in">type</span> EMPSingleEndSequences \</span><br><span class="line">--input-path emp-single-end-sequences \</span><br><span class="line">--output-path emp-single-end-sequences.qza</span><br></pre></td></tr></table></figure><h2 id="2-拆分序列"><a href="#2-拆分序列" class="headerlink" title="2 拆分序列"></a>2 拆分序列</h2><p>在QIIME1中，我们通常使用split_libraries.py / split_libraries_fastq.py进行拆分序列，并同时进行质量过滤。但是在QIIME2中，序列拆分和质量过滤分开进行。所以你既可以从未拆分序列开始，也可以从已拆分序列开始。这里我们从未拆分的序列开始。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拆分序列</span></span><br><span class="line">qiime demux emp-single \</span><br><span class="line">--i-seqs emp-single-end-sequences.qza \</span><br><span class="line">--m-barcodes-file sample-metadata.tsv \</span><br><span class="line">--m-barcodes-column BarcodeSequence \</span><br><span class="line">--o-per-sample-sequences demux.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计拆分后的序列，了解每个样品有多少序列和序列碱基质量值分布</span></span><br><span class="line">qiime demux summarize --i-data demux.qza --o-visualization demux.qzv</span><br></pre></td></tr></table></figure><p>在qiime2中，凡是通过–o-visualiztion参数生成的.qzv文件都可以通过qiime tools view来查看。如果是headless环境的话，你可以把.qzv文件解压，下载到本地来查看。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qiime tools view demux.qzv</span><br></pre></td></tr></table></figure><h2 id="3-序列质控和构建特征表（feature-table）"><a href="#3-序列质控和构建特征表（feature-table）" class="headerlink" title="3 序列质控和构建特征表（feature  table）"></a>3 序列质控和构建特征表（feature  table）</h2><p>QIIME2中有许多中质控方法可供选择，比如DADA2、Deblur和基于质量分数过滤。这里我们使用DADA2和Deblur来进行质控，你可以选择任何一个方法。这些方法都会生成一个特征表( FeatureTable[Frequency])和特征数据( FeatureData[Frequency] )，前者包含每个样品中每条唯一序列的counts(frequences)，后者包含特征标识在特征表中对应的序列。FeatureTable与QIIME1中的OTU或biom表相对应，FeatureData同QIIME1中的rep_seqs.fna(代表序列)相对应。因为DADA2和Deblur的结果是通过聚类唯一序列得到的，所以这些结果与QIIME1得到的OTUs是一致的。但是在QIIME2中，获得的OTUs分辨率更高，这是因为在QIIME2中的质控效果更好。</p><h3 id="3-1-DADA2"><a href="#3-1-DADA2" class="headerlink" title="3.1 DADA2"></a>3.1 DADA2</h3><p>DADA2是一个检测和校正Illumina扩增测序数据的流程，里面的质控步骤会额外地过滤任何在测序数据中的phiX reads和嵌合序列。dada2 denoise-single方法需要2个参数用于质量过滤：–p-trim-left m, 会把序列的前m个碱基进行修剪, –p-trunc-len n, 会在第n个碱基处截断序列。这允许用户去除低质控的序列区域。具体的m和n值，你应该查看拆分序列后的序列质量统计结果才能确定。根据demux.qzv的结果，可以确定m=0，n=120.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 去噪和构建</span></span><br><span class="line">qiime dada2 denoise-single \</span><br><span class="line">--i-demultiplexed-seqs demux.qza \</span><br><span class="line">--p-trim-left 0 \</span><br><span class="line">--p-trunc-len 120 \</span><br><span class="line">--o-representative-sequences rep-seqs-dada2.qza \</span><br><span class="line">--o-table table-dada2.qza \</span><br><span class="line">--o-denoising-stats stats-dada2.qza</span><br><span class="line"></span><br><span class="line"><span class="comment">## 把获得stats-dada2.qza统计数据变成可视化的结果</span></span><br><span class="line">qiime metadata tabulate \</span><br><span class="line">--m-input-file stats-dada2.qza \</span><br><span class="line">--o-visualization stats-dada2.qzv</span><br></pre></td></tr></table></figure><h3 id="3-2-Deblur"><a href="#3-2-Deblur" class="headerlink" title="3.2 Deblur"></a>3.2 Deblur</h3><p>Deblur使用序列错误分析来获得高质量的序列数据，这里面经历了2个步骤，第一步就是基于质量分数进行质量过滤。第二步是使用qiime deblur denoise-16s方法。这个方法需要–p-trim-length n来截断第n位碱基。通常推荐n值取质量值中值开始下降到较低值时的碱基位置。根据前面的demux.qzv中质量分布图，115-130的质量值显著下降。在有些情况下，比如同时分析多批次的测序数据时，你要保证所有的序列都是等长的，以避免出现study-specific bias。由于我们在dada2中使用了120的长度，这里同样使用120.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 质量过滤</span></span><br><span class="line">qiime quality-filter q-score \</span><br><span class="line">--i-demux demux.qza \</span><br><span class="line">--o-filtered-sequences demux-filtered.qza \</span><br><span class="line">--o-filter-stats demux-filter-stats.qza</span><br><span class="line"><span class="comment"># 过滤后可视化</span></span><br><span class="line">qiime metadata tabulate \</span><br><span class="line">--m-input-file demux-filter-stats.qza \</span><br><span class="line">--o-visualization demux-filter-stats.qzv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去噪和构建</span></span><br><span class="line">qiime deblur denoise-16S \</span><br><span class="line">--i-demultiplexed-seqs demux-filtered.qza \</span><br><span class="line">--p-trim-length 120 \</span><br><span class="line">--o-representative-sequences rep-seqs-deblur.qza \</span><br><span class="line">--o-table table-deblur.qza \</span><br><span class="line">--p-sample-stats \</span><br><span class="line">--o-stats deblur-stats.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化特种表</span></span><br><span class="line">qiime deblur visualize-stats \</span><br><span class="line">--i-deblur-stats deblur-stats.qza \</span><br><span class="line">--o-visualization deblur-stats.qzv</span><br></pre></td></tr></table></figure><h2 id="4-特种表和特征数据统计"><a href="#4-特种表和特征数据统计" class="headerlink" title="4 特种表和特征数据统计"></a>4 特种表和特征数据统计</h2><p>在完成质控和构建之后，你可能想探索一下生成的结果，feature-table summarize可以对特征表(‘OTUs’)做各种统计图；feature-table tabulate-seqs可以生成特征标识符和序列的映射文件，让你易于进行BLAST. 后续的可视化对于你了解特征表的各个细节大有裨益。</p><p>需要注意的是，正如开头所言，如果你的数据是分批次的话，那你应该先把各个特征表进行合并。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可选，合并分批次的特征表, 这里的rep-seqs-1/2.qza就是4.3中--o-representative-sequences参数指定的输出</span></span><br><span class="line">qiime feature-table merge \</span><br><span class="line">--i-tables table-1.qza \</span><br><span class="line">--i-tables table-2.qza \</span><br><span class="line">--o-merged-table table-merge.qza</span><br><span class="line">qiime feature-table merge-seqs \</span><br><span class="line">--i-data rep-seqs-1.qza \</span><br><span class="line">--i-data rep-seqs-2.qza \</span><br><span class="line">--i-merged-data rep-seqs.qza</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里使用deblur生成的表，如果要接上合并分批次的特征表，type=merge</span></span><br><span class="line"><span class="built_in">type</span>=<span class="string">'deblur'</span></span><br><span class="line">qiime feature-table summarize \</span><br><span class="line">--i-table table-<span class="variable">$&#123;type&#125;</span>.qza \</span><br><span class="line">--o-visualization table.qzv \</span><br><span class="line">--m-sample-metadata-file sample-metadata.tsv</span><br><span class="line"></span><br><span class="line">qiime feature-table tabulate-seqs \</span><br><span class="line">--i-data rep-seqs-<span class="variable">$&#123;type&#125;</span>.qza \</span><br><span class="line">--o-visualization rep-seqs.qzv</span><br></pre></td></tr></table></figure><h2 id="5-生成系统发育树用于多样性分析"><a href="#5-生成系统发育树用于多样性分析" class="headerlink" title="5 生成系统发育树用于多样性分析"></a>5 生成系统发育树用于多样性分析</h2><p>QIIME2支持多个系统多样性矩阵，包含Faith’s Phylogenetic diversity和weighted/unweighted UniFrac.除了计算每个样品的counts (比如FeatureTable[Frequency]的数据) 以外, 这些多样性矩阵需要一个根系统发育树将各个特征联系起来。这个信息存储在 Phylogeny[Rooted]中，本步的目的就是生成这样一个Phylogeny[Rooted]文件。<br>首先我们需要使用qiime alignment mafft对代表序列进行比对。<br>然后我们用qiime alignment mask 把序列中的高度可变区屏蔽掉，因为这些区域会影响发育树的生成。<br>接着使用qiime phylogeny fasttree生成聚类树，这是一个无根树<br>最后，我们用qiime phylogeny midpoint-root，把无根树的中点节点作为其midpoint-root。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 这里仍然使用deblur的表</span><br><span class="line">type=&apos;deblur&apos;</span><br><span class="line"># 1. 比对</span><br><span class="line">qiime alignment mafft \</span><br><span class="line">--i-sequences rep-seqs-$&#123;type&#125;.qza \</span><br><span class="line">--o-alignment aligned-rep-seqs.qza</span><br><span class="line"># 2. 屏蔽高变区</span><br><span class="line">qiime alignment mask \</span><br><span class="line">--i-alignment aligned-rep-seqs.qza \</span><br><span class="line">--o-masked-alignment masked-aligned-rep-seqs.qza</span><br><span class="line"># 3. 生成无根树</span><br><span class="line">qiime phylogeny fasttree \</span><br><span class="line">--i-alignment masked-aligned-rep-seqs.qza \</span><br><span class="line">--o-tree unrooted-tree.qza</span><br><span class="line"># 4. 转化为有根树</span><br><span class="line">qiime phylogney midpoint-root \</span><br><span class="line">--i-tree unrooted-tree.qza \</span><br><span class="line">--o-rooted-tree rooted-tree.qza</span><br></pre></td></tr></table></figure></p><h2 id="6-alpha和beta多样性分析"><a href="#6-alpha和beta多样性分析" class="headerlink" title="6 alpha和beta多样性分析"></a>6 alpha和beta多样性分析</h2><p>qiime2的多样性分析可以通过q2-diversity插件实现，它支持计算alpha和beta多样性矩阵、相关的统计检验、生成交互可视化表等。我们首先使用core-metrics-phylogenetic方法，根据用户指定的深度(–p-sampling-depth)进行抽样，从而计算多样性矩阵，生成PCoA图。默认计算的矩阵类型有如下这些：</p><ul><li>alpha diversity</li><li><ul><li>Shannon’s diversity index : 群落丰富度的定量指标</li></ul></li><li><ul><li>Observed OTUs: 群落丰富度的定性指标</li></ul></li><li><ul><li>Faith’s Phylogenetic Diversity: 群落丰富度的定性指标，考虑各个特征之间的系统发育关系</li></ul></li><li><ul><li>Pielou’s Evenness: 群落均匀度的指标</li></ul></li><li><p>beta diversity</p></li><li><ul><li>Jaccard distanc： 群落相异性(群落多样性)的定性指标</li></ul></li><li><ul><li>Bray-Curits distance: 群落相异性(群落多样性)的定量指标</li></ul></li><li><ul><li>unweighted UniFrac distance: 群落相异性(群落多样性)的定性指标，考虑到各个特征之间的系统发育关系</li></ul></li><li><ul><li>weighted UniFrac distance：群落相异性(群落多样性)的定量指标，考虑到各个特征之间的系统发育关系</li></ul></li></ul><p>值得注意的是，–p-samping-depth的值是十分重要的，因为不同的抽样深度，最后统计出来的结果是不一样的，多样性矩阵对此很敏感。如果有样品的序列counts低于这个设定值时，这个样品将被丢弃。这个值的选择可以根据前面生成的特征表统计结果来选择（第四步的table.qzv)。如果数据量都很大，选最小的就好。但是有异常小的值，去掉这个值再选最小的。</p><h3 id="6-1-计算多样性矩阵"><a href="#6-1-计算多样性矩阵" class="headerlink" title="6.1 计算多样性矩阵"></a>6.1 计算多样性矩阵</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">qiime diversity core-metrics-phylogenetic \</span><br><span class="line">--i-phylogeny rooted-tree.qza \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--p-sampling-depth 653 \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--output-dir core-metrics-results</span><br></pre></td></tr></table></figure><h3 id="6-2-alpha-diversity-analysis"><a href="#6-2-alpha-diversity-analysis" class="headerlink" title="6.2 alpha diversity analysis"></a>6.2 alpha diversity analysis</h3><p>在计算完多样性矩阵之后，我们可以探究各个样品中的微生物群落组成。<br>首先我们检验一下metadata中类别与alpha 多样性之间的联系，这里我们使用Faith Phylogenetic Diversity和evenness metrics来计算。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">qiime diversity alpha-group-significance \</span><br><span class="line">--i-alpha-diversity core-metrics-results/faith_pd_vector.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--o-visualization core-metrics-results/faith-pd-group-significance.qzv</span><br><span class="line"></span><br><span class="line">qiime diversity alpha-group-significance \</span><br><span class="line">--i-alpha-diversity core-metrics-results/evenness_vector.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--o-visualization core-metrics-results/evenness-group-significance.qzv</span><br></pre></td></tr></table></figure><p>如果想探究某个条件同群落多样性（alpha diversity relation）的相关性的话，可以使用qiime diversity alpha-correlation来检验。</p><h3 id="6-3-beta-diversity-analysis"><a href="#6-3-beta-diversity-analysis" class="headerlink" title="6.3 beta diversity analysis"></a>6.3 beta diversity analysis</h3><p>接下来我们分析特定分组下的样品组成，这里使用permanova统计方法，命令是qiime diversity beta-group-significance. 它将探究组内样品的距离与组间样品的距离的差异所在。–p-pairwise用于设定成对检验，比如本例中可以是gut vs. tongue。下面我们将检验不同组之间的unweighted UniFrac distance差异。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分组为 BodySite, 统计unweighted_unifrace距离的组间是否有显著差异</span></span><br><span class="line">qiime diversity beta-group-significance \</span><br><span class="line">--i-distance-matrix core-metrics-results/unweighted_unifrac_distance_matrix.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--m-metadata-column BodySite \</span><br><span class="line">--o-visualization core-metrics-results/unweighted-unifrac-body-site-significance.qzv \</span><br><span class="line">--p-pairwise</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分组为Subject, 统计unweighted_unifrace距离的组间是否有显著差异</span></span><br><span class="line">qiime diversity beta-group-significance \</span><br><span class="line">--i-distance-matrix core-metrics-results/unweighted_unifrac_distance_matrix.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--m-metadata-column Subject \</span><br><span class="line">--o-visualization core-metrics-results/unweighted-unifrac-subject-significance.qzv \</span><br><span class="line">--p-pairwise</span><br></pre></td></tr></table></figure><p>由于这里没有数据与样品的组成有关，我们就没有检验其中的关系。如果你对检验某个条件/分组对样品组成(sample composition)的相关性的话，可以结合使用qiime metadata distance-matrix, qiime diversity mantel, qiime diversity bioenv三个命令来实现。</p><h3 id="6-4-PCoA分析"><a href="#6-4-PCoA分析" class="headerlink" title="6.4 PCoA分析"></a>6.4 PCoA分析</h3><p>最后，分类是探究微生物群落组成的流行方法。我们可以使用Emperor工具来进行PCoA分析。虽然前面qiime diversity core-metrics-phylogenetic 生成了一些PCoA图，但是我们可以使用–p-custom-axes来个性化这个分析，这对探究时间序列数据十分有用。这里我们使用unweihted UniFrac和Bray-Curtis来进行PCoA分析，新的分析将加入daysSinceExperimentStart作为轴，以此来探究样品随时间的变化情况。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 三维可视化展示unweighted_unifrac的PCoA分析</span><br><span class="line">qiime emperor plot \</span><br><span class="line">--i-pcoa core-metrics-results/unweighted_unifrac_pcoa_results.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--p-custom-axes DaysSinceExperimentStart \</span><br><span class="line">--o-visualization core-metrics-results/unweighted-unifrac-emperor-DaysSinceExperimentStart.qzv</span><br><span class="line"># 三维可视化展示unweighted_unifrac的PCoA分析</span><br><span class="line">qiime emperor plot \</span><br><span class="line">--i-pcoa core-metrics-results/bray_curtis_pcoa_results.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--p-custom-axes DaysSinceExperimentStart \</span><br><span class="line">--o-visualization core-metrics-results/bray_curtis-emperor-DaysSinceExperimentStart.qzv</span><br></pre></td></tr></table></figure><h2 id="7-alpha稀释性曲线分析"><a href="#7-alpha稀释性曲线分析" class="headerlink" title="7 alpha稀释性曲线分析"></a>7 alpha稀释性曲线分析</h2><p>稀释性曲线(rarefaction curve)：一般是从样本中随机抽取一定数量的个体，统计出这些个体所代表物种数目，并以个体数与物种数来构建曲线。它可以用来比较测序数量不同的样本物种的丰富度，也可以用来说明样本的取样大小是否合理。分析采用对优化序列进行随机抽样的方法，以抽到的序列数与它们所能代表OTU的数目构建rarefaction curve。稀释性曲线图中，当曲线趋向平坦时，说明取样的数量合理，更多的取样只会产生少量新的OTU，反之则表明继续取样还可能产生较多新的OTU。因此，通过作稀释性曲线，可以得出样品的取样深度情况。<br>接下来我将使用qiime diversity alpha-rarefaction来探究抽样深度(sampling depth)与alpha diversity的关系。该命令将计算不同抽样深度下的一至多个α多样性矩阵，抽样深度由–p-min-depth/–p-max-depth指定。在每个抽样深度下，有10个多样性矩阵稀释表生成，稀释表迭代次数可由–p-iterations指定.你可以通过–me-metadata-file指定metadata进行样品分组。</p><p>生成的可视化文件有2个图。上面的那个图是alpha稀释曲线，注意用于判定样品的群落丰富度是否已经完全被观测/测序到。如果该曲线趋于平滑的话，表明对应x轴的抽样深度已经足以发现所有的群落种类（物种）。下面的那个图在有分组的时候很重要。它表明了抽样稀释时各个组剩余的样品数。如果抽样的深度d大于某样品的总计counts的话，往后的深度该样品就无法进行抽样了。这个图显示这在一定抽样深度下，稀释曲线的可信度。如果在某个抽样深度时，有某个组的剩余样品数为0，那么在该抽样深度下计算个多样性矩阵值就不可靠。</p><p>因此，你设定的–p-max-depth的值应该根据特征表统计的可视化图来选择，一般选择median frequency的值。如果稀释性曲线结果不好的话，可以适当提高或降低，但通常不能超出[low total frequency, max total frequency]的范围。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">qiime diversity alpha-rarefaction \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--i-phylogeny rooted-tree.qza \</span><br><span class="line">--p-max-depth 4000 \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--o-visualization alpha-rarefaction.qzv</span><br></pre></td></tr></table></figure><h2 id="8-物种分类"><a href="#8-物种分类" class="headerlink" title="8 物种分类"></a>8 物种分类</h2><p>接下来，我们将探究样品的物种组成，并将其同样品表型信息联系起来。</p><p>第一步要对特征序列进行物种注释, 这里用到前面生成的特征数据(FeatureData[Sequence]).我们将使用一个预先训练过的朴素贝叶斯分类器(native bayes classifier)和q2-feature-classifier插件。这个分类器用Greengenes 13_8 99% OTUs (16s, 250 bases, v4 region, 515F/806R)的数据训练过。</p><p>值得注意的是，物种分类器在经过你的特有样品类似产生的数据训练后将表现更好，所以你可以用自己的数据完成<a href="https://docs.qiime2.org/2018.6/tutorials/feature-classifier/" target="_blank" rel="noopener">分类器的训练</a>。在<a href="https://docs.qiime2.org/2018.6/data-resources/" target="_blank" rel="noopener">资源页面</a>中，我们有提供其他数据类型训练过的分类器,你需要下载你数据的相同类型数据训练过的分类器来进行后续的分析。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 进行物种分类</span><br><span class="line">wget https://data.qiime2.org/2018.6/common/gg-13-8-99-515-806-nb-classifier.qza</span><br><span class="line">qiime feature-classifier classify-sklearn \</span><br><span class="line">--i-classifier gg-13-8-99-515-806-nb-classifier.qza \</span><br><span class="line">--i-reads rep-seqs.qza \</span><br><span class="line">--o-classification taxonomy.qza</span><br><span class="line"># 可视化分类结果</span><br><span class="line">qiime metadata tabulate \</span><br><span class="line">--m-input-file taxonomy.qza \</span><br><span class="line">--o-visualization taxonomy.qzv</span><br><span class="line"># 物种分类柱状图</span><br><span class="line">qiime taxa barplot \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--i-taxonomy taxonomy.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--o-visualization taxa-bar-plots.qzv</span><br></pre></td></tr></table></figure><h2 id="9-ANCOM-微生物组成-丰度差异分析"><a href="#9-ANCOM-微生物组成-丰度差异分析" class="headerlink" title="9 ANCOM (微生物组成/丰度差异分析)"></a>9 ANCOM (微生物组成/丰度差异分析)</h2><p>ANCOM，analysis of composition of microbiomes，可以用于确定不同样品间的微生物组成的丰度差异特征，在使用之前，你应该了解使用ANCOM的假设和局限性。丰度差异分析的研究比较活跃，目前已经有两个插件可以用于这个分析：q2-gneiss和q2-composition，这里我们使用q2-composition，如果你感兴趣的话，可以<a href="https://docs.qiime2.org/2018.6/tutorials/gneiss/" target="_blank" rel="noopener">在这里学习前者的使用</a>.</p><p>ANCOM假定只有少于25%的features会在样品之间发生改变。如果你确信你的研究有更多的features会发生改变，你应该舍弃ANCOM的使用，因为这将产生更多的错误，不论是一类还是二类错误。由于在各个身体部位的样品之间的丰度变化应该很大，所以我们只使用gut组样品进行这个分析。<br>在提取出gut组的特征表后，使用ANCOM分析该表。ANCOM基于每个样品的特征频率，但是不能容忍0值的存在。这里分为2步。首先要生成组成特征表(FeatureTable[Composition]),然后才能进行差异分析。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对特征表进行过滤，只剩gut组</span></span><br><span class="line">qiime feature-table filter-samples \</span><br><span class="line">--i-table table.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--p-where <span class="string">"BodySite='gut'"</span> \</span><br><span class="line">--o-filtered-table gut-table.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加假的count（0值不容忍），生成组成特征表</span></span><br><span class="line">qiime composition add-pseudocount \</span><br><span class="line">--i-table gut-table.qza \</span><br><span class="line">--o-composition-table comp-gut-table.qza</span><br><span class="line"></span><br><span class="line"><span class="comment"># ANCOM分析</span></span><br><span class="line">qiime composition ancom \</span><br><span class="line">--i-table comp-gut-table.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--m-metadata-column Subject \</span><br><span class="line">--o-visualization ancom-Subject.qzv</span><br></pre></td></tr></table></figure><p>有时候，我们会在特定的分类水平进行丰度差异分析，为了实现这个目标，我们可以对特征频数表进行聚合，然后再做ANCOM分析。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在level 6的分类水平聚合数据</span></span><br><span class="line">qiime taxa collapse \</span><br><span class="line">--i-table gut-table.qza \</span><br><span class="line">--i-taxonomy taxonomy.qza \</span><br><span class="line">--p-level 6</span><br><span class="line">--o-collapsed-table gut-table-L6.qza</span><br><span class="line"></span><br><span class="line">qiime composition add-pseudocount \</span><br><span class="line">--i-table gut-table-L6.qza \</span><br><span class="line">--o-composition-table comp-gut-table-L6.qza</span><br><span class="line"></span><br><span class="line">qiime composition ancom \</span><br><span class="line">--i-table comp-gut-table-L6.qza \</span><br><span class="line">--m-metadata-file sample-metadata.tsv \</span><br><span class="line">--m-metadata-column Subject \</span><br><span class="line">--o-visualization L6-ancom-Subject.qzv</span><br></pre></td></tr></table></figure><h2 id="10-成对差异比较-时间序列分析"><a href="#10-成对差异比较-时间序列分析" class="headerlink" title="10 成对差异比较/时间序列分析"></a>10 成对差异比较/时间序列分析</h2><p>这部分是从fecal microbiota transplant教程里面整合的，主要使用的qiime longitudinal模块。要适应前面的数据，进行更改即可，具体的用法可以见<strong>第三节 3.7 使用q2-longitudinal进行纵向和成对差异比较</strong>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里有2个坑</span></span><br><span class="line"><span class="comment"># 第一个是metadata里面donor的行在week列的值都为-1；而我们设定的值是0和18的比较。要把donor行都去掉</span></span><br><span class="line"><span class="comment"># 第二个是pairwise-difference里面的metadata，evenness_vector对应的metric列名是pielou_e。</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 扩增子 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ChIP-seq专题 MACS2_ChIPSeeker_deeptools</title>
      <link href="/2018/10/14/ChIP-seq%E4%B8%93%E9%A2%98-MACS2_ChIPSeeker_deeptools/"/>
      <url>/2018/10/14/ChIP-seq%E4%B8%93%E9%A2%98-MACS2_ChIPSeeker_deeptools/</url>
      
        <content type="html"><![CDATA[<p>ChIP-seq是使用抗体捕获富集DNA片段和高通量测序技术来获得某些marker与DNA的结合位点的一项综合技术。ChIP是染色质免疫共沉淀, 通过特异抗体将DNA结合蛋白免疫沉淀, 用于捕获蛋白质的DNA靶点, 比如转录因子啊, 组蛋白修饰啊. 它主要分为以下四步：cross-linking、sonication、IP、Sequencing。在DNA与蛋白交联以后, 通过超声的方式随机打断染色体, 在利用抗体将目的交联物筛选出来, 再反交联获取DNA,最后上机测序.获取到测序数据后,典型的分析流程如图.</p><p><img src="http://mmbiz.qpic.cn/mmbiz_jpg/MPBFtnFrw4m2jWmOk9ic1ZkZ8VrQBrr8oCMwfEZDZG75OY3ic9qMqHhibpiafgZVfJaCSp7gqI87ETibVltjV4GgXkQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="ChIP分析流程"></p><a id="more"></a><p>文字版: rawdata -&gt; QC -&gt; mapping -&gt; peak calling(binding site) -&gt; visualization/annotation/MotifAnalysis.<br>在peak calling完成之后,我们首先会可视化看一下数据，接下来就会想知道这些peak都和什么样的基因有关. </p><h2 id="一、Overview"><a href="#一、Overview" class="headerlink" title="一、Overview"></a>一、Overview</h2><h3 id="1-1-抗体的种类"><a href="#1-1-抗体的种类" class="headerlink" title="1.1 抗体的种类"></a>1.1 抗体的种类</h3><ul><li>转录因子或抑制因子(transcription factors/repressors)如CTCT</li><li>组蛋白或组蛋白修饰(histones/histone modifications)如H3/H3K4me3</li><li>DNA修饰(DNA modfications)如DNA甲基化</li><li>染色质重塑蛋白(chromatin remodelling proteins)如BMI1</li><li>其他转录机制相关蛋白(transcription machinery)如Pol2</li></ul><h3 id="1-2-实验结果简要展示"><a href="#1-2-实验结果简要展示" class="headerlink" title="1.2 实验结果简要展示"></a>1.2 实验结果简要展示</h3><p><img src="https://s1.ax1x.com/2018/10/14/iUEKwq.png" alt="ChIP结果简要展示"></p><h3 id="1-3-富集的类型"><a href="#1-3-富集的类型" class="headerlink" title="1.3 富集的类型"></a>1.3 富集的类型</h3><p>经过抗体富集的DNA可以是单个结合点，也可以是较宽的结合区域，当然也可能是任何地方。</p><p><img src="https://s1.ax1x.com/2018/10/14/iUElkV.png" alt="type of enrichment"></p><h3 id="1-4-表征结果的形式"><a href="#1-4-表征结果的形式" class="headerlink" title="1.4. 表征结果的形式"></a>1.4. 表征结果的形式</h3><p>ChIP测的是富集, 而且是相对富集, 就是指A/B两个区域的富集信号的富集差别.如果要得到绝对值的话,那就要进行归一化或者校正.影响富集的因素有,比如mark结合的起始位点, 能结合的位点种类或数目,富集时的信号强度.</p><h2 id="二、step1-数据预处理"><a href="#二、step1-数据预处理" class="headerlink" title="二、step1: 数据预处理"></a>二、step1: 数据预处理</h2><h3 id="2-1-ChIP文库"><a href="#2-1-ChIP文库" class="headerlink" title="2.1 ChIP文库"></a>2.1 ChIP文库</h3><ul><li>potential technical problems</li><li><ul><li>adapter contimination</li></ul></li><li><ul><li>PCR duplication</li></ul></li><li>potential biological problems</li><li><ul><li>lack of enrichment</li></ul></li><li><ul><li>other selection bias</li></ul></li></ul><h3 id="2-2-质控"><a href="#2-2-质控" class="headerlink" title="2.2 质控"></a>2.2 质控</h3><ul><li>QC of reads: fastqc, multiqc</li><li>QC of alignment: multiqc</li><li>Filtering of alignment with MAPQ: samtools</li><li>Deduplication: picard</li><li>基于read density去除outliers</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用MAPQ进行过滤其值低于20的</span></span><br><span class="line">samtools view -q 20 -b -o filtered.bam input.bam</span><br></pre></td></tr></table></figure><h4 id="what-about-deduplication-为何不直接去掉所有的重复？"><a href="#what-about-deduplication-为何不直接去掉所有的重复？" class="headerlink" title="what about deduplication?为何不直接去掉所有的重复？"></a>what about deduplication?为何不直接去掉所有的重复？</h4><p>重复可以是由PCR引起的，也可能是由enrich引起的同一序列存在多个的情况，一般来说，重复使得富集更为明显，对识别富集区域(可能的结合区域/位点)有一定帮助。基于此，我们不能一股脑地去掉所有重复。</p><h2 id="三、step2：peak-calling"><a href="#三、step2：peak-calling" class="headerlink" title="三、step2：peak calling"></a>三、step2：peak calling</h2><h3 id="3-1-Peak-callers-workflow"><a href="#3-1-Peak-callers-workflow" class="headerlink" title="3.1 Peak callers workflow"></a>3.1 Peak callers workflow</h3><p><img src="https://s1.ax1x.com/2018/10/14/iUVn3D.png" alt="Peak callers workflow"></p><ul><li>优化初始数据：校正forwar/reverse peak offset, deduplication</li><li>构建模型：peak = Observed + Model</li><li>滑动窗口: 窗口大小=fragmentSize/2, 保留counts数大于Model的窗口</li><li>校正：若合并后的窗口counts数大于合并后model的counts，则合并相邻窗口生成总的候选peak set</li></ul><h3 id="3-2-Peak-calling-失败的原因"><a href="#3-2-Peak-calling-失败的原因" class="headerlink" title="3.2 Peak calling 失败的原因"></a>3.2 Peak calling 失败的原因</h3><p>Peak calling是富集程度、背景值、序列总数的综合结果。</p><ul><li>用于Observed的data是进行Model的data的子集(比如处理无效果，无处理的两组)</li><li>Observed data有peak的地方，Model data连数据都没有(With no input the region around the peak is used to model the background)</li></ul><h3 id="3-3-结果可靠吗？"><a href="#3-3-结果可靠吗？" class="headerlink" title="3.3 结果可靠吗？"></a>3.3 结果可靠吗？</h3><ul><li>多数ChIP enrichment不是链特异性的，你应该在两条链上都能看到富集</li><li>重复之间的结果应该是一致的</li></ul><h3 id="3-4-下游分析"><a href="#3-4-下游分析" class="headerlink" title="3.4 下游分析"></a>3.4 下游分析</h3><ul><li>composition and motif analysis: 前者分析peak所在DNA组成，后者分析序列潜在生物学功能</li><li>GO：peak所在基因的GO富集</li></ul><h2 id="四、step3：探索peak-data"><a href="#四、step3：探索peak-data" class="headerlink" title="四、step3：探索peak data"></a>四、step3：探索peak data</h2><h3 id="4-1-可视化peak在序列上的分布情况"><a href="#4-1-可视化peak在序列上的分布情况" class="headerlink" title="4.1 可视化peak在序列上的分布情况"></a>4.1 可视化peak在序列上的分布情况</h3><ul><li>Is there any enrichment?</li><li>What is the size / patterning of enrichment?</li><li>How well are my controls behaving?</li><li>What is the best way to quantitate this data?</li><li>Are there any technical artefacts?</li><li>Are my peaks narrow or broad</li><li>Do peak positions obviously correspond to existing features(like TSS)?</li></ul><h4 id="IGV查看enrichment"><a href="#IGV查看enrichment" class="headerlink" title="IGV查看enrichment"></a>IGV查看enrichment</h4><blockquote><p>请注意，因为你需要使用IGV可视化查看enrichment的分布情况，这里IGV的input bam文件是sorted bam文件。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">samtools sort -O bam -o <span class="variable">$name</span>.sorted.bam <span class="variable">$name</span>.bam</span><br></pre></td></tr></table></figure><h3 id="4-2-检查对照"><a href="#4-2-检查对照" class="headerlink" title="4.2 检查对照"></a>4.2 检查对照</h3><p>如果有使用IgG或Mock IP，不同的片段化DNA的方法的话，检查它们各自的peak中，peak coverage是均匀的吗？peak的分布模式是一致的吗？如果不是，那么：</p><ul><li>Low coverage：Repetitive unmappable regions, Holes in the assembly</li><li>High coverage: Mismapped reads from outside the assembly</li><li>Biases: DNA stability, GC content, Segmental Duplication</li></ul><h3 id="4-3-compare-samples"><a href="#4-3-compare-samples" class="headerlink" title="4.3 compare samples"></a>4.3 compare samples</h3><ul><li>可视化比较peak分布</li><li>scatterplot比较input/chip，input/input，chip/chip</li><li>correlation metrix, correlation tree, pca-plot, tSNE plot</li><li>Cumulative Distribution Plot, Q-Q plot</li></ul><h3 id="4-4-把enrichment-peak同序列特征相联系：trend-plots"><a href="#4-4-把enrichment-peak同序列特征相联系：trend-plots" class="headerlink" title="4.4 把enrichment/peak同序列特征相联系：trend plots"></a>4.4 把enrichment/peak同序列特征相联系：trend plots</h3><p>可视化peak在features(Gene body,promoter,CpG islands, Tss)的分布情况，查看是否符合一般性质(比如甲基化修饰应该在CpG islands富集), 然后分析可能的feature.</p><ul><li><p>查看总的enrich情况，看是否有peak在某个feature<br><img src="https://s1.ax1x.com/2018/10/14/iUZSat.png" alt="overall average"></p></li><li><p>查看不同sample在单个feature的enrichment<br><img src="https://s1.ax1x.com/2018/10/14/iUZAMQ.md.png" alt="enrichment of single feature"></p></li></ul><h2 id="五、使用MACS2进行peak-calling"><a href="#五、使用MACS2进行peak-calling" class="headerlink" title="五、使用MACS2进行peak calling"></a>五、使用MACS2进行peak calling</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一个方法,使用python的pip</span></span><br><span class="line"><span class="comment"># 1.先用conda info --envs查看当前的环境, 我的是有base(python3.7)和env_name(python2.7)</span></span><br><span class="line"><span class="comment"># 2.如果没有python2.7的环境,可以创建一个名为py27的环境</span></span><br><span class="line">conda create -n py27 python=2.7</span><br><span class="line"><span class="built_in">source</span> activate py27</span><br><span class="line">pip install MACS2</span><br><span class="line"><span class="built_in">source</span> deactivate py27</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 进入python2.7环境</span></span><br><span class="line"><span class="built_in">source</span> activate env_name</span><br><span class="line">macs2 callpeak -c control.bam -t treat.bam \</span><br><span class="line">-m 10 30 -p 1e-5 \</span><br><span class="line">-f BAM -g mm -n treat</span><br><span class="line">    <span class="comment"># -c &lt;bam&gt;进行peak calling的对照</span></span><br><span class="line">    <span class="comment"># -t &lt;bam&gt;进行peak calling的目标</span></span><br><span class="line">    <span class="comment"># -m 10 30建立双峰模型的参数</span></span><br><span class="line">    <span class="comment"># -p &lt;pvalue&gt;显著性阈值,1e-5</span></span><br><span class="line">    <span class="comment"># -f BAM 输入的文件类型</span></span><br><span class="line">    <span class="comment"># -g &lt;organism&gt; 进行peak calling的物种, hg(人), mm(小鼠), rn(rat)</span></span><br><span class="line">    <span class="comment"># -n &lt;string&gt;   输出文件的前缀</span></span><br><span class="line">nohup macs2 callpeak -c ../02alignment/IgGold.sorted.bam -t ../02alignment/suz12.sorted.bam -m 10 30 -p 1e-5 -f BAM -g mm -n suz12 2&gt;suz12.masc2.log &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每个样本共输出四个文件:</span></span><br><span class="line">    <span class="comment"># 1. name_peaks.xls         存放peak信息,格式与bed一致;坐标从1开始,而bed从0开始.</span></span><br><span class="line">    <span class="comment"># 2. name_model.r           peak模型,可直接进行R作图.</span></span><br><span class="line">    <span class="comment"># 3. name_peaks.narrowpeak  peak矩阵,与.broadpeak相似.可导入R等进行数据分析.BED6+4 format file.</span></span><br><span class="line">    <span class="comment"># 4. name_summits.bed       每个peak的peak summits(极值点的位置),用此寻找结合位点的motif.</span></span><br><span class="line"><span class="comment"># 查看peaks数目</span></span><br><span class="line">ls *.bed | xargs -i wc -l &#123;&#125; <span class="comment"># 6514 suz12_summits.bed</span></span><br></pre></td></tr></table></figure><h2 id="六、使用ChIPseeker进行可视化"><a href="#六、使用ChIPseeker进行可视化" class="headerlink" title="六、使用ChIPseeker进行可视化"></a>六、使用ChIPseeker进行可视化</h2><h3 id="6-0-BED-文件格式"><a href="#6-0-BED-文件格式" class="headerlink" title="6.0 BED 文件格式"></a>6.0 BED 文件格式</h3><table><thead><tr><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th></tr></thead><tbody><tr><td>chrom</td><td>start</td><td>end</td><td>name</td><td>score</td><td>strand</td><td>thickStart</td><td>thickEnd</td><td>itemRgb</td><td>blockCount</td><td>blockSizes</td><td>blockStarts</td></tr></tbody></table><ul><li>在这12列中,前3列是必需的字段.</li><li>score是在genome browser中上色的分值(0-1000),就是peak峰的峰高(summit height of fragment pileup)</li><li>strand值链的正负性, 但是在ChIP中我们无法区分链的正负性</li><li>thickStart/End是在genome browser画矩形的起点和中点</li><li>itemRgb是上色的颜色</li><li>block是子元件,比如外显子内含子,5’utr之类的.</li></ul><h3 id="6-1-包和文件"><a href="#6-1-包和文件" class="headerlink" title="6.1 包和文件"></a>6.1 包和文件</h3><p>TxDb数据库依据你的ChIP实验动物的物种下载对应物种的数据库.也可以自己通过makeTxDbFromBiomart/makeTxDbFromUCSC包来准备TxDb类型的数据库.hg38(TxDb.Hsapiens.UCSC.hg38.knownGene)、hg19(TxDb.Hsapiens.UCSC.hg19.knownGene)、mm10(TxDb.Mmusculus.UCSC.mm10.knownGene)、mm9(TxDb.Mmusculus.UCSC.mm9.knownGene)</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ChIPseeker)<span class="comment"># for all</span></span><br><span class="line"><span class="keyword">library</span>(TxDb.Hsapiens.UCSC.hg19.knownGene)<span class="comment"># for 6.3</span></span><br><span class="line"><span class="keyword">library</span>(org.Hs.eg.db)<span class="comment"># for 6.3,6.5</span></span><br><span class="line"><span class="keyword">library</span>(clusterProfiler)<span class="comment"># for 6.5,6.6</span></span><br><span class="line"><span class="keyword">library</span>(ReactomePA)<span class="comment"># for 6.5,6.6</span></span><br><span class="line">txdb = TxDb.Hsapiens.UCSC.hg19.knownGene</span><br><span class="line">peak = readPeakFile(filename)</span><br></pre></td></tr></table></figure><h3 id="6-2-可视化peak在基因组上的富集区域-peaks-coverage-plot"><a href="#6-2-可视化peak在基因组上的富集区域-peaks-coverage-plot" class="headerlink" title="6.2 可视化peak在基因组上的富集区域(peaks coverage plot)"></a>6.2 可视化peak在基因组上的富集区域(peaks coverage plot)</h3><p>除了peak文件, GRangeList也支持作为出入,来比较不同bed文件的peak情况。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">covplot(peak, weightCol=<span class="string">'V5'</span>)<span class="comment"># V5是peakfile的第五列(scores)</span></span><br><span class="line"><span class="comment"># 指定染色体区域</span></span><br><span class="line">covplot(peak, weightCol=<span class="string">'V5'</span>, chrs=c(<span class="string">'chr10'</span>, <span class="string">'chr12'</span>), xlim=c(<span class="number">4.5e7</span>, <span class="number">5e7</span>))</span><br></pre></td></tr></table></figure><h3 id="6-3-结合到TSS区域的peaks分析"><a href="#6-3-结合到TSS区域的peaks分析" class="headerlink" title="6.3 结合到TSS区域的peaks分析"></a>6.3 结合到TSS区域的peaks分析</h3><h4 id="6-3-1-peaks热图分析"><a href="#6-3-1-peaks热图分析" class="headerlink" title="6.3.1 peaks热图分析"></a>6.3.1 peaks热图分析</h4><p>为了分析结合到TSS区域的peaks, 我们需要准备好表示TSS regions的文件, 然后再进行计算.注意,我们这里指定了TSS上下游3000bp的区域, 你也可以指定其他区域(getBioRegion和getTagMatrix联合使用)</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">promoter = getPromoter(TxDb=txdb, upstream=<span class="number">3000</span>, downstream=<span class="number">3000</span>, by=<span class="string">'gene'</span>) <span class="comment"># by=gene/transcript</span></span><br><span class="line"><span class="comment"># getBioRegion(TxDb = NULL, upstream = 1000, downstream = 1000, by = "gene") # by=gene/transcript/exon/intron</span></span><br><span class="line">tagMatrix = getTagMatrix(peak, windows=promoter)</span><br><span class="line">tagHeatmap(tagMatrix, xlim=c(-<span class="number">3000</span>, <span class="number">3000</span>), color=<span class="string">'red'</span>)</span><br><span class="line"><span class="comment"># 一步法热图</span></span><br><span class="line">peakHeatmap(filename, TxDb=txdb, upstream=<span class="number">3000</span>, downstream=<span class="number">3000</span>, color=<span class="string">'red'</span>)</span><br></pre></td></tr></table></figure><h4 id="6-3-2-peaks的平均read-count-frequency"><a href="#6-3-2-peaks的平均read-count-frequency" class="headerlink" title="6.3.2 peaks的平均read count frequency"></a>6.3.2 peaks的平均read count frequency</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plotAvgProf(tagMatrix, xlim=c(-<span class="number">3000</span>,<span class="number">3000</span>), </span><br><span class="line">xlab=<span class="string">"Genomic Region (5'-&gt;3')"</span>, ylab=<span class="string">"Read Count Frequency"</span>,</span><br><span class="line">conf=<span class="number">0.95</span>, resample=<span class="number">1000</span>)<span class="comment"># 添加置信区间</span></span><br><span class="line"><span class="comment"># 由文件名一步到位</span></span><br><span class="line">plotAvgProf2(filename, TxDb=txdb, upstream=<span class="number">3000</span>, </span><br><span class="line">downstream=<span class="number">3000</span>, xlab=<span class="string">"Genomic Region (5'-&gt;3')"</span>, </span><br><span class="line">ylab=<span class="string">"Read Count Frequency"</span>)</span><br></pre></td></tr></table></figure><h3 id="6-4-注释及其可视化"><a href="#6-4-注释及其可视化" class="headerlink" title="6.4 注释及其可视化"></a>6.4 注释及其可视化</h3><ul><li>获取peak附近最近的基因(6.4.2)</li><li>注释peak所在的基因组区域(6.4.1)</li></ul><p>就像拿到fastq进行比对,你需要提供全基因组的参考序列, peak的注释同样需要参考信息, 也就是注释信息, 这些信息包含基因的起始和结束位置, 在基因的哪个区域是内含子, 哪里是外显子等信息.ChIP支持所有的有基因位置注释信息的物种, 这些注释我们要存储在TxDb对象里面.  </p><p>注释有好几种种, 一种是genomic annotation(annotation列),另一种是nearest gene annotation(其他咧).第一种genomic annotation的注释peak的位置,在基因的什么地方,比如UTR,外显子内含子之类的, 这个位置可能就是调控的根本, 可变剪切的调控就属于这类.而nearest gene annotation的注释是最近的基因, 是离peak的距离最近的TSS, 这个TSS所在的基因,这个关注的是启动子区域, 这个基因最有可能被调控. 然后由于一个基因有多个TSS, 多个转录本, 所以有一列transcriptId的列. 还有第三种注释,那就是注释peak区域上下游某个范围, 看这个范围的基因都有些啥.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># peakAnno是个csAnno实例, 可以用as.GRanges把它转化成GRanges实例.</span></span><br><span class="line"><span class="comment"># as.data.frame可以把csAnno转换成data.frame,以供写入文件</span></span><br><span class="line"><span class="comment"># annoDb可选,用以添加各种ID的列. 物种要对应正确</span></span><br><span class="line">peakAnno = annotatePeak(filename, tssRegion=c(-<span class="number">3000</span>, <span class="number">3000</span>), TxDb=txdb, annoDb=<span class="string">'org.Hs.eg.db'</span>)</span><br></pre></td></tr></table></figure><h4 id="6-4-1-peaks分布区域的饼图-柱形图"><a href="#6-4-1-peaks分布区域的饼图-柱形图" class="headerlink" title="6.4.1 peaks分布区域的饼图, 柱形图"></a>6.4.1 peaks分布区域的饼图, 柱形图</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plotAnnoPie(peakAnno)</span><br><span class="line">plotAnnoBar(peakAnno)</span><br><span class="line"><span class="comment"># vennpie(peakAnno)</span></span><br><span class="line">upsetplot(peakAnno, vennpie=<span class="literal">T</span>)</span><br></pre></td></tr></table></figure><h4 id="6-4-2-peak-binding-site-与最近基因的TSS距离"><a href="#6-4-2-peak-binding-site-与最近基因的TSS距离" class="headerlink" title="6.4.2 peak(binding site)与最近基因的TSS距离"></a>6.4.2 peak(binding site)与最近基因的TSS距离</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plotDistToTSS(peakAnno, title=<span class="string">'Distribution of transcription factor-binding loci\n relative to TSS'</span>)</span><br></pre></td></tr></table></figure><h3 id="6-5-进行功能富集分析"><a href="#6-5-进行功能富集分析" class="headerlink" title="6.5 进行功能富集分析"></a>6.5 进行功能富集分析</h3><p>一旦我们掌握peak区域(TF-binding site)最近的基因信息后,就可以对这些基因进行富集分析啦, 看看它们有什么功能咯.这就有好多方向.Go、KEGG、DO(基因和人类疾病,DOSE)、Reactome（基因与pathways和reactions,ReactomePA).为了进行这些富集分析,就可能要用到seq2gene函数了.它可以以多对多的形式把基因组区域同基因联系起来.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pathway1 = ReactomePA::enrichPathway(as.data.frame(peakAnno)$geneId)</span><br><span class="line">head(pathway1)</span><br><span class="line">gene = seq2gene(peak, tssRegion=c(-<span class="number">1000</span>, <span class="number">1000</span>), flankDistance=<span class="number">3000</span>, TxDb=txdb)</span><br><span class="line">pathway2 = ReactomePA::enrichPathway(gene)</span><br><span class="line">head(pathway2, <span class="number">2</span>)</span><br><span class="line">dotplot(pathway2)</span><br></pre></td></tr></table></figure><h3 id="6-6-比较不同的peak-data-set-多个peak结果一起分析咯"><a href="#6-6-比较不同的peak-data-set-多个peak结果一起分析咯" class="headerlink" title="6.6 比较不同的peak data set (多个peak结果一起分析咯)"></a>6.6 比较不同的peak data set (多个peak结果一起分析咯)</h3><h4 id="6-6-1-结合到TSS-region的peak分析-频率和热图"><a href="#6-6-1-结合到TSS-region的peak分析-频率和热图" class="headerlink" title="6.6.1 结合到TSS region的peak分析: 频率和热图"></a>6.6.1 结合到TSS region的peak分析: 频率和热图</h4><p>plotAvgProf,tagHeatmap都支持tagMatrixList的输入, plotAvgProf2和peakHeatmap也接受filenameList</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">peaks = sapply(filenames, readPeakFile)</span><br><span class="line">tagMatrixList = lapply(peaks, getTagMatrix, window=promoter)</span><br><span class="line">plotAvgProf(tagMatrixList, xlim=c(-<span class="number">3000</span>,<span class="number">3000</span>))<span class="comment"># average profiles of ChIP peaks among different experiments</span></span><br><span class="line">plotAvfProf(tagMatrixList, xlim=c(-<span class="number">3000</span>,<span class="number">3000</span>), conf=<span class="number">0.95</span>, resample=<span class="number">500</span>, facet=<span class="string">'row'</span>)<span class="comment"># 置信区间和按行作图</span></span><br><span class="line">tagHeatmap(tagMatrixList, xlim=c(-<span class="number">3000</span>,<span class="number">3000</span>), color=<span class="literal">NULL</span>)<span class="comment"># heatmap of peaks among different experiments</span></span><br></pre></td></tr></table></figure><h4 id="6-6-2-peak注释比较"><a href="#6-6-2-peak注释比较" class="headerlink" title="6.6.2 peak注释比较"></a>6.6.2 peak注释比较</h4><p>多个annotatePeak输出的结果整合成列表, 也可以输入到plotAnnoBar和plotDistToTSS里面去.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">peakAnnoList = lapply(filenames, annotatePeak, TxDb=txdb, tssRegion=c(-<span class="number">3000</span>, <span class="number">3000</span>), verbose=<span class="literal">F</span>)</span><br><span class="line">plotAnnoBar(peakAnnoList)<span class="comment"># Genomic Annotation among different ChIPseq data</span></span><br><span class="line">plotDistToTSS(peakAnnoList)<span class="comment"># Distribution of Binding Sites among different ChIPseq data</span></span><br></pre></td></tr></table></figure><h4 id="6-6-3-功能富集比较"><a href="#6-6-3-功能富集比较" class="headerlink" title="6.6.3 功能富集比较"></a>6.6.3 功能富集比较</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">genes = lapply(peakAnnoList, <span class="keyword">function</span>(x) as.data.frame(x)$geneId)</span><br><span class="line">names(genes) = sub(<span class="string">'_'</span>, <span class="string">'\n'</span>, names(genes))</span><br><span class="line">compKEGG = clusterProfiler::compareCluster(geneCluster=<span class="string">'genes'</span>, fun=<span class="string">'enrichKEGG'</span>,</span><br><span class="line"><span class="comment"># One of "groupGO", "enrichGO", "enrichKEGG", "enrichDO" or "enrichPathway"</span></span><br><span class="line">pvalueCutoff=<span class="number">0.05</span>,</span><br><span class="line">pAdjustMethod=<span class="string">'BH'</span>)</span><br><span class="line">dotplot(compKEGG, showCategory=<span class="number">15</span>, title=<span class="string">'KEGG Pathway Enrichment Analysis'</span>)</span><br></pre></td></tr></table></figure><h4 id="6-6-4-peak和注释后基因的重叠"><a href="#6-6-4-peak和注释后基因的重叠" class="headerlink" title="6.6.4 peak和注释后基因的重叠"></a>6.6.4 peak和注释后基因的重叠</h4><p>这个可以用于实验重复/样品重复peak结果的一致性. 也可以看不同样品peak结果的交叉点.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">genes = lapply(peakAnnoList, <span class="keyword">function</span>(x) as.data.frame(x)$geneId)</span><br><span class="line">vennplot(genes)</span><br></pre></td></tr></table></figure><h3 id="6-7-ChIP-seq-peak结果重叠的统计分析"><a href="#6-7-ChIP-seq-peak结果重叠的统计分析" class="headerlink" title="6.7 ChIP-seq peak结果重叠的统计分析"></a>6.7 ChIP-seq peak结果重叠的统计分析</h3><p>如果两个不同的ChIP实验的peak结果有很大重叠的话, 表明这两个实验中用于IP的蛋白极有可能是分子伴侣(cooperative in regulation). 所以,通过对重叠进行统计分析可以确认这个事实的显著性.<br>当然,这里面有一些理论前提.我们把基因组位置随机打断的话, 在把这些片段进行peak calling, 我们会得到一个peak的概率分布. 基于此, 我们可以统计ChIP-seq peak calling的显著性.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">p = GRanges(seqnames=c(<span class="string">'chr1'</span>, <span class="string">'chr3'</span>), ranges=IRanges(start=c(<span class="number">1</span>,<span class="number">100</span>), end=c(<span class="number">50</span>,<span class="number">130</span>)))</span><br><span class="line">shuffle(p, TxDb=txdb)</span><br><span class="line"><span class="comment"># 基于基因组坐标计算的overlap显著性</span></span><br><span class="line"><span class="comment">#（overlap significant of ChIP experiments based on the genome coordinations)</span></span><br><span class="line">enrichPeakOverlap(queryPeak=files[[<span class="number">5</span>]], targetPeak=unlist(files[<span class="number">1</span>:<span class="number">4</span>]),</span><br><span class="line">  TxDb=txdb, pAdjustMethod=<span class="string">'BH'</span>,</span><br><span class="line">  nShuffle=<span class="number">50</span>, chainFile=<span class="literal">NULL</span>,</span><br><span class="line">  verbose=<span class="literal">F</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于最近TSS的基因注释计算overlap显著性</span></span><br><span class="line"><span class="comment"># overlap sig. calculated based on their nearest gene annotation</span></span><br><span class="line">enrichAnnoOverlap(queryPeak = filename, targetPeak = filename(s),</span><br><span class="line">  TxDb=txdb, pAdjustMethod=<span class="string">'BH'</span>,</span><br><span class="line">  chainFile=<span class="literal">NULL</span>, distanceToTSS_cutoff=<span class="literal">NULL</span>)</span><br></pre></td></tr></table></figure><h3 id="6-8-GEO中ChIP-seq数据挖掘"><a href="#6-8-GEO中ChIP-seq数据挖掘" class="headerlink" title="6.8 GEO中ChIP-seq数据挖掘"></a>6.8 GEO中ChIP-seq数据挖掘</h3><p>我们已经可以计算不同ChIP-seq实验peak数据的重叠显著性了.而在GEO上有相当多的数据,那么我们可以拿自己的数据与里面的peak数据去找重叠,如果找到了新的蛋白-蛋白复合转录体,又是个新发现了.<br>这个包里面涵盖了17000个GEO bed文件, 可以通过getGEOspecies来获取这些文件的概要.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">getGEOspecies()<span class="comment"># 基于物种</span></span><br><span class="line">getGEOgenomeVersion() <span class="comment"># 基于基因组版本</span></span><br><span class="line"><span class="comment"># 获取详细信息</span></span><br><span class="line">hg19 = getGEOInfo(genome=<span class="string">'hg19'</span>, simplify=<span class="literal">T</span>)</span><br><span class="line"><span class="comment"># 下载数据</span></span><br><span class="line">downloadGEObedFiles(genome=<span class="string">'hg19'</span>, destDir=<span class="string">'hg19'</span>)<span class="comment"># 根据基因组版本</span></span><br><span class="line">downloadGSMbedFiles(gsm_vector, destDir=<span class="string">'hg19'</span>)    <span class="comment"># 根据gsm accession来下载</span></span><br></pre></td></tr></table></figure><h2 id="七、使用deeptools进行可视化"><a href="#七、使用deeptools进行可视化" class="headerlink" title="七、使用deeptools进行可视化"></a>七、使用deeptools进行可视化</h2><p>deeptools可以用于处理比对结果的多项质控, 并基于比对文件生成校正后的bed或bigwig格式的覆盖度文件(normalized coverage file),这就允许多个处理组的比较了. 当然,利用这些文件, 你还可以进行多种可视化.</p><p><img src="http://deeptools.readthedocs.io/en/latest/_images/start_workflow.png" alt="deeptools in ChIP-seq"></p><ul><li>多个Bam文件的相关性: multiBamSummary, plotCorrelation, multiBigWigSummary</li><li>比对后read的覆盖度: plotCoverage(–ignoreDuplicates is useful), bamPEFragmentSize(for PE)</li><li>GC-bias: computeGCBias, correctGCBias</li><li>估测ChIP信号强度:</li></ul><h3 id="7-1-质控和数据处理"><a href="#7-1-质控和数据处理" class="headerlink" title="7.1 质控和数据处理"></a>7.1 质控和数据处理</h3><ol><li>从bam文件生成bigwig<br><a href="http://deeptools.readthedocs.io/en/latest/content/tools/bamCoverage.html" target="_blank" rel="noopener">bamCoverage</a></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bamCoverage -b reads.bam -o coverage.bw \</span><br><span class="line">--binSize 10 \</span><br><span class="line">--normalizeUsing RPGC \</span><br><span class="line">--extendReads \</span><br><span class="line"><span class="comment"># -b,--bam 输入的bam文件</span></span><br><span class="line"><span class="comment"># -o 输出文件名</span></span><br><span class="line"><span class="comment"># -of 输出格式, bigwig, bedgraph</span></span><br></pre></td></tr></table></figure><ol start="2"><li>检测多个测序结果之间的可重复性</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">multiBamSummary, plotCorrelation</span><br></pre></td></tr></table></figure><ol start="3"><li>检测和校正 GC bias</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">computeGCBias</span><br></pre></td></tr></table></figure><ol start="4"><li>以特定文件校正ChIP的覆盖率度</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bamCompare with ChIP = treatment, input=control</span><br></pre></td></tr></table></figure><ol start="5"><li>检测不同ChIP实验的信号强度</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plotFingerprint</span><br></pre></td></tr></table></figure><ol start="6"><li>得到TSS(转录起始位点)富集基因的覆盖度热图</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">computeMatrix, plotHeatmap</span><br></pre></td></tr></table></figure><ol start="7"><li>比较基因在常染色体与性染色体之间的信号差别</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 过滤出欲比较的基因</span><br><span class="line">2. computeMatrix</span><br><span class="line">3. plotProfile</span><br><span class="line">4. plotting the summary plots <span class="keyword">for</span> multiple samples</span><br></pre></td></tr></table></figure><h3 id="7-2-函数的使用"><a href="#7-2-函数的使用" class="headerlink" title="7.2 函数的使用"></a>7.2 函数的使用</h3><h4 id="7-2-1-computeMatrix"><a href="#7-2-1-computeMatrix" class="headerlink" title="7.2.1 computeMatrix"></a>7.2.1 computeMatrix</h4><p>对基因组上的任何一个区域进行打分(peak 数),生成供plotHeatMap和plotProfiles用的中间文件。它的输入的是多个打分文件如bigwig文件,bed文件。当然，这个函数还可以根据输入的bw/bed文件对基因组上的区域进行筛选.<br>它有两种模式,参考点模式(reference-point)和大区域模式(scale-regions).</p><p>bw文件可以通过bamCoverage/bamCompare函数得到.</p><ul><li>computeMatrix scale-regions模式</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">computeMatrix scale-regions -S &lt;bw/bed files&gt; -R &lt;bed file&gt; -b 1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># -R,--regionsFileName 你想可视化的区域的文件名,以BED/GTF格式.</span></span><br><span class="line"><span class="comment">#多个文件的话,可以使用#进行分组.分组的文件将画在一起.</span></span><br><span class="line"><span class="comment"># -S,--scoreFileName 打分文件, 以bw,bed格式.看这里,就需要打分文件啦.bigwig.</span></span><br><span class="line"><span class="comment"># -o,-out,--outFileName 输出.gz文件以供plotHeatMap和plotProfile使用</span></span><br><span class="line"><span class="comment"># --outFileNameMatrix 输出peak calling矩阵,可以进行差异分析</span></span><br><span class="line"><span class="comment"># --outFileSortedRegions 在你设置一个筛选条件后输出的筛选后文件名</span></span><br><span class="line"><span class="comment"># -a,--downstream转录起始位点下游的bp数</span></span><br><span class="line"><span class="comment"># -b,--upstream 转录起始位点上游的bp数</span></span><br><span class="line"><span class="comment"># 具体筛选参数设定见handbook</span></span><br><span class="line"></span><br><span class="line">computeMatrix scale-regions \</span><br><span class="line">                -R genes_chr19_firstHalf.bed genes_chr19_secondHalf.bed \ <span class="comment"># separate multiple files with spaces</span></span><br><span class="line">                -S testFiles/log2ratio_*.bw  \ or use the wild card approach</span><br><span class="line">                -b 3000 -a 3000 \</span><br><span class="line">                --regionBodyLength 5000 \</span><br><span class="line">                --skipZeros -o matrix2_multipleBW_l2r_twoGroups_scaled.gz \</span><br><span class="line">                --outFileNameMatrix matrix2_multipleBW_l2r_twoGroups_scaled.tab \</span><br><span class="line">                --outFileSortedRegions regions2_multipleBW_l2r_twoGroups_genes.bed</span><br></pre></td></tr></table></figure><ul><li>computeMatrix reference-point模式</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">computedMatrix reference-point -S &lt;bw/bed file(s)&gt; -R &lt;bed file&gt; -a 3000 -b 3000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数可见scale-regions模式</span></span><br><span class="line"><span class="comment"># --referencePoint 指定参考点,可选的参考点为TSS,TES,center.TSS(region start) TES(region end), center(region center)</span></span><br><span class="line">不管你用的啥参考点, 可视化时都是用TSS作为默认标签。</span><br><span class="line"></span><br><span class="line">computeMatrix reference-point --referencePoint TSS \ <span class="comment"># alternatives: TES, center</span></span><br><span class="line">       -b 3000 -a 10000 \ <span class="comment"># define the region you are interested in</span></span><br><span class="line">       -R testFiles/genes.bed \</span><br><span class="line">       -S testFiles/log2ratio_H3K4Me3_chr19.bw  \</span><br><span class="line">       --skipZeros \</span><br><span class="line">       -o matrix1_H3K4me3_l2r_TSS.gz \ <span class="comment"># to be used with plotHeatmap and plotProfile</span></span><br><span class="line">       --outFileSortedRegions regions1_H3K4me3_l2r_genes.bed</span><br></pre></td></tr></table></figure><h4 id="7-2-2-multiBamSummary"><a href="#7-2-2-multiBamSummary" class="headerlink" title="7.2.2 multiBamSummary"></a>7.2.2 multiBamSummary</h4><p>multiBamSummary计算多个bam文件的基因组区域的read覆盖率,这个可以通过指定‘bins’模式来实现。你也可以通过‘BED-file’模式来计算指定区域的read覆盖度。它的标准输出是压缩后的numpy array(.npz). 可以使用plotCorrelation函数直接计算和可视化成对相关性。你还可以用plotPCA函数来对整个numpy文件进行主成分分析。我们并不推荐你只输入单个bw文件, 如果你只是想生成bedGraph文件的话, 倒是可以使用,但你要指定–outRawCounts选项.</p><ul><li>multiBamSummary bins</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">multiBamSummary bins --bamfiles file1.bam file2.bam ... -o results.npz</span><br><span class="line"></span><br><span class="line"><span class="comment"># --bamfiles 你输入的bam文件,用空格隔开</span></span><br><span class="line"><span class="comment"># -o 输出文件名, read覆盖度矩阵. .npz文件</span></span><br><span class="line"><span class="comment"># -l,--labels指定输入文件的标签,应该是在覆盖度矩阵里作为列名</span></span><br><span class="line"><span class="comment"># --smartLabels 自动指定标签, 使用文件名(basename filename)</span></span><br><span class="line"><span class="comment"># -r,--region 指定计算覆盖度的区域.形式为-region chr10, -region chr10:456700:891000</span></span><br><span class="line"><span class="comment"># --ignoreDuplicates 忽略重复的reads</span></span><br><span class="line"><span class="comment"># --outRawCounts 把counts per region以\t分隔的形式写入文件</span></span><br><span class="line"><span class="comment"># -e,--extendReads 当read的长度不足,允许read延伸到与fragment一致的长度.</span></span><br><span class="line">不推荐在含有spliced-read的数据里使用, 如RNA-seq。</span><br><span class="line"><span class="comment"># --minMappingQuality最低的比对质量分数,低于此的reads不进行计算</span></span><br><span class="line"><span class="comment"># --centerReads 指定reads要覆盖到fragment长度的中心</span></span><br><span class="line"><span class="comment"># 其他设定fragment长短的选项见handbook</span></span><br></pre></td></tr></table></figure><ul><li>multiBamSummary BED-file </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">multiBamSummary BED-file --BED selection.bed --bamfiles file1.bam file2.bam -o results.npz</span><br><span class="line"></span><br><span class="line"><span class="comment"># -b,--bamfiles 索引后的bam文件,以空格分隔</span></span><br><span class="line"><span class="comment"># -o 生成覆盖度的矩阵文件名</span></span><br><span class="line"><span class="comment"># --BED 指定计算覆盖度的区域文件</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>基因组变异检测(Variance Calling with GATK)</title>
      <link href="/2018/10/14/%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%8F%98%E5%BC%82%E6%A3%80%E6%B5%8B(Variance-Calling-with-GATK)/"/>
      <url>/2018/10/14/%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%8F%98%E5%BC%82%E6%A3%80%E6%B5%8B(Variance-Calling-with-GATK)/</url>
      
        <content type="html"><![CDATA[<h2 id="一、基本概念"><a href="#一、基本概念" class="headerlink" title="一、基本概念"></a>一、基本概念</h2><h3 id="1-1-名词解释"><a href="#1-1-名词解释" class="headerlink" title="1.1 名词解释"></a>1.1 名词解释</h3><ul><li><strong>基因组</strong>：个体全部DNA序列的无重复集.这里的基因组不仅仅包含了基因在内,由于目前尚有许多DNA序列不编码蛋白,也可能不会转录,反正就是这些序列的功能还没有研究清楚, 这些序列也都包含在基因组这个范畴里面.</li><li><strong>Reads</strong>：二代测序中的一个专有名词,表示着测序仪对某个DNA片段的一次测序结果,是该DNA序列的序列组成. 其长度依据测序仪不同而不同.</li><li><strong>变异</strong>：variants, 变异是一个相对的概念,产生于比较之中, 比较是指同耳熟能详的参考基因组相比较. 对于人类基因组的变异来讲,参考基因组是经过“人类基因组”计划测序所得到的最终人类基因组序列.</li></ul><a id="more"></a><h3 id="1-2-基因组变异的种类"><a href="#1-2-基因组变异的种类" class="headerlink" title="1.2 基因组变异的种类"></a>1.2 基因组变异的种类</h3><p>个体基因上的变化可以分为两种, 一种是种系上的(germline), 这种变化由遗传所得, 所以还有phasing分析，以区别这个变化来源于哪个亲本。 另一种是体细胞(somatic)上的, 这通常是由癌症所引起的异常变化, 也就是癌变相关的变化。</p><ul><li><p>单核苷酸多态性(single nucleotide polymorphism, SNP)<br>单核苷酸多态性主要是指在基因组水平上由单个核苷酸的变异所引起的DNA序列多态 性。它是人类可遗传的变异中最常见的一种，占所有已知多态性的80%以上。SNP在人类 基因组中广泛存在，平均每500〜1000个碱基对中就有1个，估计其总数可达300万个甚至更多。SNP所表现的多态性只涉及到单个碱基的变异，这种变异可由单个碱基的转换(transition)或颠换(transversion)所引起，也可由碱基的插入或缺失所致。但通常所说的SNP并不包括后两种情况。</p></li><li><p>插入和缺失(insertion and deletion, INDEL)<br>插入是指在基因组上的某个位置出现额外的DNA片段, 而缺失则是指某些位置原有的DNA片段发生丢失. 插入和缺失的DNA片段长度一般不是太长, 基本在50bp以内.</p></li><li><p>染色体结构变异(chromosome structure variant)<br>当DNA片段缺失的长度大于50bp时,我们则认为发生了染色体结构缺失. 不仅如此, 染色体结构变异还包含其他结构变化, 如染色体的易位(两条染色体)、倒位(自身).有时候, <em>色体数目变异</em>也被归为是染色体结构变异.</p></li></ul><p><img src="https://s1.ax1x.com/2018/07/04/PEOOSK.png" alt="基因组变异"></p><h3 id="1-3-基因组结构变异的检测策略"><a href="#1-3-基因组结构变异的检测策略" class="headerlink" title="1.3 基因组结构变异的检测策略"></a>1.3 基因组结构变异的检测策略</h3><ul><li><p>Pair-end Mapping(also named read pair, PEM)<br>PEM法可以检测到许多变异, 如deletion, insertion, inversion, intra/inter-chromosome translocation, tandem duplication, interspersed duplications.对应的软件有Breakdancer, variationHunter, Spanner, PEMer.<strong>注意, PEM法深受insertSize影响.</strong></p></li><li><p>Split read(SR)<br>SR法可以检测deletion, insertion, tandem duplication, inversion. SR法需要软件具备soft-clip reads的能力.相关软件有Pindel.</p></li><li><p>Read Depth(RD)<br>RD检测一些大的deletion或者duplication事件,对于小的变异则无能为力.RD有两种策略,一种是通过检测样本在一个参考基因组上read的深度分布情况来检测CNV,适用于单样本;另一种则是通过和识别出比较两个样本中所存在的丢失和重复倍增区, 以此来获得相对的CNV, 适用于case-control模型的样本.相关的软件有CNVnator, CNV-seq.</p></li><li><p>De novo assembly<br>从头组装对于变异检测最为有效,特别是long insertion和复杂结构性变异.</p></li></ul><h3 id="1-4-各个检测策略图示"><a href="#1-4-各个检测策略图示" class="headerlink" title="1.4 各个检测策略图示"></a>1.4 各个检测策略图示</h3><p><a href="https://s1.ax1x.com/2018/10/14/iU8cPH.png" target="_blank" rel="noopener">https://s1.ax1x.com/2018/10/14/iU8cPH.png</a></p><h2 id="二、基因组变异检测软件"><a href="#二、基因组变异检测软件" class="headerlink" title="二、基因组变异检测软件"></a>二、基因组变异检测软件</h2><ul><li>bwa: 用于序列比对</li><li>samtools: 处理比对后数据</li><li>picard: 处理比对后数据,功能上与samtools互补</li><li>GATK: variant calling</li></ul><h2 id="三、数据预处理：获得可进行分析的bam文件"><a href="#三、数据预处理：获得可进行分析的bam文件" class="headerlink" title="三、数据预处理：获得可进行分析的bam文件"></a>三、数据预处理：获得可进行分析的bam文件</h2><blockquote><p>后续的分析都是基于预处理产生的bam文件。</p></blockquote><h3 id="3-1-比对到参考基因组上-并排序"><a href="#3-1-比对到参考基因组上-并排序" class="headerlink" title="3.1 比对到参考基因组上,并排序"></a>3.1 比对到参考基因组上,并排序</h3><p>可用软件：BWA (DNA-seq), Picards MergeBamAlignments(针对unmapped BAM文件), STAR(RNA-seq). 注意需要排序bam文件.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 下载参考基因组数据 2. bwa建立索引</span></span><br><span class="line">bwa index ref_genome.fasta <span class="comment"># output: ref_genome.amb, .ann, .bwt, .pac, .sa</span></span><br><span class="line"><span class="comment"># 3. bwa比对,使用mem模块</span></span><br><span class="line">bwa mem -t 4 -R <span class="string">'@RG\tID:foo_lane\tPL:illumina\tLB:library\tSM:sample_name'</span> /path/to/ref_genome.fasta read_1.fq.gz read_2.fq.gz &gt; sample_name.sam</span><br><span class="line">    <span class="comment"># -R: 用'\t'分割的Read Group的字符串信息,为read指定分组. </span></span><br><span class="line">    <span class="comment"># ID是分组ID,设置为测序的laneID;PL是平台名字;SM是样本ID,用于区分样本.LB是测序文库名字.</span></span><br><span class="line"><span class="comment"># 4. 排序</span></span><br><span class="line">samtools view -S -b sample_name.sam &gt; sample_name.bam</span><br><span class="line">samtools sort -@ 4 -m 4G -O bam -o sample_name.sorted.bam sample_name.bam</span><br></pre></td></tr></table></figure><h3 id="3-2-去除重复reads"><a href="#3-2-去除重复reads" class="headerlink" title="3.2 去除重复reads"></a>3.2 去除重复reads</h3><p>重复reads是指来自同个DNA模版的reads,其在参考序列上的起始点相同; 对于PE测序, 两个端点的起始点都相同。在测序的过程中，序列是独立的，单个DNA模版的产物是相同，变异检测基于这种DNA模版产物相同而进行；在样品处理、建库测序中产生的错误(比如PCR bias，flowcell lane的邻近cluster污染)将会集中到重复，重复会增大变异检测结果的假阴性和假阳性。<br>一般来讲，扩增子测序和RNA-seq进行基因表达分析不用去除重复。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.使用samtools去重复</span></span><br><span class="line">samtools rmdup sample_name.sorted.bam sample_name.sorted.rmdup.bam</span><br><span class="line"><span class="comment"># 1.使用picard去重复</span></span><br><span class="line">java -jar picard.jar MarkDuplicates \ </span><br><span class="line">  REMOVE_DUPLICATES=<span class="literal">true</span> \              <span class="comment"># 如果不希望删除重复序列,只是进行标注,本语句不加</span></span><br><span class="line">  I=sample_name.sorted.bam \</span><br><span class="line">  O=sample_name.sorted.rmdup.bam \</span><br><span class="line">  M=sample_name.markdup_metrics.txt</span><br><span class="line"><span class="comment"># 2. 建立samtools index,方便访问</span></span><br><span class="line">samtools index sample_name.sorted.rmdup.bam <span class="comment"># sample_name.sorted.rmdup.bam.bai</span></span><br></pre></td></tr></table></figure><h3 id="3-3-局部重比对-locate-region-realignment"><a href="#3-3-局部重比对-locate-region-realignment" class="headerlink" title="3.3 局部重比对(locate region realignment)"></a>3.3 局部重比对(locate region realignment)</h3><p>本步骤会去除由多连续碱基引起的INDELs, 对于基于组装的变异检测此步不是必需,因为组装过程中多连续碱基引起的变异检测会被忽略(<strong>对于RNA-seq,会进行额外的Split ‘N’ Trim</strong>)。本步的目的在于对潜在的序列插入或删除的区域进行校正;因为全局搜索最优匹配算法在存在插入删除的区域附近的比对结果不是很好;再者,不同算法对错配和gap的容忍度不同,同样会导致不同的比对结果。本步执行的效果可见图：<a href="https://s1.ax1x.com/2018/07/04/PEHlAx.png。" target="_blank" rel="noopener">https://s1.ax1x.com/2018/07/04/PEHlAx.png。</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 定位需要重比对的目标区域</span></span><br><span class="line">java -jar /path/to/GenomeAnalysisTK.jar \</span><br><span class="line">    -T RealignerTargetCreator \</span><br><span class="line">    -R /path/to/ref_name.fasta \</span><br><span class="line">    -I sample_name.sorted.rmdup.bam \     <span class="comment"># 有多个样本就有多个本语句</span></span><br><span class="line">    -known /path/to/gatk/bundle/1000G_phase1.indels.b37.vcf \       <span class="comment"># 添加已知的候选variant区域;下同; b37的版本对应这ref_name.fasta的版本</span></span><br><span class="line">    -known /path/to/gatk/bundle/Mills_and_1000G_gold_standard.indels.b37.vcf \</span><br><span class="line">    -o sample_name.IndelRealigner.intervals</span><br><span class="line"><span class="comment"># 2. 进行序列重比对</span></span><br><span class="line">java -jar /path/to/GenomeAnalysisTK.jar \</span><br><span class="line">    -T IndelRealigner \</span><br><span class="line">    -R /path/to/ref_name.fasta \</span><br><span class="line">    -I sample_name.sorted.markdup.bam \</span><br><span class="line">    -known /path/to/gatk/bundle/1000G_phase1.indels.b37.vcf \</span><br><span class="line">    -known /path/to/gatk/bundle/Mills_and_1000G_gold_standard.indels.b37.vcf \</span><br><span class="line">    -o sample_name.sorted.rmdup.realign.bam \</span><br><span class="line">    --targetIntervals sample_name.IndelRealigner.intervals</span><br></pre></td></tr></table></figure><h3 id="3-4-碱基质量校正-Base-Quality-Score-Recalibration-BQSR"><a href="#3-4-碱基质量校正-Base-Quality-Score-Recalibration-BQSR" class="headerlink" title="3.4 碱基质量校正(Base Quality Score Recalibration, BQSR)"></a>3.4 碱基质量校正(Base Quality Score Recalibration, BQSR)</h3><p>系统性误差是变异检测结果不好的主要原因：不同测序技术和测序仪器的系统误差都不一样。再者，后续的分析是基于碱基质量，所以碱基质量分数不能含有PCR bias引起的偏差。为了(尽可能)校正这些错误,BQSR实际上是在执行的时候是按照不同的测序lane或者测序文库来进行，这个时候@RG信息(BWA比对时所设置的)就显得很重要了,算法就是通过@RG中的ID来识别各个独立的测序过程，其过程简要概括为计算lane, original quality score, machine cycle, sequencing context的covariates。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. build base recalibration model</span></span><br><span class="line">gatk BaseRecalibrator \</span><br><span class="line">    -R ref.fasta -I sample.bam \</span><br><span class="line">    -knownSites snps.vcf.gz \</span><br><span class="line">    -knownSites indels.vcf.gz \</span><br><span class="line">    -O recal.table</span><br><span class="line">    <span class="comment">#-bqsr 1st_recal.table #如果是进行第二次的recallibrator</span></span><br><span class="line"><span class="comment"># 2. ApplyBQSR</span></span><br><span class="line">gatk ApplyBQSR \</span><br><span class="line">    -R ref.fasta \</span><br><span class="line">    -I sample.bam \</span><br><span class="line">    -bqsr recal.table \</span><br><span class="line">    -O sample_bqsr.bam</span><br><span class="line">    <span class="comment"># parameters below are in GATK3, GATK4 ApplyBQSR omits by default</span></span><br><span class="line">        <span class="comment"># -SQQ 10 -SQQ 20 -SQQ 30 -SQQ 40  # to bin quals</span></span><br><span class="line">        <span class="comment"># --emit-original_quals            # to emit original quals to OQ tag</span></span><br><span class="line">        <span class="comment"># --preserve_qscores_less_than 6   # BQs less than 6 are untouched</span></span><br><span class="line"><span class="comment"># 3. 可视化校正效果,需要运行1. build base recalibration model第二次再进行可视化</span></span><br><span class="line">gatk AnalyzeCovariates -before 1st_recal.table \</span><br><span class="line">    -after 2nd_recal.table -plots plots.pdf</span><br></pre></td></tr></table></figure><h2 id="四、Germline-variant-discovery：SNPs-amp-Indels"><a href="#四、Germline-variant-discovery：SNPs-amp-Indels" class="headerlink" title="四、Germline variant discovery：SNPs &amp; Indels"></a>四、Germline variant discovery：SNPs &amp; Indels</h2><h3 id="4-1-单倍体检测-HaplotypeCaller"><a href="#4-1-单倍体检测-HaplotypeCaller" class="headerlink" title="4.1 单倍体检测(HaplotypeCaller)"></a>4.1 单倍体检测(HaplotypeCaller)</h3><p>HaplotypeCaller有2个模式可选，一个是默认模式，所有bam文件一起跑；一个GVCF模式，bam文件分开跑，生成中间g.vcf文件，这个模式利于后面添加新的样品联合分析，即所谓的N+1。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># basic mode, no GVCF</span></span><br><span class="line">gatk HaplotypeCaller \</span><br><span class="line">    -R reference.fasta \</span><br><span class="line">    -I preprocessed_reads.bam -O germline_variants.vcf</span><br><span class="line"><span class="comment"># GVCF mode</span></span><br><span class="line">gatk HaplotypeCaller \</span><br><span class="line">    -R reference.fasta -I preprocessed_reads.bam \</span><br><span class="line">    -O germline_variants.g.vcf -ERC GVCF</span><br></pre></td></tr></table></figure><h4 id="4-1-1-HaplottypeCaller的运行逻辑"><a href="#4-1-1-HaplottypeCaller的运行逻辑" class="headerlink" title="4.1.1 HaplottypeCaller的运行逻辑"></a>4.1.1 HaplottypeCaller的运行逻辑</h4><ol><li><p>identify activeRegions<br>sliding window along the reference <em>=&gt;</em> count mismatches, indels and soft-clips <em>=&gt;</em> measure of entropy <em>=&gt;</em> trim and continue with activeRegions over threshold</p></li><li><p>assemble plusible haplotypes<br>local realignment via graph assembly <em>=&gt;</em> traverse graph to collect most likely haplotypes <em>=&gt;</em> align haplotypes to reference using Smith-Waterman <em>=&gt;</em> get likely haplotypes and candidate variant sites</p></li><li><p>score haplotypes using PairHMM<br>PairHMM aligns each read to each haplotype <em>=&gt;</em> uses base qualities as the estimate of error <em>=&gt;</em> get likelihoods of the haplotypes given reads</p></li><li><p>genotype each sample at each potential variant site<br>detemine most likely combination of alleles for each site <em>=&gt;</em> based on allele likelihoods (from PairHMM) <em>=&gt;</em> apply bayes’theorem with ploidy assumption</p></li></ol><h3 id="4-2-合并calling-joint-calling-necessary-for-GVCF-mode"><a href="#4-2-合并calling-joint-calling-necessary-for-GVCF-mode" class="headerlink" title="4.2 合并calling (joint calling, necessary for GVCF mode)"></a>4.2 合并calling (joint calling, necessary for GVCF mode)</h3><p>可以进行联合分析，如前所述，有新的样品加入；如果是人的或已经有人分析的同类样品数据，可以加入进来进行联合分析</p><p><img src="https://s1.ax1x.com/2018/07/04/PVSEZD.png" alt="联合分析"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GATK3, with CombineGVCFs</span></span><br><span class="line">gatk CombineGVCFs \</span><br><span class="line">    -R reference.fasta \</span><br><span class="line">    -V sample1.g.vcf \</span><br><span class="line">    -V sample2.g.vcf \</span><br><span class="line">    -O combined.g.vcf</span><br><span class="line"></span><br><span class="line"><span class="comment"># GATK4, with GenomicsDBImport</span></span><br><span class="line">gatk GenomicsDBImport \</span><br><span class="line">    -R reference.fasta \</span><br><span class="line">    -V sample1.g.vcf \</span><br><span class="line">    -V sample2.g.vcf \</span><br><span class="line">    -L chr20 \</span><br><span class="line">    --genomicsdb-workspace-path gvcfs_db</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># on a single- or multi-sample GVCF, can be the combinned.g.vcf</span></span><br><span class="line">gatk GenotypeGVCFs \</span><br><span class="line">    -R reference.fasta \</span><br><span class="line">    -V variants.g.vcf \</span><br><span class="line">    -O final_variants.vcf</span><br><span class="line">    </span><br><span class="line"><span class="comment"># on a genomicsDB workspace</span></span><br><span class="line">gatk GenotypeGVCFs \</span><br><span class="line">    -R reference.fasta \</span><br><span class="line">    -V gendb://gvcfs_db \</span><br><span class="line">    -O final_variants.vcf</span><br></pre></td></tr></table></figure><h3 id="4-3-变异校正：VQSR-variant-quality-score-recalibration"><a href="#4-3-变异校正：VQSR-variant-quality-score-recalibration" class="headerlink" title="4.3 变异校正：VQSR(variant quality score recalibration)"></a>4.3 变异校正：VQSR(variant quality score recalibration)</h3><p>应该对原始的变异检测集进行过滤,以平衡检测集的敏感性和特异性.由于变异检测的算法通常是十分宽松开放的, 变异检测敏感性升高的同时自然会带来许多假阳性.这时候,我们有两种策略来进行过滤. 其一是使用二分阈值进行硬过滤,十分简单粗暴 但这需要我们有足够的经验去确定这个阈值. 其二则是使用机器学习的方法进行变异校正(variant recalibration，VR),对变异的辨识度较好, 但这个方法需要我们有足够多的已知数据进行训练.采用已知的高置信度的变异位点数据集进行训练, 得到某位点是否为变异位点的概率. VQSLOD就是采用此类方法进行过滤的.不过,可以肯定的是,这两种策略都应该协调好敏感性和特异性的问题,也需要对变异环境进行注释(use variant context annotations)。</p><p>VR的处理简要过程为：假定变异位点注释符合高斯聚类，然后基于已知变异位点注释数据集建立高斯混合模型(Gaussian mixure model)，接着根据位点与聚类之间的距离对所有位点进行打分，最后基于打分进行过滤。</p><blockquote><p>当你的样品不是人类或者没有足够的已知数据集时,不用进行本步骤. RNA-seq有独有的过滤操作,也不用进行本步骤,样本数太少也不用进行本步骤。 SNPs和Indels要分开各自进行校正,也就是说要以SNPmode和Indelmode各校正一次.</p></blockquote><blockquote><p>对于外显子数据,样本量太少的话,数据不足以建立一个健壮的高斯模型,联合分析(jointly)需要至少30个样本.</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 从已有数据集建立和应用高斯混合模型 VariantRecalibrator</span></span><br><span class="line">gatk VariantRecalibrator \</span><br><span class="line">    -R human.fasta</span><br><span class="line">    -V raw.SNPs.vcf</span><br><span class="line">    -resource [tags]:filename.vcf \</span><br><span class="line">    -an DP -an QD -an FS -an MQRankSum &#123;...&#125; \</span><br><span class="line">    -mode SNP \</span><br><span class="line">    -recal-file raw.SNPs.recal \    <span class="comment"># use the annotations in our callset</span></span><br><span class="line">    -tranches-file raw.SNPs.tranches \      <span class="comment"># use variants in the input callset that overlap the training data</span></span><br><span class="line">    -rscript-file recal.plots.R</span><br><span class="line"><span class="comment"># output=&gt; recal file, tranches, plots</span></span><br><span class="line"><span class="comment"># tags stand for SNP resources, values as follows, all use:</span></span><br><span class="line"><span class="comment"># hapmap,known=false,training=true,truth=true,prior=15.0</span></span><br><span class="line"><span class="comment"># omni,known=false,training=true,truth=fasle,prior=12.0</span></span><br><span class="line"><span class="comment"># 1000G,known=false,training=true,truth=false,prior=10.0</span></span><br><span class="line"><span class="comment"># dnsnp,known=true,training=false,truth=false,prior=2.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 应用VQSLOD过滤变异 ApplyVQSR</span></span><br><span class="line">gatk ApplyVQSR \</span><br><span class="line">    -R human.fasta \</span><br><span class="line">    -V raw.vcf \</span><br><span class="line">    -mode SNP \</span><br><span class="line">    -recal-file raw.SNPs.recal \</span><br><span class="line">    -tranches-file raw.SNPs.tranches \</span><br><span class="line">    -O recal.SNPs.vcf \</span><br><span class="line">    -ts-filter-level 99.0</span><br></pre></td></tr></table></figure><h3 id="4-4-表型加强-Genotype-refinement"><a href="#4-4-表型加强-Genotype-refinement" class="headerlink" title="4.4 表型加强(Genotype refinement)"></a>4.4 表型加强(Genotype refinement)</h3><p>通过使用额外的数据集改善表型检测和似然情况(genotype calls &amp; likelihoods)。具体过程如下：</p><p><img src="https://s1.ax1x.com/2018/07/04/PVSQQP.png" alt="genotype refinement workflow"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.</span></span><br><span class="line">gatk CalculateGenotypePosteriors \</span><br><span class="line">    -R reference.fasta -V input.vcf \</span><br><span class="line">    -ped family.ped -supporting population.vcf \</span><br><span class="line">    -O output.vcf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. filter low confidence GQs</span></span><br><span class="line">gatk VariantFiltration \</span><br><span class="line">    -R reference.fasta -V input.vcf \</span><br><span class="line">    --filter-expression <span class="string">'GQ&lt;20'</span> --filter-name <span class="string">'lowGQ'</span> \</span><br><span class="line">    -O output.vcf</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 3. variantAnnotator</span></span><br><span class="line">gatk VariantAnnotator \</span><br><span class="line">    -R reference.fasta -V input.vcf \</span><br><span class="line">    -A PossibleDenovo -O output.vcf</span><br></pre></td></tr></table></figure><h3 id="4-5-变异集验证-callset-evaluation"><a href="#4-5-变异集验证-callset-evaluation" class="headerlink" title="4.5 变异集验证(callset evaluation)"></a>4.5 变异集验证(callset evaluation)</h3><p>callset evaluation是为了验证variant calling结果的好坏，false positive怎么样。这里我们假设基于如果calling set是真实的，那么这个结果是典型且可比较的, 不一致性则表明有错误。(guiding principle: divergence is indicative of error<br>key assumption: truth set is representative or comparable)。通常用于作为true set的有commonly used truth sets: dbSNP, ExAC and GnomAD, HapMap, OMNI, NIST’s Genomes in a Bottle, Illumina’s Platinum Genomes。一般来讲，TiTv Ratio(Transitions / Transversions)在全基因组测序中的值为2.0-2.1，在全外显子测序中的值为3.0-3.3。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.GATK: get Variant level evaluation</span></span><br><span class="line">java -jar GenomeAnalysisTK.jar \</span><br><span class="line">    -T VariantEval -R reference.b37.fasta \</span><br><span class="line">    -<span class="built_in">eval</span> callset.vcf --comp truthset.vcf \</span><br><span class="line">    -o results.eval.grp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.GATK: get Genotype concordance</span></span><br><span class="line">java -jar GenomeAnalysisTK.jar \</span><br><span class="line">    -T GenotypeConcordance --comp truthset.vcf \</span><br><span class="line">    --<span class="built_in">eval</span> callset.vcf -o result.grp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.Picard: get variant level evalution</span></span><br><span class="line">java -jar picard.jar \</span><br><span class="line">    CollectVariantCallingMetrics INPUT=callset.vcf \</span><br><span class="line">    DBSNP=truthset.vcf OUTPUT=results</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 4.Picard: get genotype concordance</span></span><br><span class="line">java -jar picard.jar \</span><br><span class="line">    GenotypeConcordance CALL_VCF=callset.vcf \</span><br><span class="line">    TRUTH_VCF=truthset.vcf call_SAMPLE=sampleName \</span><br><span class="line">    TRUTH_SAMPLE=sampleName output=results</span><br></pre></td></tr></table></figure><h2 id="五、Somatic-variant-discovery-SNPs-amp-Indels"><a href="#五、Somatic-variant-discovery-SNPs-amp-Indels" class="headerlink" title="五、Somatic variant discovery: SNPs &amp; Indels"></a>五、Somatic variant discovery: SNPs &amp; Indels</h2><p><img src="https://s1.ax1x.com/2018/07/05/PVwKV1.png" alt="basic pipeline"></p><h3 id="5-1-用Mutect2检测体细胞小变异-产生bamout文件"><a href="#5-1-用Mutect2检测体细胞小变异-产生bamout文件" class="headerlink" title="5.1 用Mutect2检测体细胞小变异,产生bamout文件"></a>5.1 用Mutect2检测体细胞小变异,产生bamout文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里在tumor sample和对应的normal sample(a panel of normals, PoN)寻找变异</span></span><br><span class="line"><span class="comment"># 此外,这里还用到了群体种系变异数据集(a population germline variant resource)</span></span><br><span class="line">gatk --java-options <span class="string">'-Xmx2g'</span> Mutect2 \</span><br><span class="line">    -R hg38/Homo_sapiens_assembly38.fasta \</span><br><span class="line">    -I tumor.bam \</span><br><span class="line">    -I normal.bam \</span><br><span class="line">    -tumor HCC1143_tumor \</span><br><span class="line">    -normal HCC1143_normal \</span><br><span class="line">    -pon resources/chr17_pon.vcf.gz \</span><br><span class="line">    --germline-resource resources/chr17_af-only-gnomad_grch38.vcf.gz \</span><br><span class="line">    --af-of-alleles-not-in-resource 0.0000025 \</span><br><span class="line">    --<span class="built_in">disable</span>-read-filter MateOnSameConigOrNoMapptedMateReadFilter \</span><br><span class="line">    -L chr17plus.interval_list \</span><br><span class="line">    -O 1_somatic_m2.vcf.gz \</span><br><span class="line">    -bamout 2_tumor_normal_m2.bam</span><br><span class="line"></span><br><span class="line"><span class="comment"># parameters(下页还有参数)</span></span><br><span class="line"><span class="comment">#-I      提供bam文件,这里分别是肿瘤和正常的bam文件</span></span><br><span class="line"><span class="comment">#-tumor  提供bam文件对应的样本名(SM值),下同</span></span><br><span class="line"><span class="comment">#-normal 同上.可通过samtools view -H tumor.bam | grep '@RG'语句获得</span></span><br><span class="line"><span class="comment">#-pon</span></span><br><span class="line"><span class="comment">#预过滤正常变异位点集(a panel of normals callset)内的变异位点,需要指定PoN VCF文件.PoN不仅包含了常见的种系变异位点，也包含了常见的测序噪音.默认情况下,工具不会对与PoN中匹配的变异位点进行重组装或者判断为变异位点.如果要允许对PoN位点表型分型,使用--genotype-pon-sites设定.</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#--germline-resource</span></span><br><span class="line"><span class="comment">#通过指定群体种系资源(population germline resource)来对变异等位基因做注释群体种系资源必需包含等位基因特异频率,如在INFO域的AF注释.本工具使用种群等位基因频率对变异等位基因进行注释.当使用本参数时,需要考虑对--af-of-alleles-not-in-resource参数进行调整到默认的0.001.例如gnomAD resouce af-only-gnomad_grch38.vcf.gz含有200K的外显子和16k的基因组;而-I指定的数据是外显子数据,所以调整值是1/(2*exome)*0.001,即1/(2*200)*0.001=0.0000025.默认的0.001是没有种群资源的人类样品的大概值,这是基于人类平均杂合率计算得到.种群等位基因频率(POP_AF)和af-of-alleles-not-in-resource在计算变异位点时的概率有用到.</span></span><br><span class="line"><span class="comment">#--disable-read-filter MateOnSameConigOrNoMapptedMateReadFilter</span></span><br><span class="line"><span class="comment">#该参数指定保留那些配对read比对到其他不同contig的reads(pair end reads成对的).该参数的效果保留的reads均是比对到alternate contigs和span contigs的reads,对变异检测有帮助作用.</span></span><br><span class="line"><span class="comment">#-L      指定特定的目标基因组区域进行分析.这里指定该参数的目的是为了减少运行时间,加快速度.</span></span><br><span class="line"><span class="comment">#-bamout 该参数指定生成重组装的比对文件.它包含手工的单倍体和normal同Tumor的重组装比对文件.这使得手工检阅获得的变异检测称为可能.本参数可以忽略,但推荐使用,毕竟不会额外花多少时间.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># output =&gt; 1_somatic_m2.vcf.gz(raw unfiltered somatic callset), 2_tumor_normal_m2.bam (a reassembled reads bam), 1_somatic_m2.vcf.gz.tbi (indices), 2_tumor_normal_m2.bai (indices)</span></span><br></pre></td></tr></table></figure><h3 id="5-2-创建一个只有位点-sites-only-的PoN"><a href="#5-2-创建一个只有位点-sites-only-的PoN" class="headerlink" title="5.2 创建一个只有位点(sites-only)的PoN"></a>5.2 创建一个只有位点(sites-only)的PoN</h3><p>Mutect2的tumor-only模式不止可以用于创建PoN,还可以用于样本数很少的变异检测,如线粒体DNA,也可以用于<a href="https://software.broadinstitute.org/gatk/blog?id=11315" target="_blank" rel="noopener">比较2个不同样本之间的变异差异</a>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里面我们使用三个种系样品进行创建, HG00190,NA19771,HG02759</span></span><br><span class="line"><span class="comment"># 1. 对每个样品运行tumor-only模式的Mutect2, 以HG00190为例</span></span><br><span class="line">gatk Mutect2 \</span><br><span class="line">    -R path/hg38/Homo_sapiens_assembly38.fasta \</span><br><span class="line">    -I HG00190.bam \</span><br><span class="line">    -tumor HG00190 \</span><br><span class="line">    --<span class="built_in">disable</span>-read-filter MateOnSameContigOrNoMappedMateReadFilter \</span><br><span class="line">    -L chr17plus.interval_list \</span><br><span class="line">    -O 3_HG00190.vcf.gz</span><br><span class="line"><span class="comment"># output =&gt; 3_HG00190.vcf.gz, 3_HG00190.bai</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 使用CreateSomaticPanelOfNormals对所有的normal VCFs进行核对,并合并成一个变异检测集,该方法保留在所有样品vcf中都存在的变异位点</span></span><br><span class="line"><span class="comment"># 注意,这里我们只使用3个样品,正常来讲,应该最少使用40个样本</span></span><br><span class="line">gatk CreateSomaticPanelOfNormals \</span><br><span class="line">    -vcfs 3_HG00190.vcf.gz \</span><br><span class="line">    -vcfs 4_NA19771.vcf.gz \</span><br><span class="line">    -vcfs 5_HG02759.vcf.gz \</span><br><span class="line">    -O 6_threesamplepon.vcf.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#6_threesamplepon_vcf.gz:</span></span><br><span class="line"><span class="comment">#CHROM  POS ID  REF ALT QUAL    FILTER  INFO</span></span><br><span class="line"><span class="comment">#chr6 29942399   .   C   T   .   .   .</span></span><br></pre></td></tr></table></figure><h3 id="5-3-使用GetPileupSummaries和CalculateContamination检测是否存在跨样本污染"><a href="#5-3-使用GetPileupSummaries和CalculateContamination检测是否存在跨样本污染" class="headerlink" title="5.3 使用GetPileupSummaries和CalculateContamination检测是否存在跨样本污染"></a>5.3 使用GetPileupSummaries和CalculateContamination检测是否存在跨样本污染</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 对tumor BAM运行GetPileupSummaries得到reads概览,为已知的-系列变异位点做支持</span></span><br><span class="line">gatk GetPileupSummaries \</span><br><span class="line">    -I tumor.bam \</span><br><span class="line">    -V resources/chr17_small_exac_common_3_grch38.vcf.gz \</span><br><span class="line">    -O 7_tumor_getpileupsummaries.table</span><br><span class="line"></span><br><span class="line"><span class="comment"># output =&gt; 7_tumor_getpileupsummaries.table:</span></span><br><span class="line"><span class="comment"># contig  position    ref_count   alt_count   other_alt_count allele_frequency</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#parameters</span></span><br><span class="line"><span class="comment">#--minimum-population-allele-frequency   指定最小的种群等位基因频率,默认为0.01</span></span><br><span class="line"><span class="comment">#--maximum-population-allele-frequency</span></span><br><span class="line"><span class="comment">#默认为0.2.这个工具只考虑等位基因频率在这两个范围内的纯合子可变位点.这样考虑的原因在于,如果纯合子可变位点有罕见的等位基因的话,我们更倾向于将其作为REF.那如果有跨样品污染的话,我们更倾向于将其作为平常的等位基因.</span></span><br><span class="line"><span class="comment">#-L  指定该参数只是为了减少运行时间</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 使用CalculateContamination检测污染</span></span><br><span class="line"><span class="comment"># 这里有两个模式,简单模式如下. </span></span><br><span class="line"><span class="comment"># 匹配模式需要对normal sample运行GetPileupSummaries,然后把输出文件在这里指定为-matched参数值</span></span><br><span class="line">gatk CalculateContamination \</span><br><span class="line">    -I 7_tumor_getpileupsummaries.table \</span><br><span class="line">    -O 8_tumor_calculatecontamination.table</span><br></pre></td></tr></table></figure><h3 id="5-4-使用FilterMutectCalls过滤出确信的体细胞变异"><a href="#5-4-使用FilterMutectCalls过滤出确信的体细胞变异" class="headerlink" title="5.4 使用FilterMutectCalls过滤出确信的体细胞变异"></a>5.4 使用FilterMutectCalls过滤出确信的体细胞变异</h3><p>FilterMutectCalls可确定一个体细胞变异的置信度, 采用变异检测集里面的注释,使用预设的阈值来确定.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里使用全部的变异检测集</span></span><br><span class="line"><span class="comment"># 为了在污染检测的基础上有效进行过滤,可以添加--contamination-table指定污染表(contamination-table)</span></span><br><span class="line"><span class="comment"># contamintation estimate works as a hard cutoff</span></span><br><span class="line"><span class="comment"># 如果过滤所依据的注释缺乏的话,这个过滤步骤会被跳过</span></span><br><span class="line">gatk FilterMutectCalls \</span><br><span class="line">    -V somatic_m2.vcf.gz \</span><br><span class="line">    --contamination-table tumor_calculatecontamination.table \</span><br><span class="line">    -O 9_somatic_oncefiltered.vcf.gz</span><br></pre></td></tr></table></figure><h3 id="5-5-可选-检测并过滤artifact"><a href="#5-5-可选-检测并过滤artifact" class="headerlink" title="5.5 (可选)检测并过滤artifact"></a>5.5 (可选)检测并过滤artifact</h3><p>FilterByOrientationBias在sequence context artifacts(如OxoG,FFPE)的基础上进行过滤.这步是可选的,如果执行了这一步,还需要额外执行一次FilterMutectCalls.本步所需的metrics可以通过Picard的CollectSequencingArtifactMetrics获取.当然,gatk里面整合了这个方法.</p><p>OxoG在自发的种系颠换里面; 在小鼠的生殖细胞的DNA复制时,the oxidized base 8-oxoguanine (8-oxoG)会导致自然且可遗传的G-&gt;T颠换(transversion). FFPE是指福尔马林固定的处理方式,它会导致C-&gt;T转换(transition).所有在建库时,会可能出现这两种形式的假阳性变异.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 使用CollectSequencingArtifactMetrics从sequence context artifacts里面获取metrics</span></span><br><span class="line"><span class="comment"># 这里会将artifacts进行分类,比如分为preadapter(artifacts occur before hybrid selection)和baitbias(artifacts occur during hybrid selection)</span></span><br><span class="line">gatk CollectSequencingArtifactMetricx \</span><br><span class="line">    -I tumor.bam \</span><br><span class="line">    -O 10_tumor_artifact \</span><br><span class="line">    --FILE_EXTENSION <span class="string">'.txt'</span> \</span><br><span class="line">    -R path/hg38/Homo_sapiens_assembly38.fasta</span><br><span class="line"></span><br><span class="line"><span class="comment"># 你也可以在picard里面直接使用</span></span><br><span class="line">java -jar picard.jar \</span><br><span class="line">    CollectSequencingArtifactMetricx \</span><br><span class="line">    ......</span><br><span class="line">    </span><br><span class="line"><span class="comment"># output =&gt; five metrics files, pre_adapter_detail_metrics in five is for FilterByOritentationBias</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 使用FilterByOrientationBias进行定位偏差过滤</span></span><br><span class="line"><span class="comment"># orientation指F1R2, F2R1这类的定位, reads比对到参考序列的定位.</span></span><br><span class="line">gatk FilterByOrientationBias \</span><br><span class="line">    -A G/T -A C/T \</span><br><span class="line">    -V 9_somatic_oncefiltered.vcf.gz \</span><br><span class="line">    -P tumor_artifact.pre_adapter_detail_metrics.txt \</span><br><span class="line">    -O 11_somatic_twicefiltered.vcf.gz</span><br></pre></td></tr></table></figure><h2 id="六、Somatic-variant-discovery-CNV"><a href="#六、Somatic-variant-discovery-CNV" class="headerlink" title="六、Somatic variant discovery: CNV"></a>六、Somatic variant discovery: CNV</h2><p>多数癌症是由CNV引起,如HER2,EGFR,ERBB2等是因为CNV增多引起, APC,BRCA1,BRCA2,PTEN是因为CNV减少引起,这就使得CNV的检测至关重要。</p><h3 id="6-1-如何确定CNV的产生-CNV的表征方法"><a href="#6-1-如何确定CNV的产生-CNV的表征方法" class="headerlink" title="6.1 如何确定CNV的产生? CNV的表征方法?"></a>6.1 如何确定CNV的产生? CNV的表征方法?</h3><p>copy number variants会导致覆盖度不平衡(coverage imbalance).但是coverage会因WES中靶标位置和所用kits的不同而不同. 我们可以通过copy number profile来对cnv绝对定量，获得每个基因座的拷贝数(copy number of locus),也可以通过copy ratio profile来对CNV进行相对定量，获得每个基因座的拷贝数在平均倍数性(average ploidy)的占比。虽然copy ratio可以把coverage imbalance的问题解决，但外显子的原始copy ratio数据噪声很大。需要除去噪声。</p><h3 id="6-2-获得目标区域的原始coverage-counts"><a href="#6-2-获得目标区域的原始coverage-counts" class="headerlink" title="6.2 获得目标区域的原始coverage counts"></a>6.2 获得目标区域的原始coverage counts</h3><p>在收集coverage counts之前,我们先用一个genomic intervals list确定分析的分辨率(也就是我们的目标区域). 这对wes或者wgs数据分析来说都是必要的.对于外显子数据,我们使用捕获试剂盒进行补充;对于全基因组数据,我们把参考基因组分成等长的intervals或者bins, 也可以不指定这个interval_list.不管怎么样, 都是使用PreprocessIntervals.</p><h4 id="6-2-1-根据目标区域interaval对参考序列设定interval"><a href="#6-2-1-根据目标区域interaval对参考序列设定interval" class="headerlink" title="6.2.1 根据目标区域interaval对参考序列设定interval"></a>6.2.1 根据目标区域interaval对参考序列设定interval</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># exome, wes</span></span><br><span class="line">gatk PreprocessIntervals \</span><br><span class="line">    -R reference.fasta \</span><br><span class="line">    -L intervals.interval_list \</span><br><span class="line">    --bin-length 0 \</span><br><span class="line">    --padding 250 \</span><br><span class="line">    -O preprocessed_intervals.interval_list</span><br><span class="line"><span class="comment"># genome, wgs</span></span><br><span class="line">gatk PreprocessIntervals \</span><br><span class="line">    -R reference.fasta \</span><br><span class="line">    --bin-length 1000 \</span><br><span class="line">    --padding 0 \</span><br><span class="line">    -O preprocessed_intervals.interval_list</span><br><span class="line"><span class="comment"># parameters</span></span><br><span class="line"><span class="comment">#-L  可选的参数.指定目标intervals_list</span></span><br><span class="line"><span class="comment">#--bin-length    为不同的数据类型指定适当的值,比如在这里wes是0,wgs是1000</span></span><br><span class="line"><span class="comment">#--interval-merging-rule 设定为OVERLAPPING_ONLY将阻止工具合并相邻的intervals</span></span><br><span class="line"><span class="comment">#--padding   指定intervals的padding(间隔), 默认值250在大部分wes中都效果良好</span></span><br></pre></td></tr></table></figure><h4 id="6-2-2-获得对应interval的coverage-counts"><a href="#6-2-2-获得对应interval的coverage-counts" class="headerlink" title="6.2.2 获得对应interval的coverage counts"></a>6.2.2 获得对应interval的coverage counts</h4><p>Fragment counts in each genomic target/bin allow estimates of segmented copy ratio. CollectFragmentCounts计算的是paired end fragments的覆盖度, 在interval中心重叠的fragment只会被计一次. CollectReadCounts在GATK4.0.3.0中取代了CollectFragmentCounts,而且它还会将在interval重叠的reads计数. Targets/bins + BAM =&gt; collectFragmentCounts =&gt; integer read counts.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">gatk CollectFragmentCounts \</span><br><span class="line">    -I sample.bam \</span><br><span class="line">    -L intervals.interval_list \</span><br><span class="line">    --interval-merging-rule OVERLAPPING_ONLY \</span><br><span class="line">    -O sample.counts.hdf5</span><br><span class="line"></span><br><span class="line"><span class="comment">#--format    结果格式默认为hdf5.可以指定为TSV,生成tsv格式的结果. hdf5文件可以使用HDFView软件查看.</span></span><br><span class="line"><span class="comment">#filter      这个方法在底层调用了多个过滤方法,如NotDuplicateReadFilter,FirstOfPairReadFilter, etc.</span></span><br></pre></td></tr></table></figure><h3 id="6-3-生成CNV-panel-of-normals-CNV-PoN"><a href="#6-3-生成CNV-panel-of-normals-CNV-PoN" class="headerlink" title="6.3 生成CNV panel of normals(CNV, PoN)"></a>6.3 生成CNV panel of normals(CNV, PoN)</h3><p>在创建PoN时,CreateReadCountPanelOfNormals使用了Singular Value Decomposition来对counts和interavals进行抽象. PoN用于PCA去噪. PoN里面的正常样品应该与测序方法相对应,这对wes十分重要,因为wes的捕获步骤会引入靶标特异地噪声. Fragment counts + Annotated Intervals =&gt; CreateReadCountPanelOfNormals =&gt; Panel of Normals</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">gatk --java-options <span class="string">'-Xmx6500m'</span> CreateReadCountPanelOfNormals \</span><br><span class="line">    -I HG0013.alt_bwamem_GRCh38Dh.20150826.GBR.exome.counts.hdf5 \</span><br><span class="line">    -I HG0013.alt_bwamem_GRCh38Dh.20150826.GBR.exome.counts.hdf5 \</span><br><span class="line">    ... \</span><br><span class="line">    --minimum-interval-median-percentile 5.0 \</span><br><span class="line">    -O cnv.pon.hdf5</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">gatk CreateReadCountPanelOfNormals \</span><br><span class="line">    -I sample_1.counts.hdf5 \</span><br><span class="line">    -I sample_2.counts.tsv \</span><br><span class="line">    ... \</span><br><span class="line">    --annotated-intervals annotated_intervals.tsv \</span><br><span class="line">    -O cnv.pon.hdf5</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># select parameters</span></span><br><span class="line"><span class="comment">#-I  为每个样品提供integer read coverage counts. 格式可以是TSV和HDF5.可以接受单个样品,比如和tumor配对的正常样品(matched-normal)</span></span><br><span class="line"><span class="comment">#--number-of-eigensamples    默认值为20,这个会自动校正.一般来说,在去噪时,这个值越高,敏感性就越低.你可以进行敏感性分析以选取一个合适的.</span></span><br><span class="line"><span class="comment">#--spark-master  如果要使用spark的话,该参数指定.</span></span><br><span class="line"><span class="comment"># filter parameters</span></span><br><span class="line"><span class="comment">#--minimum-interval-median-percentile    默认值为10.0,会将覆盖度的中位数低于该值的targets/bins/intervals给排除.</span></span><br><span class="line"><span class="comment">#--maximum-zeros-in-sample-percentage    默认值为5.0,会将任何具有高于5%的0覆盖率target/bins的样品排除</span></span><br><span class="line"><span class="comment">#--maximum-zeros-in-interval-percentage  默认值为5.0,会将任何具有高于5%的0覆盖率的interval的样品排除</span></span><br><span class="line"><span class="comment">#--extreme-sample-median-percentile      默认值为2.5,校正后的中位数不在2.5-97.5%之间的样品将被排除</span></span><br><span class="line"><span class="comment">#--do-impute-zeros                       默认为true.会把0覆盖率区域的覆盖率值指定为非零值的中位数.</span></span><br><span class="line"><span class="comment">#--extreme-outlier-truncation-percentile 默认值为0.1.把不在0.1-99.9%区域的值分别设为最近的值(&lt;0.1设为0.1)</span></span><br></pre></td></tr></table></figure><h3 id="6-4-Denoise-coverage-data"><a href="#6-4-Denoise-coverage-data" class="headerlink" title="6.4 Denoise coverage data"></a>6.4 Denoise coverage data</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">gatk --java-options <span class="string">'-Xmx12g'</span> DenoiseReadCounts \</span><br><span class="line">    -I sample.counts.hdf5 \</span><br><span class="line">    --count-panel-of-normals cnv.pon.hdf5 \</span><br><span class="line">    --standardized-copy-ratios sample.standardizedCR.tsv \</span><br><span class="line">    --denoised-copy-ratios sample.denoisedCR.tsv</span><br><span class="line"></span><br><span class="line"><span class="comment">#--number-of-eigensamples    默认为null,使用PoN中样品的最大可用数.在这里改变该值会改变结果的分辨率.</span></span><br><span class="line"><span class="comment">#--annotated-intervals   可以使用该参数据指定进行GC-bias correlation. 参数的输入文件可以通过AnnotateIntervals产生.</span></span><br><span class="line"><span class="comment"># output =&gt; sample.standardizedCR.tsv(标准copy ratio), sample.denoisedCR.tsv(denoised copy ratios)</span></span><br></pre></td></tr></table></figure><h3 id="6-5-可视化去噪的效果"><a href="#6-5-可视化去噪的效果" class="headerlink" title="6.5 可视化去噪的效果"></a>6.5 可视化去噪的效果</h3><p>使用PlotDenoisedCopyRatios对得到的标准化copy ratio和去噪的copy ratio作图, 显示去噪的效果。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">gatk PlotDenoisedCopyRatios \</span><br><span class="line">    --standardized-copy-ratios sample.standardizedCR.tsv \</span><br><span class="line">    --denoised-copy-ratios sample.denoised.tsv \</span><br><span class="line">    --sequence-dictionary Homo_sapiens_assembly38.dict \</span><br><span class="line">    --minimum-contig-length 46709983 \</span><br><span class="line">    --output plots \</span><br><span class="line">    --output-prefix sample</span><br><span class="line"><span class="comment"># parameters</span></span><br><span class="line"><span class="comment">#--sequence-dictionary 指定用于比对的参考序列的字典</span></span><br><span class="line"><span class="comment">#--output-prefix 指定输出文件的前缀</span></span><br><span class="line"><span class="comment">#--output 输出文件路径.会产生6个文件.</span></span><br><span class="line"><span class="comment">#[sample.denoised.png], plots the standardized and denoised read counts. [sample.denoisedLimit4.png], y轴被限定在0-4.</span></span><br><span class="line"><span class="comment">#[sample.standardizedMAD.txt, sample.denoisedMAD.txt], MAD for standardized/denoised copy ratios, </span></span><br><span class="line"><span class="comment">#[sample.deltaMAD.txt], difference between standardized MAD and denoised MAD.</span></span><br><span class="line"><span class="comment">#[sample.scaledDeltaMAD.txt], fractional difference / standardized MAD.(s-MAD - d-MAD)/s-MAD</span></span><br></pre></td></tr></table></figure><h3 id="6-6-计算常见生殖系变异位点的ref和alt-alleles"><a href="#6-6-计算常见生殖系变异位点的ref和alt-alleles" class="headerlink" title="6.6 计算常见生殖系变异位点的ref和alt alleles"></a>6.6 计算常见生殖系变异位点的ref和alt alleles</h3><p>等位基因特异覆盖率的收集仅仅是原始覆盖率的收集,并没有经过任何统计参考.对于实际样本和匹配的对照比对来说,CollectAllelicCounts都是分别收集allele counts.但是对于匹配的对照进行分析的话,样品和对照一定要匹配,不然后续的ModelSegments会发生错误.</p><p>这里没有使用GetPileupSummaries，这是因为他会使用CalculateContamination估测跨样本污染的counts.它通过群体等位基因频率来设定进行counts收集的条件.而CollectAllelicCounts用到的过滤器较少,但二者都会使用MappingQualityReadFilter进行过滤.前者的过滤阈值默认是20,可设置到30.而后者使用的阈值则是50.此外,前者还使用base-quality.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为匹配的对照(matched-control)收集位于种系变异位点的counts</span></span><br><span class="line">gatk --java-options <span class="string">'-Xmx3g'</span> CollectAllelicCounts \</span><br><span class="line">    -L chr17_theta_snps.interval_list -I normal.bam \</span><br><span class="line">    -R path/ref/Homo_sapiens_assembly38.fasta -O normal.allelicCounts.tsv</span><br><span class="line"><span class="comment"># 为每个样品在相同的位点收集counts</span></span><br><span class="line">gatk --java-options <span class="string">'-Xmx3g'</span> CollectAllelicCounts \</span><br><span class="line">    -L chr17_theta_snps.interval_list -I tumor.bam \</span><br><span class="line">    -R path/ref/Homo_sapiens_assembly38.fasta -O tumor.allelicCounts.tsv</span><br><span class="line"><span class="comment"># parameters</span></span><br><span class="line"><span class="comment">#-L  必需参数.指定一个或多个genomic intervals,可以是intervals list或VCF格式. 里面包含的sites应该代表了常见的或这样品特异地种系变异位点(而且只是SNP位点).Indel和mixed-variant-type将被忽略.</span></span><br><span class="line"><span class="comment">#--minimum-base-quality  该方法会使用MappingQualityReadFilter进行过滤,默认的过滤值是20, 即MAPQ&gt;=20.</span></span><br></pre></td></tr></table></figure><h3 id="6-7-把contiguousCopyRatios分组成segments"><a href="#6-7-把contiguousCopyRatios分组成segments" class="headerlink" title="6.7 把contiguousCopyRatios分组成segments"></a>6.7 把contiguousCopyRatios分组成segments</h3><p>对于allelic copy ratios, 在control in a paired analysis或者 case in case-only analysis, ModelSegments只使用杂合体的位点.这里把allelic copy ratios 定义为alternate-allele fraction(A-AF).</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">gatk --java-options <span class="string">'-Xmx4g'</span> ModelSegements \</span><br><span class="line">    --denoised-copy-ratios tumor.denoisedCR.tsv \</span><br><span class="line">    --allelic-counts tumor.allelicCounts.tsv \</span><br><span class="line">    --normal-allelic-counts normal.allelicCounts.tsv \</span><br><span class="line">    --ouput-prefix tumor \</span><br><span class="line">    --output output_dir</span><br><span class="line"></span><br><span class="line"><span class="comment">#output: tumor.modelBegin.seg, tumor.modelFinal.seg, tumor.cr.seg, (data on the segments)</span></span><br><span class="line"><span class="comment">#tumor.modelBegin.af.param, tumor.modelBegin.cr.param, (global parameters for copy ratios,cr, allele fractions,af)</span></span><br><span class="line"><span class="comment">#tumor.modelFinal.af.param, tumor.modelFinal.cr.param,</span></span><br><span class="line"><span class="comment">#tumor.hets.normal.tsv, tumor.hets.tsv (hets:the allelic counts for the control's heterogygous sites, normal: counts for the matched control)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#--denoised-copy-ratios  输入的数据,可以是copy-ratios,也可以是--allelic-counts.下同.</span></span><br><span class="line"><span class="comment">#--allelic-counts        同上.</span></span><br><span class="line"><span class="comment">#--minimum-total-allele-count    默认值为30.对于allelic copy ratios,只考虑read depth coverage超过设定值的位点.</span></span><br><span class="line"><span class="comment">#--genotyping-homozygous-log-ratio-threshold 默认值为-10.0.指定建模时假定的杂合体的位点数目.</span></span><br><span class="line"><span class="comment">#--maximum-number-of-smoothing-iterations    指定建模时的平滑迭代次数,默认为25.</span></span><br></pre></td></tr></table></figure><h4 id="6-7-1-ModelSegments运行的三个阶段"><a href="#6-7-1-ModelSegments运行的三个阶段" class="headerlink" title="6.7.1 ModelSegments运行的三个阶段"></a>6.7.1 ModelSegments运行的三个阶段</h4><ol><li>对杂合位点进行分型,依据覆盖深度(depth)和copy-ratio intervals重叠位点进行过滤.对照中杂合的位点写入产生hets.normal.tsv文件,样本中相同的位点写入hets.tsv文件.</li><li>执行多维Kernel segmentation.这里使用到allelic counts和denoised copy ratios.</li><li>进行Markov-Chain Monte Carlo抽样和平滑分割.初始拟合模型写入modelBegin.seg,及对应的参数设置.最终拟合模型写入modelFinal.seg,及对于的参数设置.</li></ol><h3 id="6-8-检测正常拷贝数、拷贝数增多、减少的segments"><a href="#6-8-检测正常拷贝数、拷贝数增多、减少的segments" class="headerlink" title="6.8 检测正常拷贝数、拷贝数增多、减少的segments"></a>6.8 检测正常拷贝数、拷贝数增多、减少的segments</h3><p>call copy number events. 此步骤对于画出segmentation结果图并不是必需的. 使用ModelSegments的输出cr.seg作为输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gatk CallCopyRatioSegments \</span><br><span class="line">    -I tumor.cr.seg -O tumor.called.seg</span><br><span class="line"></span><br><span class="line"><span class="comment">#--neutral-segment-copy-ratio-lower-bound    默认值为0.9.设置copy-neutral segments的范围.下同.</span></span><br><span class="line"><span class="comment">#--neutral-segment-copy-ratio-upper-bound    默认值为1.1.同上.</span></span><br></pre></td></tr></table></figure><h3 id="6-9-可选-对分割-segmentation-result-结果画图"><a href="#6-9-可选-对分割-segmentation-result-结果画图" class="headerlink" title="6.9 可选.对分割(segmentation result)结果画图"></a>6.9 可选.对分割(segmentation result)结果画图</h3><p>visualizes copy and allelic ratio segmentation results.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">gatk PlotModeledSegments \</span><br><span class="line">    --denoised-copy-ratios tumor.denoisedCR.tsv --allelic-counts tumor.hets.tsv \</span><br><span class="line">    --segments tumor.modelFinal.seg --minimum-contig-length 46709983 \</span><br><span class="line">    --sequence-dictionary Homo_sapiens_assembly38.dict \        <span class="comment"># also contigs_to_plot.dict</span></span><br><span class="line">    --output-prefix tumor -O output_dir</span><br><span class="line"></span><br><span class="line"><span class="comment">#--sequence-dictionary   比对时使用的参考序列的字典</span></span><br><span class="line"><span class="comment">#--minimum-contig-length 对于GRCh38版本的参考序列来说,默认值是1,000,000-46,709,983.设置后,低于设置值的alternate/decoy contigs将会被忽略,不会画到图里面去.</span></span><br><span class="line"><span class="comment">#(-L)    </span></span><br><span class="line"><span class="comment">#你无法通过指定-L来可视化特定染色体或interval区域.你可以选择其他方式：其一, 把sequence-dictionary设置成你感兴趣的contigs, contigs_to_plot.dict。其二, 把感兴趣的CNV数据转化为BED格式,在IGV里面可视化.其三, 把数据导入R,选取感兴趣数据部分进行可视化.</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 变异检测 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>GO_KEGG富集分析 clusterProfiler</title>
      <link href="/2018/10/12/GO_KEGG%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90-clusterProfiler/"/>
      <url>/2018/10/12/GO_KEGG%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90-clusterProfiler/</url>
      
        <content type="html"><![CDATA[<p>首先呢,要详细了解的话,需要看这篇文献(Ten Years of Pathway Analysis: Current Approaches and Outstanding Challenges),他把基本的信号通路分析方法进行了总结.</p><a id="more"></a><h2 id="1-对Ensembl-ID进行转换-得到对应的基因名和EntrezID"><a href="#1-对Ensembl-ID进行转换-得到对应的基因名和EntrezID" class="headerlink" title="1.对Ensembl ID进行转换,得到对应的基因名和EntrezID"></a>1.对Ensembl ID进行转换,得到对应的基因名和EntrezID</h2><p>不同的物种要选择不同的数据库,不然选择不上.</p><ul><li>斑马鱼: <a href="http://www.bioconductor.org/packages/release/data/annotation/html/org.Dr.eg.db.html" target="_blank" rel="noopener">org.Dr.eg.db</a></li><li>拟南芥: <a href="http://www.bioconductor.org/packages/release/data/annotation/html/org.At.tair.db.html" target="_blank" rel="noopener">org.At.tair.db</a></li><li>小鼠: <a href="http://www.bioconductor.org/packages/release/data/annotation/html/org.Mm.eg.db.html" target="_blank" rel="noopener">org.Mm.eg.db</a></li><li>大鼠: <a href="https://www.bioconductor.org/packages/release/data/annotation/html/org.Rn.eg.db.html" target="_blank" rel="noopener">org.Rn.eg.db</a></li><li>人类: <a href="http://www.bioconductor.org/packages/release/data/annotation/html/org.Hs.eg.db.html" target="_blank" rel="noopener">org.Hs.eg.db</a></li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">suppressMessages(<span class="keyword">library</span>(org.Hs.eg.db))</span><br><span class="line">keytypes(org.Hs.eg.db)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ensids的ID类型与select函数的keytype要一致.如果是ENTREZID,就不用执行这一步.</span></span><br><span class="line">ensids = c(<span class="string">'400212'</span>, <span class="string">'238240'</span>, <span class="string">'238204'</span>)    </span><br><span class="line">cols &lt;- c(<span class="string">"SYMBOL"</span>, <span class="string">"GENENAME"</span>, <span class="string">'ENTREZID'</span>)</span><br><span class="line">gene = select(org.Hs.eg.db, keys=ensids, columns=cols, keytype=<span class="string">"ENTREZID"</span>)</span><br></pre></td></tr></table></figure><h2 id="2-进行注释"><a href="#2-进行注释" class="headerlink" title="2. 进行注释"></a>2. 进行注释</h2><p>同样的,OrgDb的参数数据库, 不同的物种要选择不同的数据库.</p><p>enrichKEGG的organism的参数要符合 <a href="http://www.genome.jp/kegg/catalog/org_list.html" target="_blank" rel="noopener">http://www.genome.jp/kegg/catalog/org_list.html</a> 所列.</p><h3 id="GO-amp-KEGG"><a href="#GO-amp-KEGG" class="headerlink" title="GO &amp; KEGG"></a>GO &amp; KEGG</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(clusterProfiler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.cell category</span></span><br><span class="line">ego_CC &lt;- enrichGO(gene = gene$ENTREZID, OrgDb= org.Hs.eg.db, ont = <span class="string">"CC"</span>, pAdjustMethod = <span class="string">"BH"</span>,</span><br><span class="line">                   minGSSize = <span class="number">1</span>, pvalueCutoff = <span class="number">0.01</span>, qvalueCutoff = <span class="number">0.01</span>, readable = <span class="literal">TRUE</span>)</span><br><span class="line"><span class="comment"># 2.biological progress</span></span><br><span class="line">ego_BP &lt;- enrichGO(gene = gene$ENTREZID, OrgDb= org.Hs.eg.db, ont = <span class="string">"BP"</span>,</span><br><span class="line">                   pAdjustMethod = <span class="string">"BH"</span>, minGSSize = <span class="number">1</span>,</span><br><span class="line">                   pvalueCutoff = <span class="number">0.01</span>, qvalueCutoff = <span class="number">0.01</span>, readable = <span class="literal">TRUE</span>)</span><br><span class="line"><span class="comment"># 3.molecular function</span></span><br><span class="line">ego_MF &lt;- enrichGO(gene = gene$ENTREZID, OrgDb= org.Hs.eg.db, ont = <span class="string">"MF"</span>,</span><br><span class="line">                   pAdjustMethod = <span class="string">"BH"</span>, minGSSize = <span class="number">1</span>, pvalueCutoff = <span class="number">0.01</span>,</span><br><span class="line">                   qvalueCutoff = <span class="number">0.01</span>, readable = <span class="literal">TRUE</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.KEGG</span></span><br><span class="line">kk &lt;- enrichKEGG(gene = gene$ENTREZID, organism =<span class="string">"human"</span>, pvalueCutoff = <span class="number">0.01</span>,</span><br><span class="line">                 qvalueCutoff = <span class="number">0.01</span>, minGSSize = <span class="number">1</span>,</span><br><span class="line">                 <span class="comment">#readable = TRUE, </span></span><br><span class="line">                 use_internal_data =<span class="literal">FALSE</span>)</span><br></pre></td></tr></table></figure><h3 id="GSEA富集分析"><a href="#GSEA富集分析" class="headerlink" title="GSEA富集分析"></a>GSEA富集分析</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gse &lt;- gseGO(gene = gene$ENTREZID, ont = <span class="string">"BP"</span>, </span><br><span class="line">            OrgDb = org.Hs.eg.db, keyType = <span class="string">"ENTREZID"</span>, exponent = <span class="number">1</span>,</span><br><span class="line">            nPerm = <span class="number">1000</span>, minGSSize = <span class="number">10</span>, maxGSSize = <span class="number">500</span>, pvalueCutoff = <span class="number">0.05</span>,</span><br><span class="line">            pAdjustMethod = <span class="string">"BH"</span>, verbose = <span class="literal">TRUE</span>, seed = <span class="literal">FALSE</span>, by = <span class="string">"fgsea"</span>)</span><br></pre></td></tr></table></figure><h2 id="3-进行可视化"><a href="#3-进行可视化" class="headerlink" title="3.进行可视化"></a>3.进行可视化</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">results = c(ego_cc, ego_BP, ego_MF, kk)</span><br><span class="line">names = c(<span class="string">'GO enrich: CC'</span>, <span class="string">'GO enrich: BP'</span>, <span class="string">'GO_enrich_MF'</span>, <span class="string">'KEGG enrich'</span>)</span><br><span class="line"><span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1</span>:length(results)) &#123;</span><br><span class="line">    barplot(results[i], showCategory=<span class="number">20</span>,title=names[i])</span><br><span class="line">    dotplot(results[i],title=names[i])</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># GSEA plot</span></span><br><span class="line">gseaplot(gse, geneSetID=<span class="string">"GO:0004871"</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>加权共表达基因网络分析 WGCNA</title>
      <link href="/2018/10/12/%E5%8A%A0%E6%9D%83%E5%85%B1%E8%A1%A8%E8%BE%BE%E5%9F%BA%E5%9B%A0%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90-WGCNA/"/>
      <url>/2018/10/12/%E5%8A%A0%E6%9D%83%E5%85%B1%E8%A1%A8%E8%BE%BE%E5%9F%BA%E5%9B%A0%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90-WGCNA/</url>
      
        <content type="html"><![CDATA[<p>在拿到高通量测序数据以后(特别是基因表达数据),通常要分析基因与表型之间的相关性,以探究基因对表型所起关键的调节功能；而加权基因共表达网络分析(Weighted Gene Coexpression Network Analysis)就是其中比较实用的一种分析方法。那么,什么是加权基因共表达网络分析呢？要了解这个,我们需要对以下前提有所了解。</p><ul><li>功能相关的基因,其表达水平/表达模式也基本上是相似的</li><li>表达水平高度相关的基因具有潜在的共有调控机制或参与相似的生物学过程</li><li>如果得到某个表达模式中涉及到许多基因,其中有些基因是已知的,基于上面两点,那么就可以通过该已知基因的功能推测未知基因的功能</li></ul><p>根据上面三点,我们就要得到有许多基因涉及的表达模式,而这个可以通过对基因的表达数据进行聚类得到.讲到这里,WGCNA实质上也是一种聚类方法.而在WGCNA之前,现在也在使用的另一种基因与表型的分析方法,那就是基因共表达网络分析.而WGCNA相较于后者来讲,有何优势?</p><a id="more"></a><h2 id="一、总述"><a href="#一、总述" class="headerlink" title="一、总述"></a>一、总述</h2><h3 id="1-1-相较于GCNA-WGCNA的优势"><a href="#1-1-相较于GCNA-WGCNA的优势" class="headerlink" title="1.1 相较于GCNA,WGCNA的优势"></a>1.1 相较于GCNA,WGCNA的优势</h3><ol><li>对Pearson coefficient的绝对值取β次幂构建相关性<br>这样做的优势在于,如果两个基因相关性较高的话,取幂后相关性更高;相关性较低,取幂后相关性更低.如此,就更加凸显两个基因的相关性.</li><li>相关性阈值的软设定<br>使用相关性软阈值设定的方法,进一步涵盖潜在的显著相关性基因;而非一刀切,因为你无法判定0.89与0.90之间,前者就相关性不显著,后者就显著相关.如果一刀切的话,你的结果则依据这个相关性阈值的设定不同,而显著不同</li><li>以TOM进一步表征基因的相关性<br>在基因两两相关而构建的网络（图）中，通过判断两个基因与其他基因相关性的相似程度来确定这两个基因的实际相关性（topological overlap），以此聚类得出的分组更符合前面所述的前提。</li></ol><h3 id="1-2-相较于差异分析-WGCNA优势"><a href="#1-2-相较于差异分析-WGCNA优势" class="headerlink" title="1.2 相较于差异分析,WGCNA优势"></a>1.2 相较于差异分析,WGCNA优势</h3><ul><li>从更高层次理解基因表达与表型之间的因果关系<br>相较于简单比较不同处理中基因表达的差异，WGCNA立足于基因模块（多个基因）的共有效应，更加符合实际情况，因为生命活动就是多中因素共同调节的结果。</li></ul><h3 id="1-3-基本术语"><a href="#1-3-基本术语" class="headerlink" title="1.3 基本术语"></a>1.3 基本术语</h3><table><thead><tr><th>术语</th><th>解析</th></tr></thead><tbody><tr><td>共表达网络(co-expression network)</td><td>无向的、加权的表达网络。无符号的a(i,j) =</td><td>cor(xi, xj)</td><td>^β,有符号的a(i,j) =</td><td>(1 + cor(xi, xj))/2</td><td>^β</td></tr><tr><td>模块(module)</td><td>高度相关的基因集</td></tr><tr><td>连接性(connectivity)</td><td>网络中某个基因与其他基因连接值的总和</td></tr><tr><td>模块内部连接性(intramodular connectivity)</td><td>模块中某个基因与同模块其他基因的连接值总和</td></tr><tr><td>模块特征(module eigengene)</td><td>给定模块的第一个主成分</td></tr><tr><td>特征显著性(eigengene significance)</td><td>模块与表型之间的相关系数</td></tr><tr><td>模块关系(基于模块特征的连接性)</td><td>给定模块的模块特征与基因表达的相关性</td></tr><tr><td>关键基因(hub gene)</td><td>给定模块中具有较大连接性的基因</td></tr><tr><td>基因显著性(gene significance)</td><td>基因表达的显著性(-log(p-value))</td></tr><tr><td>模块显著性(module significant)</td><td>给定模块中所有基因显著性的绝对值的平均值</td></tr></tbody></table><h3 id="1-4-基本过程"><a href="#1-4-基本过程" class="headerlink" title="1.4 基本过程"></a>1.4 基本过程</h3><ol><li>计算基因的相关性(Pearson correlation的β次幂，connectivity, K)</li><li>依据connectivity计算两两基因的topological overlap（relative connectivity）</li><li>根据拓扑重叠值构建基因表达网络</li><li>对此进行层次聚类，确定共表达模块（表达模式）</li><li>选取感兴趣的模块进行后续分析：模块的功能富集、模块与性状的相关性、模块与样本间的相关系数</li><li>挖掘模块的关键信息：寻找模块核心基因（hub gene)、预测基因功能</li></ol><h2 id="二、分析过程"><a href="#二、分析过程" class="headerlink" title="二、分析过程"></a>二、分析过程</h2><h2 id="2-1-导入数据、预处理"><a href="#2-1-导入数据、预处理" class="headerlink" title="2.1 导入数据、预处理"></a>2.1 导入数据、预处理</h2><p>这里主要有两个目的，一个是检测数据集是否都满足WGCNA的要求，二是排除离群值，后者需要你根据数据产生的聚类树，选择合适的cutHeight来去除离群值。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">expr = read.table(<span class="string">'./clean_data/expr_matrix.txt'</span>)</span><br><span class="line">gsg = goodSamplesGenes(expr)</span><br><span class="line"><span class="keyword">if</span> (!gsg$allOK) expr = expr[gsg$goodSamples, gsg$goodGenes]</span><br><span class="line">sampleTree = hclust(as.dist(expr), method=<span class="string">'average'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [ Visualization 1 ], 根据画出的图确定cutHeight,这里假设是120</span></span><br><span class="line">pdf(file=<span class="string">'visual_01_sampleTree_with_outlier.pdf'</span>)</span><br><span class="line">plot(sampleTree,</span><br><span class="line">main=<span class="string">'Sample Clustering to detect outliers'</span>,</span><br><span class="line">xlab=<span class="string">''</span>, sub=<span class="string">''</span>)</span><br><span class="line">abline(h=<span class="number">120</span>, col=<span class="string">'red'</span>)</span><br><span class="line">dev.off()</span><br><span class="line"></span><br><span class="line">cutHeight = <span class="number">120</span></span><br><span class="line">sample_cut = cutreeStatic(sampleTree, cutHeight=cutHeight)</span><br><span class="line">expr = expr[sample_cut == <span class="number">1</span>, ]</span><br><span class="line">sampleTreeCut = hclust(as.dist(expr), method=<span class="string">'average'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [ Visualization 2], 可视化样本聚类树和表型数据</span></span><br><span class="line">traits = read.table(file=<span class="string">'./clean_data/traits.txt'</span>)</span><br><span class="line">pdf(file=<span class="string">'visual_02_sampleCutTree_with_traits.pdf'</span>)</span><br><span class="line">colors = numbers2colors(traits)</span><br><span class="line">plotDendroAndColors(sampleTreeCut, colors,</span><br><span class="line">groupLabels=colnames(traits),</span><br><span class="line">                    main=<span class="string">'Sample Clustering and traits'</span>)</span><br><span class="line">dev.off()</span><br><span class="line"></span><br><span class="line">save(sampleTree, sampleTreeCut, expr, file=<span class="string">'01_sampleTree_cut_outlier.RData'</span>)</span><br></pre></td></tr></table></figure><h2 id="2-2-获取软阈值"><a href="#2-2-获取软阈值" class="headerlink" title="2.2 获取软阈值"></a>2.2 获取软阈值</h2><p>这里的软阈值选取power significance 大于0.8或0.85,0.9的power值。一般来说都在7-10之间。如果数据较好，可以直接通过”beta=soft$EstiamteSoft”获取，否则通过可视化获取。如果数据展示出的scale-free network不太好，那就多选取一些数据，而非仅仅基于有差异表达的基因表达矩阵。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">powers = <span class="number">1</span>:<span class="number">20</span></span><br><span class="line">powerSigR2 = <span class="number">0.8</span></span><br><span class="line">soft = pickSoftThreshold(expr, powerVectors=powers, verbose=<span class="number">3</span>)</span><br><span class="line">beta = soft$EstimateSoft</span><br><span class="line"></span><br><span class="line"><span class="comment"># [ visualizaiton 3], 可视化软阈值的选取</span></span><br><span class="line">pdf(file=<span class="string">'visual_03_soft_pick_threshold.pdf'</span>)</span><br><span class="line">par(mfrow=c(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">plot(soft$fitIndices$Power,  -sign(soft$fitIndices$slope) * soft$fitIndices$SFT.R.sq, </span><br><span class="line">     xlab=<span class="string">'Soft Threshold (power)'</span>,</span><br><span class="line">     ylab=<span class="string">'Scale Free Topology Model Fit, signed R^2'</span>, type=<span class="string">'n'</span>,</span><br><span class="line">     main=paste(<span class="string">'Scale Independce'</span>))</span><br><span class="line">text(soft$fitIndices$Power, -sign(soft$fitIndices$slope) * soft$fitIndices$SFT.R.sq,</span><br><span class="line">     labels=soft$fitIndices$Power, cex=<span class="number">0.9</span>, col=<span class="string">'red'</span>)</span><br><span class="line">abline(h=<span class="number">0.8</span>, col=<span class="string">'blue'</span>)</span><br><span class="line">plot(soft$fitIndices$Power, soft$fitIndices$mean.k.,</span><br><span class="line">     xlab=<span class="string">'Soft Threshold (power)'</span>,</span><br><span class="line">     ylab=<span class="string">'Mean connectivity'</span>, type=<span class="string">'n'</span>,</span><br><span class="line">     main=paste(<span class="string">'Mean connectivity'</span>))</span><br><span class="line">text(soft$fitIndices$Power, soft$fitIndices$mean.k.,</span><br><span class="line">     labels=soft$fitIndices$Power, cex=<span class="number">0.9</span>, col=<span class="string">'red'</span>)</span><br><span class="line">dev.off()</span><br><span class="line"></span><br><span class="line">save(soft, beta, file=<span class="string">'02_soft_threshold.RData'</span>)</span><br></pre></td></tr></table></figure><h2 id="2-3-构建网络"><a href="#2-3-构建网络" class="headerlink" title="2.3 构建网络"></a>2.3 构建网络</h2><p>构建网络有一步法和多步法，由于后续分析和可视化的需要，这里使用多步法。在我们通过拓扑网络计算节点距离进行聚类后，还可以根据聚类后的合并模块特征靠近的或者较小的模块。</p><h3 id="2-3-3-计算拓扑网络和内部连接性，基于此构建聚类树"><a href="#2-3-3-计算拓扑网络和内部连接性，基于此构建聚类树" class="headerlink" title="2.3.3 计算拓扑网络和内部连接性，基于此构建聚类树"></a>2.3.3 计算拓扑网络和内部连接性，基于此构建聚类树</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">softConnect = softConnectivity(expr, power=beta)-<span class="number">1</span></span><br><span class="line">adjacency = adjacency(expr, power=beta)</span><br><span class="line">TOM = TOMsimilarity(adjacency) <span class="comment"># 一步到位 TOM = TOMsimilarityFromExpr(expr,beta)</span></span><br><span class="line">dissTOM = <span class="number">1</span> - TOM <span class="comment"># dissTOM = TOMdist(adjacency)</span></span><br><span class="line">geneTree = hclust(as.dist(dissTOM), method=<span class="string">'average'</span>)</span><br><span class="line"><span class="comment"># [visualization 4], 可视化拓扑图</span></span><br><span class="line">pdf(file=<span class="string">'visual_04_scale_free_topology_plot.pdf'</span>)</span><br><span class="line">scaleFreePlot(softConnect, truncated=<span class="literal">F</span>,</span><br><span class="line">main=paste(<span class="string">'Scale Free Topology, power='</span>, beta,sep=<span class="string">''</span>))</span><br><span class="line">dev.off()</span><br><span class="line"><span class="comment"># [visualization 5], 可视化拓扑网络聚类树</span></span><br><span class="line">pdf(file=<span class="string">'visual_05_raw_gene_tree_on_dissTOM.pdf'</span>)</span><br><span class="line">plot(geneTree, xlab=<span class="string">''</span>, sub=<span class="string">''</span>,</span><br><span class="line">    main=<span class="string">'Gene Clustering on TOM-based dissimilarity'</span>,</span><br><span class="line">    labels=<span class="literal">F</span>, hang=<span class="number">0.04</span>)</span><br><span class="line">dev.off()</span><br><span class="line"><span class="comment"># [visualization 5.1], 可视化模块与模块之间的拓扑相异性，揭示基于拓扑重叠进行聚类的效果</span></span><br><span class="line">pdf(file=<span class="string">'visual_05_dissTOM_between_module.pdf'</span>)</span><br><span class="line">TOMplot(dissTOM, geneTree)</span><br><span class="line">dev.off()</span><br><span class="line">save(softConnect, adjacency, TOM, geneTree, file=<span class="string">'03_conn_adj_TOM.RData'</span>)</span><br><span class="line">rm(c(soft, softConnect))</span><br></pre></td></tr></table></figure><h3 id="2-3-2-把拓扑网络聚类树进行动态修剪，产生初始模块"><a href="#2-3-2-把拓扑网络聚类树进行动态修剪，产生初始模块" class="headerlink" title="2.3.2 把拓扑网络聚类树进行动态修剪，产生初始模块"></a>2.3.2 把拓扑网络聚类树进行动态修剪，产生初始模块</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">minModuleSize=<span class="number">30</span></span><br><span class="line">dissTOM_cut = cutreeDynamic(dendro=geneTree, distM=dissTOM,</span><br><span class="line">                            deepSplit=<span class="number">2</span>, pamRespectsDendro=<span class="literal">F</span>,</span><br><span class="line">                            minClusterSize=minModuleSize)</span><br><span class="line">dynamicColors = labels2colors(dissTOM_cut)</span><br><span class="line"><span class="comment"># [visualization 6] 可视化拓扑重叠相异性的多维尺度图(mds-plot)</span></span><br><span class="line">pdf(file=<span class="string">'visual_06_MDS_plot_on_dissTOM_cut.pdf'</span>)</span><br><span class="line">dimension_num = <span class="number">2</span></span><br><span class="line">cmd = cmdscale(as.dist(dissTOM_cut),dimensional_num)</span><br><span class="line">plot(cmd, col=as.character(dynamicColors), main=<span class="string">'MDS plot'</span>,</span><br><span class="line">xlab=<span class="string">'Scaling Dimension 1'</span>, ylab=<span class="string">'Scaling Dimension 2'</span>)</span><br><span class="line">dev.off()</span><br></pre></td></tr></table></figure><h3 id="2-3-3-计算模块特征，合并特征相似或靠近的模块，产生最终模块"><a href="#2-3-3-计算模块特征，合并特征相似或靠近的模块，产生最终模块" class="headerlink" title="2.3.3 计算模块特征，合并特征相似或靠近的模块，产生最终模块"></a>2.3.3 计算模块特征，合并特征相似或靠近的模块，产生最终模块</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">MEs = moduleEigengenes(expr, dynamicColors)$eigengenes</span><br><span class="line">dissMEs = <span class="number">1</span> - cor(MEs)</span><br><span class="line">dissMEs_tree = hclust(as.dist(dissMEs), method=<span class="string">'average'</span>)</span><br><span class="line">MEDissThreshold = <span class="number">0.25</span></span><br><span class="line">mergedMEs = mergeCloseModules(expr, dynamicColors,</span><br><span class="line">cutHeight=MEDissThreshold, verbose=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># [visualization 6], 可视化拓扑网络聚类树的动态修剪和合并产生的模块比较</span></span><br><span class="line">pdf(file=<span class="string">'visual_06_raw_tree_with_dynamicCut_merge.pdf'</span>)</span><br><span class="line">mergedColors = mergedMEs$colors</span><br><span class="line">plotDendroAndColors(geneTree, cbind(dynamicColors, mergedColors),</span><br><span class="line">c(<span class="string">'Dynamic Tree cut'</span>, <span class="string">'Dynamic Merged'</span>),</span><br><span class="line">dendroLabels=<span class="literal">F</span>, hang=<span class="number">0.03</span>,</span><br><span class="line">                    addGuide=<span class="literal">T</span>, guideHang=<span class="number">0.05</span>,</span><br><span class="line">                    main=<span class="string">'Gene Dendrogram with Dynamic cut &amp; Merge'</span>)</span><br><span class="line">dev.off()</span><br><span class="line"><span class="comment"># [visualization 7], 可视化模块特征聚类图</span></span><br><span class="line">pdf(file=<span class="string">'visual_07_module_eigengenes_cluster.pdf'</span>)</span><br><span class="line">plot(dissMEs_tree, main=<span class="string">'Module Eigengenes Clustering'</span>)</span><br><span class="line">dev.off()</span><br><span class="line">save(MEs, dissMEs_tree, mergedMEs, file=<span class="string">'04_rawMEs_dissMEs_tree_mergedMEs.RData'</span>)</span><br><span class="line">rm(c(MEs, dissMEs_tree))</span><br></pre></td></tr></table></figure><h2 id="2-4-关联分析"><a href="#2-4-关联分析" class="headerlink" title="2.4 关联分析"></a>2.4 关联分析</h2><p>从“2.1-2.3”是我们进行WGCNA的分析过程，下面是一些具体的关联分析。所谓关联分析就是把我们得到的最终的聚类模块同其他数据如表型数据计算相关性，看有哪些模块与这些数据相关，那么模块中的基因就与这些数据相关。下面是一些示例。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入相关数据</span></span><br><span class="line">traits = read.table(<span class="string">'./clean_data/traits.txt'</span>)</span><br><span class="line"><span class="comment"># expr 如果不存在就load('01_sampleTree_cut_outlier.RData')</span></span><br><span class="line"><span class="comment"># mergedMEs如果不存在，就load('04_rawMEs_dissMEs_tree_mergedMEs.RData')</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新计算最终的模块特征, 并据此排序</span></span><br><span class="line">mergedColors = mergedMEs$colors</span><br><span class="line">MEs = moduleEigengenes(expr, mergedColors)$eigengenes</span><br><span class="line">MEs = orderMEs(MEs)</span><br><span class="line">nGenes = ncol(expr)</span><br><span class="line">nSamples = nrow(expr)</span><br><span class="line">modNames = substring(names(MEs), <span class="number">3</span>)</span><br><span class="line">moduleColors = mergedColors</span><br></pre></td></tr></table></figure><h3 id="2-4-1-模块与模块相关性"><a href="#2-4-1-模块与模块相关性" class="headerlink" title="2.4.1 模块与模块相关性"></a>2.4.1 模块与模块相关性</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方法一</span></span><br><span class="line"><span class="comment"># plotMEpairs(MEs)</span></span><br><span class="line"><span class="comment"># 方法二</span></span><br><span class="line">moduleModuleCor = cor(MEs, MEs, use=<span class="string">'p'</span>)</span><br><span class="line">moduleModulePvalue = corPvalueStudent(moduleModuleCor, nSamples)</span><br><span class="line">moduleModuleText = paste0(signif(moduleModuleCor,<span class="number">2</span>), <span class="string">'\n('</span>,</span><br><span class="line">signif(moduleModulePvalue,<span class="number">2</span>), <span class="string">')'</span>)</span><br><span class="line">dim(moduleModuleText) = dim(moduleModuleCor)</span><br><span class="line"><span class="comment"># [visualization 8] 模型与模块之间的相关性</span></span><br><span class="line">pdf(file=<span class="string">'visual_09_module_module_relationship.pdf'</span>)</span><br><span class="line">labeledHeatmap(Matrix=moduleModuleCor, xLabels=names(MEs),</span><br><span class="line">yLabels=names(MEs), ySymbols=names(MEs),</span><br><span class="line">xSymbols=names(MEs), colorLabels=<span class="literal">F</span>,</span><br><span class="line">colors=greenWhiteRed(<span class="number">50</span>), textMatrix=moduleModuleText,</span><br><span class="line">setStdMargins=<span class="literal">F</span>, zlim=c(-<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">main=paste(<span class="string">'Relationships between Module Eigengenes'</span>))</span><br><span class="line">dev.off()</span><br><span class="line">MMdata = cbind(moduleModuleCor, moduleModulePvalue)</span><br><span class="line">colnames(MMdata) = c(paste0(colnames(moduleModuleCor), <span class="string">'.Cor'</span>),</span><br><span class="line">paste0(colnames(moduleModulePvalue), <span class="string">'.Pvalue'</span>))</span><br><span class="line">write.csv(MMdata, file=<span class="string">'WGCNA_02_Modue_Module_relationship.csv'</span>)</span><br></pre></td></tr></table></figure><h3 id="2-4-2-模块与表型之间的相关性"><a href="#2-4-2-模块与表型之间的相关性" class="headerlink" title="2.4.2 模块与表型之间的相关性"></a>2.4.2 模块与表型之间的相关性</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">moduleTraitCor = cor(MEs, traits, use=<span class="string">'p'</span>)</span><br><span class="line">moduleTraitPvalue = corPvalueStudent(moduleTraitCor, nSamples)</span><br><span class="line">moduleTraitText = paste0(signif(moduleTraitCor,<span class="number">2</span>), <span class="string">'\n('</span>,</span><br><span class="line">signif(moduleTraitPvalue,<span class="number">2</span>), <span class="string">')'</span>)</span><br><span class="line">dim(moduleTraitText) = dim(moduleTraitCor)</span><br><span class="line"><span class="comment"># [visualization 9] 模型与表型之间的相关性</span></span><br><span class="line">pdf(file=<span class="string">'visual_08_module_traits_relationship.pdf'</span>)</span><br><span class="line">labeledHeatmap(Matrix=moduleTraitCor, xLabels=names(traits),</span><br><span class="line">yLabels=names(MEs), ySymbols=names(MEs),</span><br><span class="line">colorLabels=<span class="literal">F</span>, colors=greenWhiteRed(<span class="number">50</span>),</span><br><span class="line">textMatrix=moduleTraitText, setStdMargins=<span class="literal">F</span>,</span><br><span class="line">zlim=c(-<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">main=paste(<span class="string">'Relationships between module eigengenes and traits '</span>))</span><br><span class="line">dev.off()</span><br><span class="line">MTdata = cbind(moduleTraitCor, moduleTraitPvalue)</span><br><span class="line">colnames(MTdata) = c(paste0(colnames(moduleTraitCor), <span class="string">'.Cor'</span>),</span><br><span class="line">paste0(colnames(moduleTraitPvalue), <span class="string">'.Pvalue'</span>))</span><br><span class="line">write.csv(MTdata, file=<span class="string">'WGCNA_01_Modue_Traits_relationship.csv'</span>)</span><br></pre></td></tr></table></figure><h3 id="2-4-3-模块与基因表达量相关性"><a href="#2-4-3-模块与基因表达量相关性" class="headerlink" title="2.4.3 模块与基因表达量相关性"></a>2.4.3 模块与基因表达量相关性</h3><p>通过检测模块与表型之间的相关性，我们可以得到高度相关的模块与表型。使用这个模块和表型，获取要分析的基因。假定我们的模块是“blue”和表型是“weight”。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">geneModuleCor = cor(expr, MEs, use=<span class="string">'p'</span>) </span><br><span class="line"><span class="comment"># modNames = substring(names(MEs), 3)</span></span><br><span class="line">geneModulePvalue = corPvalueStudent(geneModuleCor, nSamples)</span><br><span class="line">names(geneModuleCor) = paste(modNames, <span class="string">'.Cor'</span>, sep=<span class="string">''</span>)</span><br><span class="line">names(geneModulePvalue) = paste(modNames, <span class="string">'.Cor.pvalue'</span>, sep=<span class="string">''</span>)</span><br><span class="line">write.csv(cbind(geneModuleCor, geneModulePvalue),</span><br><span class="line">file=<span class="string">'WGCNA_03_gene_module_relationship.csv'</span>)</span><br><span class="line"></span><br><span class="line">geneTraitCor = cor(expr, traits, use=<span class="string">'p'</span>)</span><br><span class="line">geneTraitPvalue = corPvalueStudent(geneTraitCor, nSamples)</span><br><span class="line">names(geneTraitCor) = paste(colnames(traits), <span class="string">'.Cor'</span>, sep=<span class="string">''</span>)</span><br><span class="line">names(geneTraitPvalue) = paste(colnames(traits), <span class="string">'.Cor.pvalue'</span>, sep=<span class="string">''</span>)</span><br><span class="line">write.csv(cbind(geneTraitCor, geneTraitPvalue),</span><br><span class="line">file=<span class="string">'WGCNA_04_gene_trait_relationship.csv'</span>)</span><br><span class="line"></span><br><span class="line">module_aim = <span class="string">'blue'</span></span><br><span class="line">trait_aim = <span class="string">'weight'</span></span><br><span class="line">module_column = match(module_aim, modNames)</span><br><span class="line">trait_column = match(trait_aim, colnames(traits))</span><br><span class="line">geneModuleCorAim = geneModuleCor[moduleColors == module_aim, module_column]</span><br><span class="line">geneTraitCorAim = geneTraitCor[moduleColors == module_aim, trait_column]</span><br><span class="line"><span class="comment"># [visualization 10] 模块与基因表达量的相关性</span></span><br><span class="line">pdf(file=paste(<span class="string">'visual_10_gene_significance_MM_in_'</span>, module_aim, <span class="string">'.pdf'</span>, sep=<span class="string">''</span>))</span><br><span class="line"><span class="comment"># 这里应该也可以用labledHeatmap</span></span><br><span class="line">verboseScatterplot(abs(geneModuleCorAim),</span><br><span class="line">abs(geneTraitCorAim),</span><br><span class="line">xlab=paste(<span class="string">'Module Membership in'</span>, module_aim, <span class="string">' module'</span>),</span><br><span class="line">ylab=paste(<span class="string">'Gene significance for'</span>, trait_aim),</span><br><span class="line">main=paste(<span class="string">'Module membership ('</span>, module_aim, <span class="string">') vs Gene significance ('</span>, trait_aim, <span class="string">')'</span>),</span><br><span class="line">col = module_aim)</span><br><span class="line">dev.off()</span><br></pre></td></tr></table></figure><h3 id="2-4-4-模块与模块内总体基因显著值"><a href="#2-4-4-模块与模块内总体基因显著值" class="headerlink" title="2.4.4 模块与模块内总体基因显著值"></a>2.4.4 模块与模块内总体基因显著值</h3><p>“we define a gene significance variable as minus log10 of the univarite Cox regression pvalue for predicting survival on the basis of the gene epxression info“, 有文献定义了个gene significance, 然后可视化各个模块内该gene significance的分布情况。这说gen significance的分布情况。这说明gene significance是由我们自己定义的。我们这里使用每个基因的平均表达量作为其基因显著特征</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">exprPerGene = colMeans(expr)</span><br><span class="line"><span class="comment"># [visualizaton 11] 模块与总体基因表达量柱状图</span></span><br><span class="line">pdf(file=<span class="string">'visual_11_total_geneSig_in_module.pdf'</span>)</span><br><span class="line">plotModuleSignificance(exprPerGene, moduleColors, main=<span class="string">"Module significance"</span>)</span><br><span class="line">dev.off()</span><br></pre></td></tr></table></figure><h3 id="2-4-5-各个模块内的基因表达模式图"><a href="#2-4-5-各个模块内的基因表达模式图" class="headerlink" title="2.4.5 各个模块内的基因表达模式图"></a>2.4.5 各个模块内的基因表达模式图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">pdf(file=paste(<span class="string">'visual_12_gene_expression_pattern_in_all_modules.pdf'</span>, sep=<span class="string">''</span>), w=<span class="number">12</span>,h=<span class="number">9</span>)</span><br><span class="line"><span class="keyword">for</span>(moduleName <span class="keyword">in</span> modNames) &#123;</span><br><span class="line">    column = match(moduleName, modNames)</span><br><span class="line">    sizeGrWindow(<span class="number">12</span>,<span class="number">9</span>)</span><br><span class="line">    par(mfrow=c(<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">    par(mar=c(<span class="number">1</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">3</span>))</span><br><span class="line">    plotMat(t(expr[, moduleColors == moduleName]),</span><br><span class="line">            nrgcols=<span class="number">30</span>, clabels=rownames(traits));</span><br><span class="line">    par(mar=c(<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">    barplot(MEs[, column], xlab = moduleName, ylab=<span class="string">'Gene Expression pattern'</span>, col=moduleName)</span><br><span class="line">&#125;</span><br><span class="line">dev.off()</span><br></pre></td></tr></table></figure><h3 id="2-4-6-模块内部基因连接性与基因显著的相关性"><a href="#2-4-6-模块内部基因连接性与基因显著的相关性" class="headerlink" title="2.4.6 模块内部基因连接性与基因显著的相关性"></a>2.4.6 模块内部基因连接性与基因显著的相关性</h3><p>这里的基因显著定义还是与2.4.4是一样的。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">exprPerGene = colMeans(expr)</span><br><span class="line">ConnectivityMeasure = intramodularConnectivity(adjacency, moduleColors)</span><br><span class="line">pdf(file=paste(<span class="string">'visual_13_intramodularConnect_gene_significance.pdf'</span>, sep=<span class="string">''</span>))</span><br><span class="line"><span class="keyword">for</span>(moduleName <span class="keyword">in</span> modNames) &#123;</span><br><span class="line">verboseScatterplot(ConnectivityMeasure$kWithin[moduleName == moduleColors],</span><br><span class="line">exprPerGene[moduleName == moduleColors],</span><br><span class="line">col=moduleColors[moduleColors == moduleName],</span><br><span class="line">main=paste(<span class="string">'module '</span>, moduleName, sep=<span class="string">''</span>),</span><br><span class="line">ylab=<span class="string">'Gene significance'</span>,</span><br><span class="line">xlab=<span class="string">'Intramodular K'</span>)</span><br><span class="line">&#125;</span><br><span class="line">dev.off()</span><br></pre></td></tr></table></figure><h2 id="2-5-导出数据"><a href="#2-5-导出数据" class="headerlink" title="2.5 导出数据"></a>2.5 导出数据</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">load(<span class="string">'01_sampleTree_cut_outlier.RData'</span>)</span><br><span class="line">load(<span class="string">'03_conn_adj_TOM.RData'</span>)</span><br><span class="line">load(<span class="string">'04_rawMEs_dissMEs_tree_mergedMEs.RData'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># softConnect, adjacency, TOM, geneTree,MEs, dissMEs_tree, mergedMEs</span></span><br><span class="line">probes = colnames(expr)</span><br><span class="line"><span class="comment"># 想要导出的模块</span></span><br><span class="line">modules = c(<span class="string">'green'</span>, <span class="string">'black'</span>)</span><br><span class="line">inModule = is.finite(match(mergedColors, modules))</span><br><span class="line">modTOM = TOM[inModule, inModule]</span><br><span class="line">modProbes = probes[inModule]</span><br><span class="line">dimnames(modTOM) = list(modProbes, modProbes)</span><br><span class="line">IMConn = softConnectivity(expr[, modProbes]);</span><br><span class="line"></span><br><span class="line">nTop = <span class="number">30</span>;</span><br><span class="line">top = (rank(-IMConn) &lt;= nTop)</span><br><span class="line"></span><br><span class="line">cyt = exportNetworkToCytoscape(modTOM[top, top],</span><br><span class="line">        edgeFile=paste(<span class="string">'CytoscapeInput-edges-'</span>, paste(modules, collapse=<span class="string">'-'</span>), <span class="string">'.txt'</span>, sep=<span class="string">''</span>),</span><br><span class="line">        nodeFile=paste(<span class="string">'CytoscapeInput-nodes-'</span>, paste(modules, collapse=<span class="string">'-'</span>), <span class="string">'.txt'</span>, sep=<span class="string">''</span>),</span><br><span class="line">        weighted=<span class="literal">T</span>,</span><br><span class="line">        threshold = <span class="number">0.02</span>,</span><br><span class="line">        nodeNames = modProbes,</span><br><span class="line">        nodeAttr=mergedColors[inModule])</span><br><span class="line"></span><br><span class="line">vis = exportNetworkToVisANT(modTOM[top, top],</span><br><span class="line">                            file = paste(<span class="string">"VisANTInput-"</span>, module, <span class="string">".txt"</span>, sep=<span class="string">""</span>),</span><br><span class="line">                            weighted = <span class="literal">TRUE</span>,</span><br><span class="line">                            threshold = <span class="number">0</span>,</span><br><span class="line">                            probeToGene = data.frame(annot$substanceBXH, annot$gene_symbol) )</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 富集分析 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>差异分析 Ballgown</title>
      <link href="/2018/10/12/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90-Ballgown/"/>
      <url>/2018/10/12/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90-Ballgown/</url>
      
        <content type="html"><![CDATA[<p>Ballgown是一款灵活的用于RNA-seq数据差异分析的软件，除了差异分析，他还可以进行转录本的组织、可视化和分析表达程度。</p><a id="more"></a><h2 id="preprocessing"><a href="#preprocessing" class="headerlink" title="preprocessing"></a>preprocessing</h2><p>在正式使用之前,你应该做完以下几步：</p><ul><li>RNA-seq的reads应该比对到参考基因组上了</li><li>转录本也组装完成，或者你有一个参考转录本</li><li>用于分析的表达矩阵应该是ballgown的可读格式</li></ul><p>推荐的两个pipeline：</p><ul><li>pipeline1: TopHat2 -&gt; stringtie -&gt; ballgown</li><li>pipeline2: TopHat2 -&gt; Cufflinks -&gt; Tablemaker -&gt; ballgown</li></ul><p>Tablemaker:     <a href="https://github.com/leekgroup/tablemaker" target="_blank" rel="noopener">https://github.com/leekgroup/tablemaker</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pipeline1</span></span><br><span class="line">tophat2 -G ref.gff -o output_path -p 6 ref_index reads.fastq</span><br><span class="line">stringtie -B -G ref.gff -p 6 accepted_hist.bam -o stringtie.gff</span><br><span class="line"></span><br><span class="line"><span class="comment"># pipeline2</span></span><br><span class="line">tophat2 -G ref.gff -o output_path -p 6 ref_index reads.fastq</span><br><span class="line">cufflinks -g ref.gff -o output_path accepted_hits.bam</span><br><span class="line"><span class="comment"># tablemaker调用cufflinks</span></span><br></pre></td></tr></table></figure><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span>(<span class="string">'http://bioconductor.org/biocLite.R'</span>)</span><br><span class="line">biocLite(<span class="string">'ballgown'</span>)</span><br></pre></td></tr></table></figure><h2 id="Ballgown需求的格式"><a href="#Ballgown需求的格式" class="headerlink" title="Ballgown需求的格式"></a>Ballgown需求的格式</h2><p><a href="https://github.com/alyssafrazee/ballgown#ballgown-readable-expression-output" target="_blank" rel="noopener">https://github.com/alyssafrazee/ballgown#ballgown-readable-expression-output</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 文件目录</span></span><br><span class="line">extdata/</span><br><span class="line">sample01/</span><br><span class="line">e2t.ctab</span><br><span class="line">e_data.ctab</span><br><span class="line">i2t.ctab</span><br><span class="line">i_data.ctab</span><br><span class="line">t_data.ctab</span><br><span class="line"></span><br><span class="line"><span class="comment"># e_data.ctab: exon-level expression measurements, one row per exon</span></span><br><span class="line"><span class="comment"># e_id chr strandstartend rcountucountmrcountcovcov_sdmcovmcov_sd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># i_data.ctab: intro-(ie. junction-)level expression measurements, one row per intron</span></span><br><span class="line"><span class="comment"># e_id chrstrandstartendrcountucountmrcount</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># t_data.ctab: transcript-level expression measurements, one row per transcript</span></span><br><span class="line"><span class="comment"># t_idchrstrandstartendt_namenum_exonslengthgene_idgene_namecov FPKM</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># e2t.ctab:which exons belong to which transcripts</span></span><br><span class="line"><span class="comment"># e_id t_id</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># i2t.ctab: which introns belong to which transcripts</span></span><br><span class="line"><span class="comment"># i_datat_data</span></span><br></pre></td></tr></table></figure><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h3 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1. 加载数据"></a>1. 加载数据</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ballgown)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.寻找数据目录</span></span><br><span class="line">data_directory = system.file(<span class="string">'extdata'</span>, package=<span class="string">'ballgown'</span>)<span class="comment"># 找到Ballgown所在的目录下extdata目录</span></span><br><span class="line">data_directory</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.1 番外：自己构造目录文件</span></span><br><span class="line">samples_path = data.frame(c(<span class="string">'sample01_path'</span>, <span class="string">'sample02_path'</span>, <span class="keyword">...</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 构造Ballgown对象</span></span><br><span class="line">bg = ballgown(dataDir=data_directory, samplePattern=<span class="string">'sample'</span>, meas=<span class="string">'all'</span>)</span><br><span class="line"><span class="comment"># meas的参数是那些.ctab文件不重复列的列名</span></span><br><span class="line"><span class="comment"># bg = ballgown(samples=samples_path, samplePattern='sample', meas='all')</span></span><br><span class="line">bg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果数据量太大</span></span><br><span class="line"><span class="comment"># in load.R</span></span><br><span class="line"><span class="keyword">library</span>(ballgown)</span><br><span class="line">data_directory = system.file(<span class="string">'extdata'</span>, package=<span class="string">'ballgown'</span>)</span><br><span class="line">bg = ballgown(dataDir=data_directory, samplePattern=<span class="string">'sample'</span>, meas=<span class="string">'all'</span>)</span><br><span class="line">save(bg, file=<span class="string">'bg.rda'</span>)</span><br><span class="line"><span class="comment"># 然后在每次使用时,运行以下命令,然后通过load()加载bg.rda</span></span><br><span class="line">R CMD BATCH load.R</span><br></pre></td></tr></table></figure><h3 id="2-处理组装数据"><a href="#2-处理组装数据" class="headerlink" title="2. 处理组装数据"></a>2. 处理组装数据</h3><p>一个Ballgown对象有6个分支, structure, expr, indexes, dirs, mergeDate, meas.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># structure十分依赖GenomicRanges包。它指定了组装的转录本的基因位置，外显子内含子转录本的关系。</span></span><br><span class="line">structure(bg)$exon</span><br><span class="line">structure(bg)$intron</span><br><span class="line">structure(bg)$trans</span><br><span class="line"></span><br><span class="line"><span class="comment"># expr包含了表达数据</span></span><br><span class="line"><span class="comment"># *expr(bg, meas_name)</span></span><br><span class="line">transcript_fpkm = texpr(bg, <span class="string">'FPKM'</span>)</span><br><span class="line">transcript_cov = texpr(bg, <span class="string">'cov'</span>)</span><br><span class="line">whole_tx_table = texpr(bg, <span class="string">'all'</span>)</span><br><span class="line">exon_mcov = eexpr(bg, <span class="string">'mcov'</span>)</span><br><span class="line">junction_rcount = iexpr(bg)</span><br><span class="line">whole_intron_table = iexpr(bg, <span class="string">'all'</span>)</span><br><span class="line">gene_expression = gexpr(bg)</span><br><span class="line"></span><br><span class="line"><span class="comment"># indexes</span></span><br><span class="line">indexes(bg)</span><br><span class="line">pData(bg) = data.frame(id=sampleNames(bg), group=rep(c(<span class="number">1</span>,<span class="number">0</span>), each=<span class="number">10</span>))</span><br><span class="line">exon_transcript_table = indexes(bg)$e2t</span><br><span class="line">transcript_gene_table = indexes(bg)$t2g</span><br><span class="line">phenotype_table = pData(bg)</span><br><span class="line">head(transcript_gene_table)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他</span></span><br><span class="line">head(bg@dirs)</span><br><span class="line">bg@mergeDate</span><br><span class="line">bg@meas</span><br></pre></td></tr></table></figure><h3 id="3-数据特征可视化"><a href="#3-数据特征可视化" class="headerlink" title="3.数据特征可视化"></a>3.数据特征可视化</h3><ul><li>可视化组装的转录本结构</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plotTranscripts(gene=<span class="string">'XLOC_000454'</span>,</span><br><span class="line">gown=bg, samples=<span class="string">'sample12'</span>,</span><br><span class="line">meas=<span class="string">'FPKM'</span>,</span><br><span class="line">colorby=<span class="string">'transcript'</span>,</span><br><span class="line">main=<span class="string">'transcripts from gene XLOC_000454: sample12, FPKM'</span>)</span><br><span class="line"><span class="comment"># 多个样本同时画图</span></span><br><span class="line">plotTranscripts(<span class="string">'XLOC_00054'</span>, bg,</span><br><span class="line">samples=c(<span class="string">'sample01'</span>, <span class="string">'sample02'</span>),</span><br><span class="line">meas=<span class="string">'FPKM'</span>,</span><br><span class="line">colorby=<span class="string">'transcript'</span>)</span><br></pre></td></tr></table></figure><ul><li>进行分组比较表达量</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plotMeans(<span class="string">'XLOC_00054'</span>, bg,</span><br><span class="line">   groupvar=<span class="string">'group'</span>,</span><br><span class="line">   meas=<span class="string">'FPKM'</span>,</span><br><span class="line">   colorby=<span class="string">'transcript'</span>)</span><br></pre></td></tr></table></figure><h3 id="4-差异分析"><a href="#4-差异分析" class="headerlink" title="4. 差异分析"></a>4. 差异分析</h3><p>ballgown默认使用parametric F-test comparing nested linear model进行统计.它同时使用两个模型,一个模型是包含感兴趣协变量,如case/control status, 如time;另一个不包含协变量.显著性的p-value表明包含协变量的模型得到的结果要比不包含的模型结果更为显著，也就说明具有差异。而q-value&lt;0.05表明FDR被控制在5%。stattest函数可自动处理两组比较和多组比较和时间系列比较。</p><ul><li>组组比较，group分组</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stat_results = stattest(bg, feature=<span class="string">'transcript'</span>, meas=<span class="string">'FPKM'</span>, covariate=<span class="string">'group'</span>)</span><br><span class="line">head(stat_resuts)</span><br></pre></td></tr></table></figure><ul><li>时间系列比较</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果你的时间点较少，比如低于5，建议将其作为分组变量进行组组比较</span></span><br><span class="line">pData(bg) = data.frame(pData(bg), time=rep(<span class="number">1</span>:<span class="number">10</span>,<span class="number">2</span>))<span class="comment"># dummy time corvariate</span></span><br><span class="line">timecourse_results = stattest(bg, feature=<span class="string">'transcript'</span>, meas=<span class="string">'FPKM'</span>, covariate=<span class="string">'time'</span>, timecourse=<span class="literal">T</span>)</span><br></pre></td></tr></table></figure><ul><li>调整混杂因素</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 你可以通过pData调整任何混杂因素,也可以像下面一样添加</span></span><br><span class="line">group_adj_timecourse_results = stattest(bg, feature=<span class="string">'transcript'</span>,</span><br><span class="line">meas=<span class="string">'FPKM'</span>, covariate=<span class="string">'time'</span>, </span><br><span class="line">timecourse=<span class="literal">T</span>, adjustvars=<span class="string">'group'</span>)</span><br></pre></td></tr></table></figure><ul><li>自定义比较模型 </li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sex,age,group,time vs. group,time</span></span><br><span class="line"><span class="comment"># 模拟数据</span></span><br><span class="line">set.seed(<span class="number">43</span>)</span><br><span class="line">sex = sample(c(<span class="string">'M'</span>, <span class="string">'F'</span>), size=nrow(pData(bg)), replace=<span class="literal">T</span>)</span><br><span class="line">age = sample(<span class="number">21</span>:<span class="number">52</span>, size=nrow(pData(bg)), replace=<span class="literal">T</span>)</span><br><span class="line"><span class="comment"># 创建design matrices</span></span><br><span class="line">mod = model.matrix(~ sex + age + pData(bg)$group + pData(bg)$time)</span><br><span class="line">mod0 = model.matrix(~ pData(bg)$group + pData(bg)$time)</span><br><span class="line"><span class="comment"># 进行差异分析</span></span><br><span class="line">adjusted_results = stattest(bg, feature=<span class="string">'transcript'</span>, meas=<span class="string">'FPKM'</span>, mod0=mod0, mod=mod)</span><br><span class="line">head(adjusted_results)</span><br></pre></td></tr></table></figure><ul><li>输出到其他差异统计软件如limma,limma voom, DESeq, DEXSeq, EdgeR, etc.</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 见2.处理组装数据</span></span><br><span class="line">*expr(bg, meas_name)</span><br></pre></td></tr></table></figure><ul><li>简单地转录聚类<br>如此做是为了避免一个基因有多个相似的转录用作组装，会导致表达差异检测不准确。可以进行一下聚类看看。聚类使用的聚类是Jaccard distance;你也可以使用k-means clustering或者hierarchical clustering。</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clusterTranscripts(gene=<span class="string">'XLOC_000454'</span>, gown=bg, k=<span class="number">2</span>, method=<span class="string">'kmeans'</span>)</span><br><span class="line"><span class="comment"># 也可以可视化</span></span><br><span class="line">plotLatentTranscripts(gene=<span class="string">'XLOC_00054'</span>, gown=bg, k=<span class="number">2</span>, method=<span class="string">'kmeans'</span>, returncluster=<span class="literal">F</span>)</span><br></pre></td></tr></table></figure><ul><li>针对基因进行聚合表达量</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">agg = collapseTranscripts(gene=<span class="string">'XLOC_00054'</span>, gown=bg, k=<span class="number">2</span>, method=<span class="string">'kmeans'</span>)</span><br><span class="line">stattest(gowntable=agg$tab, pData=pData(bg), feature=<span class="string">'transcript_cluster'</span>,</span><br><span class="line">covariate=<span class="string">'group'</span>, libadjust=<span class="literal">F</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 差异分析 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>差异分析 DESeq2</title>
      <link href="/2018/10/12/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90-DESeq2/"/>
      <url>/2018/10/12/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90-DESeq2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>与DESeq类似的包有：edgeR、limma、DSS、EBSeq、baySeq</p></blockquote><h2 id="一、核心逻辑代码"><a href="#一、核心逻辑代码" class="headerlink" title="一、核心逻辑代码"></a>一、核心逻辑代码</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># countData: 以样品为列名,基因为行名的表达矩阵</span></span><br><span class="line"><span class="comment"># colData的形式: 以样品作为行名,列是样品对应的分组类型</span></span><br><span class="line"><span class="comment"># 生成count matrix</span></span><br><span class="line">dds &lt;- DESeqDataSetFromMatrix(countData = cts,</span><br><span class="line">                              colData = coldata,</span><br><span class="line">                              design = ~ batch + condition)</span><br><span class="line"><span class="comment"># 生成DESeq数据集</span></span><br><span class="line">dds &lt;- DESeq(dds)</span><br><span class="line"><span class="comment"># 进行比较，获得结果</span></span><br><span class="line">res &lt;- results(dds, contrast=c(<span class="string">'condition'</span>, <span class="string">'treat'</span>, <span class="string">'ctrl'</span>))</span><br><span class="line">resultsNames(dds)</span><br><span class="line">res &lt;- lfcShrink(dds, coef=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#  DESeqDataSetFromTximport:   由Salmon, Saifish, kallisto生成</span></span><br><span class="line"><span class="comment">#  DESeqDataSetFromHTSeq:      由htseq-counts生成</span></span><br><span class="line"><span class="comment">#  DESeqDataSet:               由RangedSummarizedExpriment生成</span></span><br></pre></td></tr></table></figure><a id="more"></a><p>DESeq2为count数据提供两类变换方法，使不同均值的方差趋于稳定，rlog和vst，这两个函数可以用于处理含有色散平均趋势的负二项数据（类如RNA-seq）。由于rlog计算量很大，与vst的效果相近，那么，在数据集小于30的时候，使用rlog；大数据集使用vst可以加快速度。但做这样的变换不是用于差异分析，而是用于pca，WGCNA，clustering等与聚类相关的分析才用得到。</p><h2 id="二、标准流程-standard-workflow"><a href="#二、标准流程-standard-workflow" class="headerlink" title="二、标准流程 standard workflow"></a>二、标准流程 standard workflow</h2><h3 id="2-1-input-data"><a href="#2-1-input-data" class="headerlink" title="2.1 input data"></a>2.1 input data</h3><ul><li>DESeq的input data是不需要预先进行标准化的，因为软件包内部会自己根据文库大小等进行标准化。  </li><li>input data有四类，分别对应四个读取函数，见核心逻辑代码部分。</li><li>DESeqDataSet是包中存取read counts和统计中间值的对象，通常简写为dds。其参数必需要有一个design formula，以被后续估计dispersion和log2 fold changes使用。</li></ul><h3 id="2-2-DESeqDataSetFromTximport：-txi文件"><a href="#2-2-DESeqDataSetFromTximport：-txi文件" class="headerlink" title="2.2 DESeqDataSetFromTximport：.txi文件"></a>2.2 DESeqDataSetFromTximport：.txi文件</h3><blockquote><p>这类数据是由Salmon、Saifish、kallisto、RSEM等软件产生，数据应该是estimated gene counts。<br>    使用这些软件的好处在于：  </p><pre><code>1. 它们会修正样品间gene length的可能改变。  2. 它们使用的速度更快、占用CPU内存更少（相比于基于比对的软件来讲）。  3. 它们可以避免丢弃多匹配片段（基因同源序列），提高灵敏度。</code></pre></blockquote><h3 id="2-3-使用DESeqDataSetFromMatrix-count-matrix文件"><a href="#2-3-使用DESeqDataSetFromMatrix-count-matrix文件" class="headerlink" title="2.3 使用DESeqDataSetFromMatrix: count matrix文件"></a>2.3 使用DESeqDataSetFromMatrix: count matrix文件</h3><blockquote><p>这类数据来源于Rsubread包的featureCounts函数。使用DESeqDataSetFromMatrix，需要提供counts matrix、数据框格式的样品信息、design formula。</p></blockquote><h3 id="2-4-input-htseq-count"><a href="#2-4-input-htseq-count" class="headerlink" title="2.4 input: htseq-count"></a>2.4 input: htseq-count</h3><blockquote><p>具体的使用可见前面，以pasilla来源数据为例</p></blockquote><h3 id="2-5-input-SummarizedExperiment"><a href="#2-5-input-SummarizedExperiment" class="headerlink" title="2.5 input: SummarizedExperiment"></a>2.5 input: SummarizedExperiment</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用airway包来源的数据进行示例</span></span><br><span class="line"><span class="keyword">library</span>(<span class="string">'airway'</span>)</span><br><span class="line">data(<span class="string">'airway'</span>)</span><br><span class="line">se &lt;- airway</span><br><span class="line"></span><br><span class="line"><span class="keyword">library</span>(<span class="string">'DESeq2'</span>)</span><br><span class="line">ddsSE &lt;- DESeqDataSet(se, design = ~cell + dex)</span><br></pre></td></tr></table></figure><h3 id="2-6-预过滤"><a href="#2-6-预过滤" class="headerlink" title="2.6 预过滤"></a>2.6 预过滤</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了减少内存占用，先把count数很低的数据剔除</span></span><br><span class="line">keep &lt;- rowSums(counts(dds)) &gt;= <span class="number">10</span></span><br><span class="line">dds &lt;- dds[keep,]</span><br></pre></td></tr></table></figure><h3 id="2-7-指定factor-levels"><a href="#2-7-指定factor-levels" class="headerlink" title="2.7 指定factor levels"></a>2.7 指定factor levels</h3><blockquote><p>R 将基于字母顺序默认参考水平，但实际通常是根据对照组作为参考水平。因此有必要时要设置</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dds$condition &lt;- factor(dds$condition, levels=c(<span class="string">'untreated'</span>, <span class="string">'treated'</span>))</span><br><span class="line"><span class="comment"># 也可以直接指定</span></span><br><span class="line">dds$condition &lt;- relevel(dds$condition, ref=<span class="string">'untreated'</span>)</span><br><span class="line"><span class="comment"># 如果有时对dds取子集时，导致某些水平不含数据，那么这个水平就可以丢弃</span></span><br><span class="line">dds$condition &lt;- droplevels(dds$condition)</span><br></pre></td></tr></table></figure><h3 id="2-8-合并技术性重复：collapseReplicates函数"><a href="#2-8-合并技术性重复：collapseReplicates函数" class="headerlink" title="2.8 合并技术性重复：collapseReplicates函数"></a>2.8 合并技术性重复：collapseReplicates函数</h3><h2 id="三、差异表达分析"><a href="#三、差异表达分析" class="headerlink" title="三、差异表达分析"></a>三、差异表达分析</h2><blockquote><p>函数DESeq用来进行差异表达分析，所有计算都整合在该函数里面；生成一个结果对象。你需要使用results函数对该结果对象取值，才能获取到包含了log2FoldChange、p-value、p-adj-value等的结果。</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dds &lt;- DESeq(dds)</span><br><span class="line">res &lt;- results(dds)</span><br></pre></td></tr></table></figure><blockquote><p>如果你想修改coeffficient的数量的话，可以这样设置：</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">res &lt;- results(dds, contrast=<span class="string">'2'</span>)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">resFC &lt;- lfcShrink(dds, coef=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><blockquote><p>如果有太多样本参与比较，可以并行计算</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(<span class="string">'BiocParallel'</span>)</span><br><span class="line">register(MulticoreParam(<span class="number">4</span>))</span><br><span class="line">dds &lt;- DESeq(dds)</span><br><span class="line">res &lt;- results(dds)</span><br><span class="line">resFc &lt;- lfcShrink(dds, coef=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><blockquote><p>按照p-value排序结果、取摘要值、统计个数、调整p-value值</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">resOrdered &lt;- res[order(res$pvalue),]</span><br><span class="line">summary(res)</span><br><span class="line">sum(res$padj &lt; <span class="number">0.1</span>, na.rm=<span class="literal">TRUE</span>)</span><br><span class="line">res0.05 &lt;- results(dds, alpha=<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure><h2 id="四、探索和导出结果"><a href="#四、探索和导出结果" class="headerlink" title="四、探索和导出结果"></a>四、探索和导出结果</h2><h3 id="MA-plot"><a href="#MA-plot" class="headerlink" title="MA-plot"></a>MA-plot</h3><p>收缩估计(shrinkage estimates)通过在回归时缩小对结果影响较小的系数值来达到改善结果的目的.有多种收缩方法可供选择,如apeglm, ashr, normal.前二者需要安装同名bioconductor包,后者是DESeq2自带的.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plotMA(res, ylim=c(-<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line"><span class="comment"># 使用lfcShrink来改变shrinkage estimators</span></span><br><span class="line">resApe &lt;- lfcShrink(dds, coef=<span class="number">2</span>, type=<span class="string">'apeglm'</span>)</span><br><span class="line">resAsh &lt;- lfcShrink(dds, coef=<span class="number">2</span>, type=<span class="string">'ashr'</span>)</span><br><span class="line">par(mfrow=c(<span class="number">1</span>,<span class="number">3</span>), mar=c(<span class="number">4</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">xlim &lt;- c(<span class="number">1</span>,<span class="number">1e5</span>); ylim &lt;- c(-<span class="number">3</span>,<span class="number">3</span>)   <span class="comment">#改变yx轴的值范围</span></span><br><span class="line">plotMA(resLFC, xlim=xlim, ylim=ylim, main=<span class="string">"normal"</span>)</span><br><span class="line">plotMA(resApe, xlim=xlim, ylim=ylim, main=<span class="string">"apeglm"</span>)</span><br><span class="line">plotMA(resAsh, xlim=xlim, ylim=ylim, main=<span class="string">"ashr"</span>)</span><br></pre></td></tr></table></figure><h3 id="plot-counts"><a href="#plot-counts" class="headerlink" title="plot counts"></a>plot counts</h3><blockquote><p>计算一个基因的reads counts在各个处理组的情况</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plotCounts(dds, gene=which.min(res$padj), intgroup=<span class="string">'condition'</span>)</span><br><span class="line"><span class="comment"># 输出数据框以供ggplot使用</span></span><br><span class="line">d &lt;- plotCounts(dds, gene=which.min(res$padj),intgroup=<span class="string">'condition'</span>, returnData=<span class="literal">TRUE</span>)</span><br><span class="line"><span class="keyword">library</span>(<span class="string">'ggplot2'</span>)</span><br><span class="line">ggplot(d, aes(x=condition,y=count)) +</span><br><span class="line">    geom_point(position=position_jitter(w=<span class="number">0.1</span>,h=<span class="number">0</span>)) +</span><br><span class="line">    scale_y_log10(breaks=c(<span class="number">25</span>,<span class="number">100</span>,<span class="number">400</span>))</span><br></pre></td></tr></table></figure><h3 id="更多有关结果的信息"><a href="#更多有关结果的信息" class="headerlink" title="更多有关结果的信息"></a>更多有关结果的信息</h3><blockquote><p>p-value是NA？原因有三：某行(row)所有样品都是0 counts；某行的样品值极端大或者小；自动独立过滤引起的低矫正后counts，p-adj会被设为NA。</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mcols(res)$description</span><br></pre></td></tr></table></figure><h3 id="富可视化、生成报告"><a href="#富可视化、生成报告" class="headerlink" title="富可视化、生成报告"></a>富可视化、生成报告</h3><blockquote><p>可以使用Reporting Tools、regionReport、Glimma、pcaExplore输出结果</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">write.csv(as.data.frame(resOrdered), file=<span class="string">'results.csv'</span>)</span><br><span class="line">resSig &lt;- subset(resOrdered, padj &lt; <span class="number">0.1</span>)</span><br><span class="line">write.csv(as.data.frame(resSig), file=<span class="string">'sig_results.csv'</span>)</span><br></pre></td></tr></table></figure><h3 id="多因子设计"><a href="#多因子设计" class="headerlink" title="多因子设计"></a>多因子设计</h3><blockquote><p>重点在于colData的生成和类似formula(~type+condition)的生成</p></blockquote><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## DataFrame with 7 rows and 3 columns</span></span><br><span class="line"><span class="comment">##            condition        type sizeFactor</span></span><br><span class="line"><span class="comment">##             &lt;factor&gt;    &lt;factor&gt;  &lt;numeric&gt;</span></span><br><span class="line"><span class="comment">## treated1     treated single-read  1.6355014</span></span><br><span class="line"><span class="comment">## treated2     treated  paired-end  0.7612159</span></span><br><span class="line"><span class="comment">## treated3     treated  paired-end  0.8326603</span></span><br><span class="line"><span class="comment">## untreated1 untreated single-read  1.1383376</span></span><br><span class="line"><span class="comment">## untreated2 untreated single-read  1.7935406</span></span><br><span class="line"><span class="comment">## untreated3 untreated  paired-end  0.6494828</span></span><br><span class="line"><span class="comment">## untreated4 untreated  paired-end  0.7516005</span></span><br><span class="line">colData(dds) <span class="comment"># 存起备用 </span></span><br><span class="line">ddsMF &lt;- dds </span><br><span class="line">levels(ddsMF$type)  <span class="comment"># 生成新的level </span></span><br><span class="line"><span class="comment"># re-run DESeq</span></span><br><span class="line">design(ddsMF) &lt;- formula(~ type + condition) </span><br><span class="line">ddsMF &lt;- DESeq(ddsMF)</span><br><span class="line">resMF &lt;- results(ddsMF)</span><br><span class="line"><span class="comment"># 还可以这样干</span></span><br><span class="line">resMFType &lt;- results(ddsMF, contrast=c(<span class="string">'type'</span>, <span class="string">'single'</span>, <span class="string">'paired'</span>))</span><br></pre></td></tr></table></figure><h2 id="五、通过聚类可视化表征数据质量"><a href="#五、通过聚类可视化表征数据质量" class="headerlink" title="五、通过聚类可视化表征数据质量"></a>五、通过聚类可视化表征数据质量</h2><h3 id="表达矩阵的热图"><a href="#表达矩阵的热图" class="headerlink" title="表达矩阵的热图"></a>表达矩阵的热图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ntd,vsd,rld分别是norm,vst,rlog变换后的数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">library</span>(<span class="string">'pheatmap'</span>)</span><br><span class="line">select &lt;- order(rowMeans(counts(dds,normalized=<span class="literal">TRUE</span>)), decreasing=<span class="literal">TRUE</span>)[<span class="number">1</span>:<span class="number">20</span>]</span><br><span class="line">df &lt;- as.data.frame(colData(dds)[,c(<span class="string">'condition'</span>, <span class="string">'type'</span>)])</span><br><span class="line">pheatmap(assay(ntd)[select,], cluster_rows=<span class="literal">FALSE</span>, show_rownames=<span class="literal">FALSE</span>, cluster_cols=<span class="literal">FALSE</span>, annotation_col=df)</span><br><span class="line">pheatmap(assay(vsd)[select,], cluster_rows=<span class="literal">FALSE</span>, show_rownames=<span class="literal">FALSE</span>, cluster_cols=<span class="literal">FALSE</span>, annotation_col=df)</span><br><span class="line">pheatmap(assay(rld)[select,], cluster_rows=<span class="literal">FALSE</span>, show_rownames=<span class="literal">FALSE</span>, cluster_cols=<span class="literal">FALSE</span>, annotation_col=df)</span><br></pre></td></tr></table></figure><h3 id="样品距离热图"><a href="#样品距离热图" class="headerlink" title="样品距离热图"></a>样品距离热图</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这类图直观地显示了样品间的相似度和差异性</span></span><br><span class="line">sampleDists &lt;- dist(t(assay(vsd)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">library</span>(<span class="string">'RColorBrewer'</span>)</span><br><span class="line">sampleDistMatrix &lt;- as.matrix(sampleDists)</span><br><span class="line">rownames(sampleDistMatrix) &lt;- paste(vsd$condition, vsd$type, sep=<span class="string">'-'</span>)</span><br><span class="line">colnames(sampleDistMatrix) &lt;- <span class="literal">NULL</span></span><br><span class="line">colors &lt;- colorRampPalette( rev(brewer.pal(<span class="number">9</span>, <span class="string">'Blues'</span>)) )(<span class="number">255</span>)</span><br><span class="line">pheatmap(sampleDistMatrix,</span><br><span class="line">        clustering_distance_rows=sampleDists,</span><br><span class="line">        clustering_distance_cols=sampleDists,</span><br><span class="line">        col=colors)</span><br></pre></td></tr></table></figure><h3 id="样品的主成分分析"><a href="#样品的主成分分析" class="headerlink" title="样品的主成分分析"></a>样品的主成分分析</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vsd = vst(dds)</span><br><span class="line">plotPCA(vsd, intgroup=c(<span class="string">'condition'</span>, <span class="string">'type'</span>))   <span class="comment"># 这里condition,type都是分组信息</span></span><br><span class="line"><span class="comment"># returnData可以返回主成分分析数据,进而使用其他方法画图</span></span><br><span class="line">pcaData &lt;- plotPCA(vsd, intgroup=c(<span class="string">"condition"</span>, <span class="string">"type"</span>), returnData=<span class="literal">TRUE</span>)</span><br><span class="line">percentVar &lt;- round(<span class="number">100</span> * attr(pcaData, <span class="string">"percentVar"</span>))</span><br><span class="line">ggplot(pcaData, aes(PC1, PC2, color=condition, shape=type)) +</span><br><span class="line">  geom_point(size=<span class="number">3</span>) +</span><br><span class="line">  xlab(paste0(<span class="string">"PC1: "</span>,percentVar[<span class="number">1</span>],<span class="string">"% variance"</span>)) +</span><br><span class="line">  ylab(paste0(<span class="string">"PC2: "</span>,percentVar[<span class="number">2</span>],<span class="string">"% variance"</span>)) + </span><br><span class="line">  coord_fixed()</span><br></pre></td></tr></table></figure><h2 id="FAQs"><a href="#FAQs" class="headerlink" title="FAQs"></a>FAQs</h2><h3 id="分析成对的样品"><a href="#分析成对的样品" class="headerlink" title="分析成对的样品"></a>分析成对的样品</h3><blockquote><p>使用多因子设计即可。</p></blockquote><h3 id="含有多个组，共同分析还是分开分析？"><a href="#含有多个组，共同分析还是分开分析？" class="headerlink" title="含有多个组，共同分析还是分开分析？"></a>含有多个组，共同分析还是分开分析？</h3><blockquote><p>共同分析，两两比较时，使用result函数的contrast指定要比较的两个</p></blockquote><h3 id="可以分析无重复（without-replicate）的数据吗？"><a href="#可以分析无重复（without-replicate）的数据吗？" class="headerlink" title="可以分析无重复（without replicate）的数据吗？"></a>可以分析无重复（without replicate）的数据吗？</h3><blockquote><p>可以，但是只推荐用于探索性的分析，不适用于比较分析。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>差异分析 RSEM</title>
      <link href="/2018/10/12/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90-RSEM/"/>
      <url>/2018/10/12/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90-RSEM/</url>
      
        <content type="html"><![CDATA[<p>RSEM利用的是transcripts而非genome。我们有两种方式来构建RSEM转录参考，其一是利用参考基因组来构建；另外一种方式是从许多转录本中构建。</p><a id="more"></a><h2 id="1-下载对应的基因组和注释文件"><a href="#1-下载对应的基因组和注释文件" class="headerlink" title="1. 下载对应的基因组和注释文件"></a>1. 下载对应的基因组和注释文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ftp://ftp.ensembl.org/pub/release-82/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna.toplevel.fa.gz</span><br><span class="line">ftp://ftp.ensembl.org/pub/release-82/gtf/mus_musculus/Mus_musculus.GRCm38.82.chr.gtf.gz</span><br></pre></td></tr></table></figure><h2 id="2-构建索引"><a href="#2-构建索引" class="headerlink" title="2. 构建索引"></a>2. 构建索引</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用bowtie2索引</span></span><br><span class="line">gunzip Mus_musculus.GRCm38.dna.toplevel.fa.gz</span><br><span class="line">gunzip ref/Mus_musculus.GRCm38.82.chr.gtf.gz</span><br><span class="line"><span class="comment"># 从基因组构建</span></span><br><span class="line">rsem-prepare-reference --gtf Mus_musculus.GRCm38.82.chr.gtf \</span><br><span class="line">   --bowtie2 --bowtie2-path bowtie2 \</span><br><span class="line">   Mus_musculus.GRCm38.dna.toplevel.fa mouse_ref</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从转录本构建</span></span><br><span class="line">rsem-prepare-reference --transcript-to-gene-map mouse_ref_mapping.txt \</span><br><span class="line">   --bowtie2 --bowtie2-path bowtie2 \</span><br><span class="line">   ref/mouse_ref.fa ref/mouse_ref</span><br></pre></td></tr></table></figure><h2 id="3-表达定量"><a href="#3-表达定量" class="headerlink" title="3. 表达定量"></a>3. 表达定量</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">rsem-calculate-expression -p 8 --paired-end \</span><br><span class="line">--bowtie2 --bowtie2-path bowtie2 \</span><br><span class="line">--estimate-rspd \</span><br><span class="line">--append-names \</span><br><span class="line">--output-genome-bam \</span><br><span class="line">read1.fastq read2.fastq \</span><br><span class="line">ref/mouse_ref path/to/output/prefix</span><br><span class="line"><span class="comment"># output =&gt; prefix.genes.results, prefix.genome.bam, prefix.genome.sorted.bam,</span></span><br><span class="line"><span class="comment">#prefix.genome.sorted.bam.bai, prefix.isoforms.results, prefix.stat,</span></span><br><span class="line"><span class="comment">#prefix.transcript.bam, prefix.transcript.sorted.bam, prefix.transcript.sorted.bam.bai</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --output-genome-bam只在由基因组构建索引时有效</span></span><br><span class="line"><span class="comment"># --bam 当输入不是fastq文件而是bam文件时,指定该参数</span></span><br><span class="line"><span class="comment"># --calc-ci 指定了会计算CQV值, coefficient of quartile variation，这将回答该基因的测序深度是否足够用于差异检测</span></span><br><span class="line"><span class="comment"># --no-bam-output 不输出bam文件</span></span><br><span class="line"><span class="comment"># --single-cell-prior 使用针对单细胞的预设条件运行</span></span><br></pre></td></tr></table></figure><h2 id="4-结果输出"><a href="#4-结果输出" class="headerlink" title="4. 结果输出"></a>4. 结果输出</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># in R</span></span><br><span class="line">data = read.table(<span class="string">'prefix.gene.results'</span>, header=<span class="literal">T</span>, stringsAsFactors=<span class="literal">F</span>)</span><br><span class="line">idx = order(data[,<span class="string">'TPM'</span>], decreasing=<span class="literal">T</span>)</span><br><span class="line">data[idx[<span class="number">1</span>:<span class="number">10</span>], c(<span class="string">'gene_id'</span>, <span class="string">'expected_count'</span>, <span class="string">'TPM'</span>)]</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># in bash</span></span><br><span class="line">rsem-plot-model /path/to/output/prefix prefix.diagnostic.pdf</span><br><span class="line">rsem-plot-transcript-wiggles --gene-list --show-unique \</span><br><span class="line">prefix gene_ids.txt aim_gene_transcript_wiggle.pdf</span><br><span class="line"><span class="comment"># gene_ids.txt: 含有gene identifier of aim_gene</span></span><br><span class="line"></span><br><span class="line">rsem-bam2wig prefix.genome.sorted.bam prefix.wig prefix</span><br></pre></td></tr></table></figure><h2 id="5-生成表达矩阵"><a href="#5-生成表达矩阵" class="headerlink" title="5. 生成表达矩阵"></a>5. 生成表达矩阵</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rsem-generate-data-matrix sample1.genes.results sample2.genes.results \</span><br><span class="line">  sample3.genes.results ... \</span><br><span class="line">  sampleN.genes.results &gt; gene_matrix.txt</span><br><span class="line">rsem-run-ebseq gene_matrix.txt NumberOfgroup1,numberofgroup2 gene_matrix.ebseq.results</span><br><span class="line">rsem-control-fdr gene_matrix.ebseq.result 0.05 gene_matrix.de.txt</span><br></pre></td></tr></table></figure><h2 id="6-检测转录表达差异-differentially-expressed-isoforms"><a href="#6-检测转录表达差异-differentially-expressed-isoforms" class="headerlink" title="6. 检测转录表达差异(differentially expressed isoforms)"></a>6. 检测转录表达差异(differentially expressed isoforms)</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">rsem-generate-ngvector mouse_ref.transcripts.fa mouse_ref</span><br><span class="line"><span class="comment"># mouse_ref.transcripts.fa是mouse的转录组参考序列</span></span><br><span class="line"><span class="comment"># output=&gt; mouse_ref.ngvec</span></span><br><span class="line">rsem-generate-data-matrix sample1.isoforms.results \</span><br><span class="line">  sample2.isoforms.results sample3.isoforms.results \</span><br><span class="line">  ...</span><br><span class="line">  sampleN.isoforms.results &gt; isoform_matrix.txt</span><br><span class="line">rsem-run-ebseq --ngvector mouse_ref.ngvec isoform_matrix.txt control_sample_num,treate_sample_num \</span><br><span class="line">  isoform_ebseq.results</span><br><span class="line">rsem-control-fdr isoform_ebseq.results 0.05 isoform.de.txt</span><br></pre></td></tr></table></figure><h2 id="7-检测测序深度是否足够"><a href="#7-检测测序深度是否足够" class="headerlink" title="7. 检测测序深度是否足够"></a>7. 检测测序深度是否足够</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 在rsem-calculate-expression中指定--calc-ci</span></span><br><span class="line"><span class="comment"># 2. 如果基因的cov值高于0.05表明测序深度不够,需要多少？</span></span><br><span class="line">rsem-simulate-reads ../ref/mouse_ref prefix.stat/prefix.model \</span><br><span class="line">prefix.isoforms.results 0.36 20000000 prefix_sim_2M \</span><br><span class="line">--seed 0</span><br><span class="line"><span class="comment"># ../ref/mouse_ref指定参考文件的位置</span></span><br><span class="line"><span class="comment"># 0.36是预设的背景噪音比率</span></span><br><span class="line"><span class="comment"># output =&gt; prefix_sim_2M_1.fastq, prefix_sim_2M_2.fastq</span></span><br><span class="line"></span><br><span class="line">rsem-calculate-expression -p 8 --paired-end \</span><br><span class="line">  --bowtie2 --bowtie2-path bowtie2 \</span><br><span class="line">  --estimate-rspd \</span><br><span class="line">  --append-names \</span><br><span class="line">  --no-bam-output \</span><br><span class="line">  --calc-ci \</span><br><span class="line">  prefix_sim_2M_1.fastq prefix_sim_2M_2.fastq \</span><br><span class="line">  ../ref/mouse_ref prefix_sim_2M</span><br><span class="line"><span class="comment"># 查看output的六个文件中prefix_sim_2m.genes.results,如果基因的cov低于0.05,表明20000000的测序深度足够.</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 差异分析 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>比对 Bowtie2</title>
      <link href="/2018/10/12/%E6%AF%94%E5%AF%B9-Bowtie2/"/>
      <url>/2018/10/12/%E6%AF%94%E5%AF%B9-Bowtie2/</url>
      
        <content type="html"><![CDATA[<p>bowtie2是个超快的、内存占用少的序列比对工具，善于比对相对较长的基因组。bowtie2有gapped、pair-end和local比对模式，可以多线程进行。它是许多pipeline的首个步骤，例如变异检测，CHIP-seq，RNA-seq，BS-seq等等。<br>bowtie2不像常规目的的比对工具如MUMmer，Blast等。它在大的参考基因组的比对上表现更好，因为它针对当前各个测序平台的测序reads进行过优化。如果你的目的是比对很大的两个序列，比如基因组之间的比对，你应考虑使用MUMmer。如果你的目的是比对相对较短的序列如大肠杆菌的基因组，用bowtie2可以大大减少你的时间。</p><a id="more"></a><h2 id="bowtie1和bowtie2的区别"><a href="#bowtie1和bowtie2的区别" class="headerlink" title="bowtie1和bowtie2的区别"></a>bowtie1和bowtie2的区别</h2><ul><li>对于长于50bp的序列,bowtie2速度更快也更灵敏，内存占用更少；但是Bowtie1在短于50bp的比对上有时会更快或更灵敏</li><li>bowtie2通过gap penalty支持gapped alignment</li><li>bowtie2支持局部比对(soft clipped, not end-to-end)</li><li>bowtie1的read length上限是1000bp，而bowtie2则没有上限</li><li>bowtie2支持参考基因组的跨Ns比对</li><li>对于pair-end reads,如果比对不上,bowtie2尝试将单个reads进行比对</li><li>bowtie2不支持colorspace reads的比对</li></ul><h2 id="Getting-started"><a href="#Getting-started" class="headerlink" title="Getting started"></a>Getting started</h2><h3 id="1-对参考基因组建立索引"><a href="#1-对参考基因组建立索引" class="headerlink" title="1. 对参考基因组建立索引"></a>1. 对参考基因组建立索引</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># prefix是输出的索引文件前缀, .1.bt2, .2.bt2, .3.bt2, .4.bt2, .rev.1.bt2, .rev.2.bt2</span></span><br><span class="line">bowtie2-build path/to/ref.fa prefix</span><br></pre></td></tr></table></figure><h3 id="2-进行比对"><a href="#2-进行比对" class="headerlink" title="2. 进行比对"></a>2. 进行比对</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于单端测序(single end)</span></span><br><span class="line">bowtie2 -x prefix -U Single_end.fq -S align.sam &gt; align.log</span><br><span class="line"><span class="comment"># 对于双端测序(paire-end)</span></span><br><span class="line">bowtie2 -x prefix -1 read1.fq -2 read2.fq -S align.sam &gt; align.log</span><br><span class="line"><span class="comment"># 如果要使用局部比对模式</span></span><br><span class="line">bowtie2 --<span class="built_in">local</span> -x prefix -U sigle_end.fq -S align.sam &gt; align.log</span><br></pre></td></tr></table></figure><h3 id="3-从index里获取原始ref-fa"><a href="#3-从index里获取原始ref-fa" class="headerlink" title="3. 从index里获取原始ref.fa"></a>3. 从index里获取原始ref.fa</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bowtie2-inspect prefix</span><br></pre></td></tr></table></figure><h2 id="构建好的index下载"><a href="#构建好的index下载" class="headerlink" title="构建好的index下载"></a>构建好的index下载</h2><table><thead><tr><th>总卷</th><th>分卷</th></tr></thead><tbody><tr><td><a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/hg18.zip" target="_blank" rel="noopener">H. sapiens, UCSC hg18</a></td><td><a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/hg18.1.zip" target="_blank" rel="noopener">part1</a>, <a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/hg18.2.zip" target="_blank" rel="noopener">part2</a>, <a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/hg18.3.zip" target="_blank" rel="noopener">part3</a></td></tr><tr><td><a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/hg19.zip" target="_blank" rel="noopener">H. sapiens, UCSC hg19</a></td><td><a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/hg19.1.zip" target="_blank" rel="noopener">part1</a>, <a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/hg19.2.zip" target="_blank" rel="noopener">part2</a>, <a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/hg19.3.zip" target="_blank" rel="noopener">part3</a></td></tr><tr><td><a href="ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Eukaryotes/vertebrates_mammals/Homo_sapiens/GRCh38/seqs_for_alignment_pipelines/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.bowtie_index.tar.gz" target="_blank" rel="noopener">H. sapiens, NCBI GRCh38</a></td><td>none</td></tr><tr><td><a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm10.zip" target="_blank" rel="noopener">M. musculus, UCSC mm10</a></td><td><a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm10.1.zip" target="_blank" rel="noopener">part1</a>, <a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm10.2.zip" target="_blank" rel="noopener">part2</a>, <a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm10.3.zip" target="_blank" rel="noopener">part3</a></td></tr><tr><td><a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm9.zip" target="_blank" rel="noopener">M. musculus, UCSC mm9</a></td><td><a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm9.1.zip" target="_blank" rel="noopener">part1</a>, <a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm9.2.zip" target="_blank" rel="noopener">part2</a>, <a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm9.3.zip" target="_blank" rel="noopener">part3</a></td></tr><tr><td><a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/rn4.zip" target="_blank" rel="noopener">R. norvegicus, UCSC rn4</a></td><td><a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/rn4.1.zip" target="_blank" rel="noopener">part1</a>, <a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/rn4.2.zip" target="_blank" rel="noopener">part2</a>, <a href="ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/rn4.3.zip" target="_blank" rel="noopener">part3</a></td></tr></tbody></table><h2 id="bowtie2相关术语解读"><a href="#bowtie2相关术语解读" class="headerlink" title="bowtie2相关术语解读"></a>bowtie2相关术语解读</h2><h3 id="1-比对模式"><a href="#1-比对模式" class="headerlink" title="1. 比对模式"></a>1. 比对模式</h3><p>bowtie2里面有两种比对模式：end-to-end, local。前者在比对时要read的首尾比对上,中间没有比对上的作为gap进行罚分.而local比对模式在比对时，优先保证read内部而非两端的比对，就比对效果上看，local模式下的read两端没有比对上，类似切了两端，所以又称为soft clipped。</p><h3 id="2-scores-higher-more-similar"><a href="#2-scores-higher-more-similar" class="headerlink" title="2. scores: higher = more similar"></a>2. scores: higher = more similar</h3><p>比对得分指示着read与参考序列的相似性，得分越高相似性越高。比对得分的控制可以通过指定各个情况的得分实现。如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--ma:match bonus,比对上的得分</span><br><span class="line">--mp:   mismatch penalty,比对不上的罚分</span><br><span class="line">--np:<span class="built_in">read</span>/ref序列中有N的罚分</span><br><span class="line">--rdg:affine <span class="built_in">read</span> gap penalty,比对时<span class="built_in">read</span>出现gap的罚分;注意gap与mismatch的不同</span><br><span class="line">--rfg:affine reference gap penalty,比对时ref上出现gap的罚分</span><br><span class="line">--score-min:指定的最低得分,高于该得分的比对才算比对成功</span><br></pre></td></tr></table></figure><h3 id="3-mapping-quality-higher-more-unique"><a href="#3-mapping-quality-higher-more-unique" class="headerlink" title="3. mapping quality: higher = more unique"></a>3. mapping quality: higher = more unique</h3><p>比对质量指示着read比对到参考序列上的唯一性，得分越高，越是唯一比对。如果一个read有多种比对情况,那么某个比对情况score越高，我们就说这个比对越唯一。</p><h3 id="4-mixed-mode"><a href="#4-mixed-mode" class="headerlink" title="4. mixed mode"></a>4. mixed mode</h3><p>如果pair-end的reads比对不上，bowtie2会尝试使用单个read进行比对，这个情况称为mixed mode。这样的结果就是得到的比对率可能会比不使用该模式的比对率高辣么一点点。你可以指定–no-mixed参数禁用。</p><h3 id="5-reporting"><a href="#5-reporting" class="headerlink" title="5. reporting"></a>5. reporting</h3><p>bowtie2有三种结果模式,默认模式是搜索多个比对情况,然后输出最佳比对。-a模式会搜索并输出所有比对情况。-k模式则是搜索1至多个比对情况，并输出。如果多个比对情况得分相同的话，bowtie2会随机选一个。</p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>差异分析 edgeR</title>
      <link href="/2018/10/12/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90-edgeR/"/>
      <url>/2018/10/12/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90-edgeR/</url>
      
        <content type="html"><![CDATA[<p>下方的代码把edgeR的三种差异分析整合成一个函数, 调用时直接指定参数即可.</p><ul><li>classcial</li><li>glm: likelihood ratio test/ quasi-likelihood F-test</li><li><ul><li>quasi-likelihood(qlf): 推荐用于差异分析，因为他对错误率限制较好。</li></ul></li><li><ul><li>likelihood(lrt)：对与单细胞RNA-测序和没有重复的数据较好</li></ul></li></ul><a id="more"></a><h2 id="调用代码"><a href="#调用代码" class="headerlink" title="调用代码"></a>调用代码</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">suppressPackageStartupMessages(<span class="keyword">library</span>(edgeR))</span><br><span class="line">setwd(<span class="string">'~/practice/180716_edgeR/'</span>)</span><br><span class="line"></span><br><span class="line">rawdata = read.table(<span class="string">'rawdata.txt'</span>)</span><br><span class="line">head(rawdata)</span><br><span class="line">rawdata = rawdata[-(<span class="number">1</span>:<span class="number">5</span>),]</span><br><span class="line"></span><br><span class="line">groups = grepl(<span class="string">'01A'</span>, colnames(rawdata))</span><br><span class="line">groups = ifelse(groups, <span class="string">'tumor'</span>, <span class="string">'normal'</span>)</span><br><span class="line">table(groups)</span><br><span class="line"></span><br><span class="line">edgeR_DGE(exprSet = rawdata, group=groups, type=<span class="string">'classical'</span>)</span><br></pre></td></tr></table></figure><h2 id="定义代码"><a href="#定义代码" class="headerlink" title="定义代码"></a>定义代码</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">edgeR_DGE &lt;- <span class="keyword">function</span>(exprSet, group, type, cpm=c(<span class="number">100</span>,<span class="number">4</span>)) &#123;</span><br><span class="line">    <span class="comment"># 生成DEGList</span></span><br><span class="line">    DGE = DGEList(counts=exprSet, group=group)</span><br><span class="line">    DGE.old = DGE</span><br><span class="line">    <span class="comment"># 生成design</span></span><br><span class="line">    design = model.matrix(~group)</span><br><span class="line">    <span class="comment"># cpm过滤</span></span><br><span class="line">    keep = rowSums(edgeR::cpm(DGE) &gt; cpm[<span class="number">1</span>]) &gt;= cpm[<span class="number">2</span>]</span><br><span class="line">    DGE = DGE[keep,]</span><br><span class="line">    <span class="comment"># 进行校正</span></span><br><span class="line">    DGE = calcNormFactors(DGE)</span><br><span class="line">    <span class="comment"># 检测离群值和关系</span></span><br><span class="line">    png(<span class="string">'plotMDS.png'</span>)</span><br><span class="line">    plotMDS(DGE, method=<span class="string">'bcv'</span>, col=as.numeric(DGE$samples$group))</span><br><span class="line">    legendCol = unique(as.numeric(DGE$samples$group))</span><br><span class="line">    legendGroup = unique(as.character(DGE$samples$group))</span><br><span class="line">    legend(<span class="string">"bottomright"</span>, legendGroup, col=legendCol, pch=<span class="number">20</span>)</span><br><span class="line">    dev.off()</span><br><span class="line">    <span class="keyword">if</span> (type == <span class="string">'classical'</span>) &#123;</span><br><span class="line">        <span class="comment"># 计算离散度dispersion</span></span><br><span class="line">        d = estimateCommonDisp(DGE)</span><br><span class="line">        d = estimateTagwiseDisp(d)</span><br><span class="line">        test = exactTest(d)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment"># 计算离散度dispersion</span></span><br><span class="line">        d = estimateGLMCommonDisp(DGE)</span><br><span class="line">        d = estimateGLMTrendedDisp(d)</span><br><span class="line">        d = estimateGLMTagwiseDisp(d)</span><br><span class="line">        <span class="keyword">if</span> (type == <span class="string">'qlf'</span>) &#123;</span><br><span class="line">            fit = glmQLFit(d, design)</span><br><span class="line">            test = glmQLFTest(fit, coef=<span class="number">2</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (type == <span class="string">'lrt'</span>) &#123;</span><br><span class="line">            fit = glmFit(d, design)</span><br><span class="line">            test = glmLRT(fit, coef=<span class="number">2</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    png(<span class="string">'plotBCV.png'</span>)</span><br><span class="line">    plotBCV(d)</span><br><span class="line">    dev.off()</span><br><span class="line">    png(<span class="string">'plotSmear.png'</span>)</span><br><span class="line">    de = decideTestsDGE(test, adjust.method=<span class="string">"BH"</span>, p.value = <span class="number">0.05</span>)</span><br><span class="line">    tags = rownames(d)[as.logical(de)]</span><br><span class="line">    plotSmear(test, de.tags=tags)</span><br><span class="line">    abline(h=c(-<span class="number">4</span>,<span class="number">4</span>), col=<span class="string">'blue'</span>)</span><br><span class="line">    dev.off()</span><br><span class="line">    finalDGE = topTags(test, n=nrow(exprSet))</span><br><span class="line">    finalDGE = as.data.frame(finalDGE)</span><br><span class="line">    write.csv(file=<span class="string">'DGE_edgeR.txt'</span>, finalDGE, quote = <span class="literal">F</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 差异分析 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>比对 subread</title>
      <link href="/2018/10/12/%E6%AF%94%E5%AF%B9-subread/"/>
      <url>/2018/10/12/%E6%AF%94%E5%AF%B9-subread/</url>
      
        <content type="html"><![CDATA[<p>subread是个套件,里面有subread aligner, subjunc aligner, featureCounts, exactSNP.</p><p>subread aligner可以用于DNA-seq和RNA-seq.当用于RNA-seq时,subread只适用于差异分析;对于检测基因组变异如可变剪接之类的,需要reads的完全比对,这时候可以使用subjunc进行比对.在比对RNA-seq数据时,subread不会取检测exon-exon junctions的存在,只会把exon-spanning eads的最大可比对区域作为比对结果.但是,如果只是进行差异分析的话,subread的结果足以进行.subread的比对上reads可能会比subjunc多.</p><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载源文件</span></span><br><span class="line">https://sourceforge.net/projects/subread/files/</span><br><span class="line">tar zxvf subread-1.6.2.tar.gz</span><br><span class="line">make -f Makefile.Linux</span><br><span class="line"></span><br><span class="line"><span class="comment"># in R</span></span><br><span class="line">biocLite(<span class="string">'Rsubread'</span>)</span><br></pre></td></tr></table></figure><h2 id="subread-aligner"><a href="#subread-aligner" class="headerlink" title="subread aligner"></a>subread aligner</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">subread-buildindex -o my_index ref.fa  <span class="comment">#允许单染色体文件</span></span><br><span class="line"><span class="comment"># -B 把index进行分割多个文件;会覆盖-M的设置</span></span><br><span class="line"><span class="comment"># -c 构建color-space索引</span></span><br><span class="line"><span class="comment"># -f &lt;int&gt; 去除高度重复序列的重复阈值,高于该阈值的重复序列将被去除</span></span><br><span class="line"><span class="comment"># -F 构建一个完全索引,小鼠的完全索引达14G</span></span><br><span class="line"><span class="comment"># -M &lt;int&gt; 可以用int MB的RAM</span></span><br><span class="line"><span class="comment"># -o &lt;string&gt;index的basename</span></span><br><span class="line"></span><br><span class="line">subread-align -t 1 -i my_index -r reads.fastq -o subread_results.bam</span><br><span class="line"><span class="comment"># -t &lt;int&gt;进行比对的数据类型, 0是RNA-seq, 1是DNA-seq</span></span><br><span class="line"><span class="comment"># --multiMapping 允许多比对</span></span><br><span class="line"><span class="comment"># -B &lt;int&gt; 允许的多比对数指定为int</span></span><br><span class="line"><span class="comment"># -T &lt;int&gt;指定用int个threads</span></span><br><span class="line"><span class="comment"># -I &lt;int&gt; 检测的indel长度最长为int bp</span></span><br><span class="line"><span class="comment"># -d &lt;int&gt; minFragLength指定为50</span></span><br><span class="line"><span class="comment"># -D 600maxFragLength指定为600</span></span><br><span class="line"><span class="comment"># -r fastq文件输入的reads</span></span><br><span class="line"><span class="comment"># -R read2.fastq 如果是paired-end,由此指定read2</span></span><br><span class="line"><span class="comment"># -a &lt;string&gt;指定注释文件</span></span><br><span class="line"><span class="comment"># -A &lt;string&gt; 指定参考基因组和注释之间的chr名对应关系的文件</span></span><br><span class="line"><span class="comment">#第一列是注释里面的染色体名,第二列是参考基因组对应的染色体名.不需要列名.</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -b 当比对color space文件时,输出的比对结果保持正常格式,而非color-space</span></span><br><span class="line"><span class="comment"># -F &lt;string&gt; 指定注释文件的格式, 'GTF', 'GFF', 'SAF'(在Rsubread里默认这个)</span></span><br><span class="line"><span class="comment"># -m &lt;int&gt; 指定一致性阈值,当比对一致性超过该阈值则认为比对上</span></span><br><span class="line"><span class="comment"># -n &lt;int&gt; 允许的最大错配数</span></span><br><span class="line"><span class="comment"># -p &lt;int&gt; 当是paired-end时,两个reads的比对一致性最低值,应该小于-m的指定值</span></span><br><span class="line"><span class="comment"># -P 3/6/33/64指定使用的phred质量值,3指phred+33; 在Rsubread中,33值phred+33.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他有关genomic variance的设置见handbook.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 比对microRNA-seq reads</span></span><br><span class="line"><span class="comment"># 注释下载: http://www.mirbase.org/</span></span><br><span class="line">subread-buildindex -F -B -o mm10_full_index mm10.fa</span><br><span class="line">subread-align -t 1 -i mm10_full_index \</span><br><span class="line">  -n 35 -m 4 -M 3 -T 10 -I 0 \</span><br><span class="line">  --multiMapping -B 10 \</span><br><span class="line">  -r miRNA_reads.fastq -o results.sam</span><br></pre></td></tr></table></figure><h2 id="subjunc"><a href="#subjunc" class="headerlink" title="subjunc"></a>subjunc</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">subjunc -i my_index -r rnaseq-reads1.txt -R rnaseq-read2.txt -o subjunc_result</span><br></pre></td></tr></table></figure><h2 id="featureCounts定量"><a href="#featureCounts定量" class="headerlink" title="featureCounts定量"></a>featureCounts定量</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">featureCounts -T 5 -a annotation.gtf -t exon -g gene_id \</span><br><span class="line">  -o counts.txt mapping_results_SE.sam</span><br><span class="line">  # 可以有多个bam文件</span><br><span class="line"># paired-end</span><br><span class="line">featureCounts -p -a annotation.gtf -t exon -g gene_id \</span><br><span class="line">  # -P -d 50 -D 600# 指定了fragment长度</span><br><span class="line">  # -B # 不考虑fragment,但两个read都要比对上,才计数</span><br><span class="line">  # -C  # 排除嵌合(chimeric fragments)</span><br><span class="line">  -o counts.txt mapping_results_PE.bam</span><br></pre></td></tr></table></figure><h2 id="SNP-calling"><a href="#SNP-calling" class="headerlink" title="SNP calling"></a>SNP calling</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">exactSNP [options] -i input -g reference genome -o output</span><br><span class="line"></span><br><span class="line"><span class="comment"># -a &lt;file&gt; 指定vcf格式的snp注释文件</span></span><br><span class="line"><span class="comment"># -b 指定输入文件是bam文件</span></span><br><span class="line"><span class="comment"># -f &lt;float&gt; 指定含SNP位点区域的错配碱基的最小区域</span></span><br><span class="line"><span class="comment"># -g &lt;file&gt; 指定参考基因组文件, fasta格式</span></span><br><span class="line"><span class="comment"># -i &lt;file&gt;指定输入文件,SAM或BAM,如果是BAM,指定-b选项</span></span><br><span class="line"><span class="comment"># -n &lt;int&gt; 指定出现错配碱基的最小数目</span></span><br><span class="line"><span class="comment"># -Q &lt;int&gt; 指定在50x测序深度是的SNPcalling的q-value的cutoff值</span></span><br><span class="line"><span class="comment"># -r &lt;int&gt; 判定为SNp时需要的最少比对上reads数目</span></span><br><span class="line"><span class="comment"># -s &lt;int&gt; 指定作为SNP位点的碱基质量值阈值</span></span><br><span class="line"><span class="comment"># -t &lt;int&gt; read两端切除的碱基数</span></span><br><span class="line"><span class="comment"># -T &lt;int&gt; Threads</span></span><br><span class="line"><span class="comment"># -x &lt;int&gt; 判断为SNP的位点的最大测序深度</span></span><br></pre></td></tr></table></figure><h2 id="在R里面"><a href="#在R里面" class="headerlink" title="在R里面"></a>在R里面</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(Rsubread)</span><br><span class="line">buildindex(basename=<span class="string">'my_index'</span>, reference=<span class="string">'genome.fa'</span>)</span><br><span class="line">align(index=<span class="string">'my_index'</span>, type=<span class="string">'dna'</span>,</span><br><span class="line">  readfile1=<span class="string">'reads.txt.gz'</span>,</span><br><span class="line">  output_file=<span class="string">'rsubread.bam'</span>,</span><br><span class="line">  nthreads=<span class="number">5</span>,</span><br><span class="line">  indels=<span class="number">16</span>,</span><br><span class="line">  unique=<span class="literal">F</span>, nBestLocations=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># pairedd-end</span></span><br><span class="line">align(index=<span class="string">'my_index'</span>,</span><br><span class="line">  readfile1=<span class="string">'reads1.fq.fz'</span>, readfile2=<span class="string">'reads2.fq.gz'</span>,</span><br><span class="line">  type=<span class="string">'dna'</span>,</span><br><span class="line">  output_file=<span class="string">'rsubread.bam'</span>,</span><br><span class="line">  minFragLength=<span class="number">50</span>, maxFragLength=<span class="number">600</span>)</span><br><span class="line"></span><br><span class="line">subjunc(index=<span class="string">'my_index'</span>, readfile1=<span class="string">'rnaseq-reads.txt.gz'</span>, output_file=<span class="string">'subjunc_results.bam'</span>)</span><br><span class="line"></span><br><span class="line">featureCounts(files=<span class="string">"mapping_results_SE.sam"</span>, nthreads=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 提供参考注释的话</span></span><br><span class="line">featureCounts(files=<span class="string">"mapping_results_SE.sam"</span>,annot.ext=<span class="string">"annotation.gtf"</span>,</span><br><span class="line">isGTFAnnotationFile=<span class="literal">TRUE</span>,GTF.featureType=<span class="string">"exon"</span>,GTF.attrType=<span class="string">"gene_id"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># paired-end</span></span><br><span class="line">featureCounts(files=c(<span class="string">'read1_mapped.bam'</span>, <span class="string">'read2_mapped.bam'</span>))</span><br><span class="line">featureCounts(files=<span class="string">'PE_mapped.bam'</span>, isPairedEnd=<span class="literal">T</span>,</span><br><span class="line"> requireBothEndsMapped=<span class="literal">TRUE</span>, <span class="comment"># 要两个reads都比对上才计数</span></span><br><span class="line"> countChimericFragments=<span class="literal">FALSE</span>) <span class="comment"># 不考虑chimeric fragment</span></span><br></pre></td></tr></table></figure><h2 id="其他小功能"><a href="#其他小功能" class="headerlink" title="其他小功能"></a>其他小功能</h2><ul><li>repair: 把paired-end.bam文件里面的reads成对放置</li><li>coverageCount: 计算基因组中某个区域的read coverage</li><li>flattenGTF: 把GTF里面的某个feature的行提取成SAF文件.如提取所有的exons注释</li><li>promoterRegions:只在Rsubread里面有,提取出每个基因的启动子区域位置.</li><li>removeDunp: 去除SAM文件里面的重复reads</li><li>subread-fullscan：提取目标序列在染色体上的高度同源序列位置</li></ul>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>比对软件 Hisat2</title>
      <link href="/2018/10/12/%E6%AF%94%E5%AF%B9%E8%BD%AF%E4%BB%B6-Hisat2/"/>
      <url>/2018/10/12/%E6%AF%94%E5%AF%B9%E8%BD%AF%E4%BB%B6-Hisat2/</url>
      
        <content type="html"><![CDATA[<p>hisat2是快速灵敏的比对软件,可用于全基因组测序，转录组测序，外显子测序的数据比对.基于GCSA（bwt的拓展），我们设计了graph FM index用于比对。hisat2的比对结果是sam格式文件，你可以使用samtools，GATK等软件进行后续的分析.</p><a id="more"></a><h2 id="下载与安装"><a href="#下载与安装" class="headerlink" title="下载与安装"></a>下载与安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install hisat2</span><br></pre></td></tr></table></figure><h2 id="Getting-started"><a href="#Getting-started" class="headerlink" title="Getting started"></a><a href="https://ccb.jhu.edu/software/hisat2/manual.shtml" target="_blank" rel="noopener">Getting started</a></h2><h3 id="1-构建索引"><a href="#1-构建索引" class="headerlink" title="1. 构建索引"></a>1. 构建索引</h3><p>如果你用到了–snp, –ss, –exon等参数,对于人类基因组的大小来说,hisat2需要200G RAM。这几个参数慎用。<a href="ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data" target="_blank" rel="noopener">预构建的索引</a>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出8个以index为前缀的.n.ht2的文件,n=1-8</span></span><br><span class="line">hisat2-build ref.fa index</span><br></pre></td></tr></table></figure><h3 id="2-进行比对"><a href="#2-进行比对" class="headerlink" title="2. 进行比对"></a>2. 进行比对</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># single-end</span></span><br><span class="line">hisat2 -f -x index -U reads.fa -S align.sam &gt; align.log</span><br><span class="line"><span class="comment"># pair-end</span></span><br><span class="line">hisat2 -f -x index -1 read_1.fa -2 read_2.fa -S align.sam &gt; align.log</span><br></pre></td></tr></table></figure><h3 id="3-使用samtools进行下游分析"><a href="#3-使用samtools进行下游分析" class="headerlink" title="3. 使用samtools进行下游分析"></a>3. <a href="http://samtools.sourceforge.net/mpileup.shtml" target="_blank" rel="noopener">使用samtools进行下游分析</a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转为bam</span></span><br><span class="line">samtools view -bS align.sam &gt; align.bam</span><br><span class="line"><span class="comment"># 对bam进行排序</span></span><br><span class="line">samtools sort align.bam -o align.sorted.bam</span><br><span class="line"><span class="comment"># variant calling</span></span><br><span class="line">samtools mpileup -uf ref.fa align.sorted.bam | bcftools view -bvcg - &gt; align.raw.bcf</span><br><span class="line">bcftools view align.raw.bcf</span><br></pre></td></tr></table></figure><h2 id="options"><a href="#options" class="headerlink" title="options"></a>options</h2><h3 id="hisat2：进行比对"><a href="#hisat2：进行比对" class="headerlink" title="hisat2：进行比对"></a>hisat2：进行比对</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">hisat2 [options]* -x &lt;hisat2-idx&gt; &#123;-1 &lt;m1&gt; -2 &lt;m2&gt; | -U &lt;r&gt; | --sra-acc &lt;SRA accession number&gt;&#125; [-S &lt;hit&gt;]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项</span></span><br><span class="line">-x &lt;hisat2-idx&gt; 索引的前缀</span><br><span class="line">-1 &lt;ml&gt; 以逗号分隔的多个pair-end read1</span><br><span class="line">-2 &lt;ml&gt;以逗号分隔的多个pair-end read2</span><br><span class="line">-U &lt;r&gt;以逗号分隔的多个single-end reads</span><br><span class="line">--sra-acc &lt;number&gt;指定sra accession number</span><br><span class="line">-S &lt;hit&gt;指定输出文件</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入可选参数</span></span><br><span class="line">-q 说明输入文件格式是fastq文件</span><br><span class="line">--qseq 说明输入文件格式是QSEQ文件</span><br><span class="line">-f 说明输入文件是fasta文件</span><br><span class="line">-r 说明输入文件是每行一个序列，除此无他</span><br><span class="line">-c reads是以序列的形式用逗号分隔输入的</span><br><span class="line">-s,--skip &lt;int&gt;reads的前int个跳过</span><br><span class="line">-u &lt;int&gt;只比对int个reads</span><br><span class="line">-5,--trim5 &lt;int&gt;比对前截去5‘端的int个base</span><br><span class="line">-3,--trim3 &lt;int&gt;比对前截去3’端的int个base</span><br><span class="line">--phred33说明fastq的碱基质量体系phred33</span><br><span class="line">--phred64 说明fastq的碱基质量体系是phred64</span><br><span class="line">--solexa-quals说明质量体系是solexa,并且转换成phred</span><br><span class="line"></span><br><span class="line"><span class="comment"># 比对可选参数</span></span><br><span class="line">--n-ceil &lt;func&gt;指定每条reads允许N碱基的个数的函数;超过将被丢弃</span><br><span class="line">--ignore-quals在对错配罚分时,考虑该位置的碱基质量</span><br><span class="line">--nofw/--norc 指定后,在pair-end无法比对时,不会试图去比对参考序列的forward链(nofw)和reverse链(norc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打分选项</span></span><br><span class="line">--mp MX,MN 指定错配时的最大和最小罚分</span><br><span class="line">--sp MX,MN 指定发生soft clipped的碱基的最大和最小罚分</span><br><span class="line">--no-softclip 禁用softclip</span><br><span class="line">--np &lt;int&gt;指定N碱基的罚分</span><br><span class="line">--rdg m1,m2指定比对时<span class="built_in">read</span> gap open(m1)和gap extend(m2)的罚分</span><br><span class="line">--rfg m1,m2 指定比对时reference gap open(m1)和gap extend(m2)的罚分</span><br><span class="line">--score-min &lt;func&gt;指定比对得分的函数, 当超过计算所得分数时才算一个成功比对</span><br></pre></td></tr></table></figure><h3 id="hisat2-index-构建索引"><a href="#hisat2-index-构建索引" class="headerlink" title="hisat2-index: 构建索引"></a>hisat2-index: 构建索引</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">hisat2-build [options]* &lt;reference_in&gt; &lt;ht2_base&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项</span></span><br><span class="line">-f 指定ref的文件格式</span><br><span class="line">-c 以逗号分隔的形式指定有多个ref 序列，而非fasta文件的列表</span><br><span class="line">--large-index指定构建大型索引即便参考序列短于 4 billion bp</span><br><span class="line">-a 禁止自动使用参数（--bmax，--dv，--packed）</span><br><span class="line">-r 不构建3.ht2,4.ht2</span><br><span class="line">-3 只构建3.ht2,4.ht2</span><br><span class="line">-p 使用多少个线程</span><br><span class="line">--snp &lt;path&gt;提供snps的列表</span><br><span class="line">--haplotype &lt;path&gt;提供haplotypes的文件</span><br><span class="line">--ss 提供间接位点(splice sites)的文件.与--exon联用</span><br><span class="line">--exon &lt;path&gt;提供外显子文件,与--ss联用</span><br><span class="line">--cutoff &lt;int&gt;  只对参考序列int个base构建索引,丢弃其余部分</span><br><span class="line">-q 静默运行</span><br></pre></td></tr></table></figure><h3 id="hisat2-inspect-从index提取源参考序列"><a href="#hisat2-inspect-从index提取源参考序列" class="headerlink" title="hisat2-inspect:从index提取源参考序列"></a>hisat2-inspect:从index提取源参考序列</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hisat2-inspect [options]* &lt;ht2_base&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项</span></span><br><span class="line">-a &lt;int&gt;输出时每隔60base就换行</span><br><span class="line">-n 输出参考序列名,每行一个</span><br><span class="line">-s 打印进行构建索引的参数</span><br><span class="line">--snp 打印snps</span><br><span class="line">--ss 打印splice site</span><br><span class="line">--exon 打印exon</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>差异分析 limma</title>
      <link href="/2018/10/12/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90-limma/"/>
      <url>/2018/10/12/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90-limma/</url>
      
        <content type="html"><![CDATA[<p>limma最开始是用于芯片数据分析的,不过现在也支持RNA-seq等数据的差异分析，但是需要通过voom函数进行校正表达矩阵。</p><a id="more"></a><h2 id="分析芯片数据"><a href="#分析芯片数据" class="headerlink" title="分析芯片数据"></a>分析芯片数据</h2><p>在limma芯片数据分析的过程中,有需要注意的一个地方,那就是分组矩阵和差异比较矩阵的问题,使用差异比较矩阵时的代码是有不一样的,结果仍旧相同,当然你要指定好makeContrasts的参数咯.</p><p>使用topTable时,coef是用来指定提取特定比较的结果.例如你在design的时候,1-2的比较,coef可以设置为’1-2’.如果不是用差异比较矩阵,coef=1就是分组矩阵的column1-column2,以此类推</p><h3 id="不使用差异比较矩阵"><a href="#不使用差异比较矩阵" class="headerlink" title="不使用差异比较矩阵"></a>不使用差异比较矩阵</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(limma)</span><br><span class="line">groups = sort(rep(<span class="number">1</span>:<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">names(groups) = level(factor(groups))</span><br><span class="line">design = model.matrix(~factor(groups))</span><br><span class="line">fit.lm = lmfit(expr, design)</span><br><span class="line">fit.ebs = eBayes(fit.lm)</span><br><span class="line">topTable(fit.ebs, adjust=<span class="string">'BH'</span>, coef=<span class="number">2</span>, lfc=<span class="number">1</span>, p.value=<span class="number">0.05</span>, numbers=<span class="number">30000</span>)</span><br><span class="line"><span class="comment"># 输出所有的差异分析结果</span></span><br><span class="line">results = desideTests(fit.ebs)</span><br></pre></td></tr></table></figure><h3 id="使用差异比较矩阵"><a href="#使用差异比较矩阵" class="headerlink" title="使用差异比较矩阵"></a>使用差异比较矩阵</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">groups = sort(rep(<span class="number">1</span>:<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">design = model.matrix(~ <span class="number">0</span> + factor(groups))</span><br><span class="line">colnames(design) = c(<span class="string">'1'</span>,<span class="string">'2'</span>,<span class="string">'3'</span>)</span><br><span class="line">fit.lm = lmfit(expr, design)</span><br><span class="line">contrast = makeContrasts(<span class="string">'1-2'</span>, <span class="string">'1-3'</span>, <span class="string">'2-3'</span>, levels=design)</span><br><span class="line">fit.cts = contrasts.fit(fit.lm, contrast)</span><br><span class="line">fit.ebs = eBayes(fit.cts)</span><br><span class="line"><span class="comment"># 选取top的基因查看</span></span><br><span class="line">topTable(fit.ebs, adjust=<span class="string">'BH'</span>, coef=<span class="number">2</span>, lfc=<span class="number">1</span>, p.value=<span class="number">0.05</span>, numbers=<span class="number">30000</span>)</span><br><span class="line"><span class="comment"># 输出所有的差异分析结果</span></span><br><span class="line">results = desideTests(fit.ebs)</span><br></pre></td></tr></table></figure><h2 id="分析RNA-seq数据"><a href="#分析RNA-seq数据" class="headerlink" title="分析RNA-seq数据"></a>分析RNA-seq数据</h2><p>用于差异分析的RNA-seq数据必需是 <strong>raw_counts</strong> 数据.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">suppressMessages(<span class="keyword">library</span>(limma))</span><br><span class="line"><span class="comment"># 构建分组矩阵</span></span><br><span class="line">expr_matrix = your_expr_matrix</span><br><span class="line">groups = your_groups</span><br><span class="line">design = model.matrix(~factor(group_list))</span><br><span class="line">colnames(design) = levels(factor(group_list))</span><br><span class="line">rownames(design) = colnames(expr_matrix)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行校正</span></span><br><span class="line">v = voom(expr_matrix, design, normalize=<span class="string">'quantile'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行差异分析</span></span><br><span class="line">fit.lm = lmFit(v, design)</span><br><span class="line">fit.ebs = eBayes(fit.lm)</span><br><span class="line">DE.genes = topTable(fit.ebs, coef=<span class="number">2</span>, n=<span class="literal">Inf</span>, lfc=<span class="number">1</span>, p.value=<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure><h2 id="结果说明"><a href="#结果说明" class="headerlink" title="结果说明"></a>结果说明</h2><ul><li>topTable用于提取top基因和对应的contrast</li><li>logFC是log fold change</li><li>aveExpr是average log2-expression level for gene in all array</li><li>pvalue/adj.p.value是p-value和校正后的p-value</li><li>t 是 moderated t-statistic</li><li>B 假设B=1.5,则exp(1.5)=4.48,因此基因出现差异表达的可能性为4.48/(1+4.48)=0.8</li></ul>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 差异分析 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>生信基础 reads 重复和比对重复</title>
      <link href="/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-reads-%E9%87%8D%E5%A4%8D%E5%92%8C%E6%AF%94%E5%AF%B9%E9%87%8D%E5%A4%8D/"/>
      <url>/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-reads-%E9%87%8D%E5%A4%8D%E5%92%8C%E6%AF%94%E5%AF%B9%E9%87%8D%E5%A4%8D/</url>
      
        <content type="html"><![CDATA[<p>在说duplication之前,我们有必要说一下PCR bias和unique reads. PCR bias是指在PCR扩增的过程中,PCR引物会偏好性地同某条DNA链结合,导致的结果就是这条DNA链被扩增的数目要更多;而不是所有的DNA链被平行扩增.那么什么又是unique reads呢?在得到测序结果后,对于任意两条reads,只要其reads的起点,中间序列,终点这三点有一点不同,这两条reads就是互为unique reads. 所以我们来看, 建库后PCR扩增的测序结果里面,肯定有很多条reads不是unique reads,这些reads就是所谓的duplication, 这其中肯定也包含了PCR bias引起的额外重复.</p><a id="more"></a><blockquote><p>duplication rate = 1 - unique reads / total reads.</p></blockquote><h2 id="1-duplication的来源"><a href="#1-duplication的来源" class="headerlink" title="1. duplication的来源"></a>1. duplication的来源</h2><ul><li>PCR duplicate</li><li>cluster duplicate</li><li>optical duplicate: 单个cluster的光信号重影导致2个信号产生</li></ul><h2 id="2-影响重复率-duplication-rate-的因素"><a href="#2-影响重复率-duplication-rate-的因素" class="headerlink" title="2. 影响重复率(duplication rate)的因素"></a>2. 影响重复率(duplication rate)的因素</h2><ul><li>扩增模版的多样性</li><li>模版序列的多样性: PCR bias</li><li>adapter与fragment的连接效率</li><li>fragment的一致性: 片段长度不同,扩增效率也是不同的</li><li>cluster PCR: cluster的大小影响测序信号的强弱</li><li>其他影响测序过程的方面</li></ul><h3 id="3-去重"><a href="#3-去重" class="headerlink" title="3. 去重"></a>3. 去重</h3><p>如果是原始数据的重复在质控阶段就可以了,类似的包Trimmomatic和fastp都能去重.如果是比对后的重复,使用samtools可以去重,也可以使用picard去重.(去重的原理是把bam文件里面的比对结果改成1024,表示duplicate)</p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>生信基础 unique比对的获取</title>
      <link href="/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-unique%E6%AF%94%E5%AF%B9%E7%9A%84%E8%8E%B7%E5%8F%96/"/>
      <url>/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-unique%E6%AF%94%E5%AF%B9%E7%9A%84%E8%8E%B7%E5%8F%96/</url>
      
        <content type="html"><![CDATA[<h2 id="1-Sam文件各标签含义（tophat-hisat2"><a href="#1-Sam文件各标签含义（tophat-hisat2" class="headerlink" title="1.Sam文件各标签含义（tophat/hisat2)"></a>1.Sam文件各标签含义（tophat/hisat2)</h2><ul><li>NH:i:<n>: N=1时 为unique。常用于tophat/hisat2产生的sam文件unique read筛选。</n></li><li>CC:Z: 当为‘=’为map到同一条基因上，一般在map基因组时由于内含子存在而容易出现，他只代表两种不同的方式，计数时应记为1。此处一般为其他基因的名字。CP:i 和HI：i标签为map到第i条基因及起始位置。</li><li>YT:Z:S 代表的含义与bowtie产生的sam也不同。具体还未知！其他标签AS，XN,XM,XO,XG,NM,MD等如下图可以看出都相同。</li></ul><a id="more"></a><blockquote><p>对于tophat/hisat2比对产生的sam文件我们可以直接筛选NH标签。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep‘NH:i:1’ out.sam &gt;unique.sam</span><br></pre></td></tr></table></figure><h2 id="2-Sam文件各标签含义（bowtie2"><a href="#2-Sam文件各标签含义（bowtie2" class="headerlink" title="2.Sam文件各标签含义（bowtie2)"></a>2.Sam文件各标签含义（bowtie2)</h2><ul><li>AS:i:<n>Alignmentscore.可以为负的，在local下可以为正的。 只有当Align≥1 time才出现</n></li><li>XS:i:<n>Alignmentscorefor second-best alignment. 当Align&gt;1 time出现</n></li><li>YS:i:<n>Alignmentscorefor opposite mate in the paired-end alignment. 当该read是双末端测序中的另一条时出现</n></li><li>XN:i:<n>Thenumber of ambiguous bases in the reference covering this alignment.（推测是指不知道错配发生在哪个位置，推测是针对于**和缺失，待查证）</n></li><li>XM:i:s错配碱基的数目</li><li>XO:i:<n>Thenumberof gap opens(针对于比对中的**和缺失)</n></li><li>XG:i:<n>Thenumberof gap extensions(针对于比对中的**和缺失延伸数目)</n></li><li>NM:i:<n>Theeditdistance。（edits:**/缺失/替换数目)</n></li><li>YF:Z:s该reads被过滤掉的原因。可能为LN(错配数太多，待查证)、NS(read中包含N或者．)、SC(match bonus低于设定的阈值)、QC(failing quality control，待证)</li><li>YT:Z:s值为UU表示不是pair中一部分、CP是pair且可以完美匹配、DP是pair但不能很好的匹配、UP是pair但是无法比对到参考序列上。</li><li>MD:Z:s比对上的错配碱基的字符串表示。</li></ul><blockquote><p>由于bowtie2产生的sam文件并没有NH标签，所以提取uniqueread可能比较麻烦。首先提取“AS”标签表示能比对上的read（&gt;=1 time），然后利用grep反正则表达式过滤掉XS标签得到我们需要的unique read。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep “AS:” aligned.sam | grep –v “XS:” &gt;unique_alignments.sam</span><br></pre></td></tr></table></figure><p>对于双端测序用bowtie2比对筛选unique concordant pair时则需要在上一步的基础上增加如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep ‘YT:Z:CP’ unique.sam&gt;pair-end_unique.sam</span><br></pre></td></tr></table></figure><h2 id="3-Bwa获取unique"><a href="#3-Bwa获取unique" class="headerlink" title="3.Bwa获取unique"></a>3.Bwa获取unique</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">samtools view bwa.bam | grep <span class="string">"XT:A:U"</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>生信基础 各种数据的下载</title>
      <link href="/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%8B%E8%BD%BD/"/>
      <url>/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E5%90%84%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%8B%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<h2 id="三大数据库版本对应情况"><a href="#三大数据库版本对应情况" class="headerlink" title="三大数据库版本对应情况"></a>三大数据库版本对应情况</h2><table><thead><tr><th>NCBI</th><th>UCSC</th><th>Ensemble</th></tr></thead><tbody><tr><td>GRCh36</td><td>hg18</td><td>ENSEMBL release_52</td></tr><tr><td>GRCh37</td><td>hg19</td><td>ENSEMBL release_59/61/64/68/69/75</td></tr><tr><td>GRCh38</td><td>hg38</td><td>ENSEMBL release_76/77/78/80/81/82</td></tr></tbody></table><a id="more"></a><h2 id="SRA-SRR数据"><a href="#SRA-SRR数据" class="headerlink" title="SRA/SRR数据"></a>SRA/SRR数据</h2><p>上<a href="https://www.ebi.ac.uk/" target="_blank" rel="noopener">EBI网站</a>查找数据的SRR,然后使用aspera下载fastq.gz原始数据</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .openssh不可用则改用.putty的文件</span></span><br><span class="line"><span class="comment"># 注意nohup &amp; 之前的那个点".", 是给ascp用的</span></span><br><span class="line">ascp=~/.aspera/connect/bin/ascp</span><br><span class="line">ssh_key=~/.aspera/connect/etc/asperaweb_id_dsa.openssh</span><br><span class="line">nohup <span class="variable">$ascp</span> -P 33001 -i <span class="variable">$ssh_key</span> \</span><br><span class="line">    era-fasp@fasp.sra.ebi.ac.uk:/vol1/fastq/SRR404/000/SRR4041970/SRR4041970_1.fastq.gz . &amp;</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 数据库对应的地址</span></span><br><span class="line">NCBI: anonftp@ftp-private.ncbi.nlm.nih.gov:genomes/</span><br><span class="line">EBI: era-fasp@fasp.sra.ebi.ac.uk:/vol1/</span><br><span class="line"></span><br><span class="line"><span class="comment"># sra-tools::prefetch accession</span></span><br></pre></td></tr></table></figure><h2 id="GEO数据"><a href="#GEO数据" class="headerlink" title="GEO数据"></a>GEO数据</h2><p>使用GEOquery包进行下载.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用GDS858的ID下载</span></span><br><span class="line">GDS = getGEO(<span class="string">'GDS858'</span>, destdir=<span class="string">'.'</span>)</span><br><span class="line">expr_matrix = Table(GDS)<span class="comment">#得到表达矩阵</span></span><br><span class="line">Des_info = Meta(GDS)<span class="comment">#得到描述信息(metadata)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用GSE1009的ID下载</span></span><br><span class="line"><span class="comment"># 返回的是含expressionSet对象的list</span></span><br><span class="line">genes = geneNames(GSE[[<span class="number">1</span>]])<span class="comment"># 得到gene名, geneNames是biobase包里面的</span></span><br><span class="line">samples = sampleNames(GSE[[<span class="number">1</span>]])<span class="comment"># 得到样品名</span></span><br><span class="line">pdata = pData(GSE[[<span class="number">1</span>]])<span class="comment"># 得到描述信息(metadata)</span></span><br><span class="line">expr_matrix = exprs(GSE[[<span class="number">1</span>]])<span class="comment"># 得到表达矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># GPL16699的ID下载</span></span><br><span class="line">Des_info = Meta(GPL)<span class="comment"># 得到描述信息</span></span><br><span class="line">Annotation = Table(GPL)<span class="comment"># 得到芯片注释信息(geneID-probeID)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载原始数据</span></span><br><span class="line">rawdata = getGEOSuppFiles(GSE1009)</span><br></pre></td></tr></table></figure><h2 id="TCGA"><a href="#TCGA" class="headerlink" title="TCGA"></a>TCGA</h2><blockquote><p><a href="https://xenabrowser.net/datapages/" target="_blank" rel="noopener">xenabrowser</a>整合了TCGA的数据,可以直接选择下载</p></blockquote><p>先从TCGA选择数据,然后下载对应的manifest进行下载.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TCGA：https://cancergenome.nih.gov/</span><br><span class="line">gdc-client.exe download -m gdc_manifest_20180516_053841.txt -d tcgadata</span><br></pre></td></tr></table></figure><h2 id="参考基因组及注释"><a href="#参考基因组及注释" class="headerlink" title="参考基因组及注释"></a>参考基因组及注释</h2><blockquote><p>如果浏览器无法访问,将ftp:改成http:即可  </p></blockquote><ul><li>UCSC Table Browser：  <a href="http://genome.ucsc.edu/cgi-bin/hgTables?hgsid=679534527_eRMIpVLpdUvIprCRZP6InFABs6gX" target="_blank" rel="noopener">http://genome.ucsc.edu/cgi-bin/hgTables?hgsid=679534527_eRMIpVLpdUvIprCRZP6InFABs6gX</a></li><li>NCBI ftp：            <a href="ftp://ftp.ncbi.nlm.nih.gov/" target="_blank" rel="noopener">ftp://ftp.ncbi.nlm.nih.gov/</a>  </li><li>EMBL ftp：            <a href="ftp://ftp.ensembl.org/pub/" target="_blank" rel="noopener">ftp://ftp.ensembl.org/pub/</a>,<pre><code>ftp://ftp.ensembl.org/pub/release-86/gtf/homo_sapiens</code></pre></li><li>GCD:                  <a href="http://www.gencodegenes.org/" target="_blank" rel="noopener">http://www.gencodegenes.org/</a></li><li>指定基因(batch entrezhttps)://<a href="http://www.ncbi.nlm.nih.gov/sites/batchentrez" target="_blank" rel="noopener">www.ncbi.nlm.nih.gov/sites/batchentrez</a></li><li>植物参考基因组(phytozome):<a href="https://phytozome.jgi.doe.gov/pz/portal.html" target="_blank" rel="noopener">https://phytozome.jgi.doe.gov/pz/portal.html</a></li><li>小鼠基因组(MGI):      <a href="http://www.informatics.jax.org/" target="_blank" rel="noopener">http://www.informatics.jax.org/</a></li><li>拟南芥(ZFIN):         <a href="https://zfin.org/" target="_blank" rel="noopener">https://zfin.org/</a></li><li>DDBJ</li><li>Gramene</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># entrez 下载</span></span><br><span class="line"><span class="comment"># 1. 准备好accession或identifier文件</span></span><br><span class="line"><span class="comment"># 2. 选择数据类型</span></span><br><span class="line"><span class="comment"># 3. 上传准备好的文件, 点击Retrieve按钮获取即可</span></span><br></pre></td></tr></table></figure><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ol><li>水稻的参考基因组和注释</li></ol><ul><li>参考基因组: <a href="http://rice.plantbiology.msu.edu/pub/data/Eukaryotic_Projects/o_sativa/annotation_dbs/pseudomolecules/version_7.0/all.dir/all.con" target="_blank" rel="noopener">http://rice.plantbiology.msu.edu/pub/data/Eukaryotic_Projects/o_sativa/annotation_dbs/pseudomolecules/version_7.0/all.dir/all.con</a></li><li>注释: <a href="http://rice.plantbiology.msu.edu/pub/data/Eukaryotic_Projects/o_sativa/annotation_dbs/pseudomolecules/version_7.0/all.dir/all.gff3" target="_blank" rel="noopener">http://rice.plantbiology.msu.edu/pub/data/Eukaryotic_Projects/o_sativa/annotation_dbs/pseudomolecules/version_7.0/all.dir/all.gff3</a></li></ul><ol start="2"><li>拟南芥</li></ol><ul><li>参考转录组,cDNA<br><a href="ftp://ftp.ensemblgenomes.org/pub/plants/release-28/fasta/arabidopsis_thaliana/cdna/Arabidopsis_thaliana.TAIR10.28.cdna.all.fa.gz" target="_blank" rel="noopener">ftp://ftp.ensemblgenomes.org/pub/plants/release-28/fasta/arabidopsis_thaliana/cdna/Arabidopsis_thaliana.TAIR10.28.cdna.all.fa.gz</a></li><li>参考基因组,genome<br><a href="ftp://ftp.ensemblgenomes.org/pub/plants/release-28/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.28.dna.genome.fa.gz" target="_blank" rel="noopener">ftp://ftp.ensemblgenomes.org/pub/plants/release-28/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.28.dna.genome.fa.gz</a></li><li>注释,gff3<br><a href="ftp://ftp.ensemblgenomes.org/pub/plants/release-28/gff3/arabidopsis_thaliana/Arabidopsis_thaliana.TAIR10.28.gff3.gz" target="_blank" rel="noopener">ftp://ftp.ensemblgenomes.org/pub/plants/release-28/gff3/arabidopsis_thaliana/Arabidopsis_thaliana.TAIR10.28.gff3.gz</a>  </li><li>注释,gtf<br><a href="ftp://ftp.ensemblgenomes.org/pub/plants/release-28/gtf/arabidopsis_thaliana/Arabidopsis_thaliana.TAIR10.28.gtf.gz" target="_blank" rel="noopener">ftp://ftp.ensemblgenomes.org/pub/plants/release-28/gtf/arabidopsis_thaliana/Arabidopsis_thaliana.TAIR10.28.gtf.gz</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>生信基础 常用gene_ID的转换</title>
      <link href="/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E5%B8%B8%E7%94%A8gene_ID%E7%9A%84%E8%BD%AC%E6%8D%A2/"/>
      <url>/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E5%B8%B8%E7%94%A8gene_ID%E7%9A%84%E8%BD%AC%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<h2 id="ID-类型"><a href="#ID-类型" class="headerlink" title="ID 类型"></a>ID 类型</h2><table><thead><tr><th>ID 示例</th><th>ID 来源</th></tr></thead><tbody><tr><td>ENSG00000116717</td><td>Ensemble ID</td></tr><tr><td>GA45A_HUMAN</td><td>UniProtKB/Swiss-Prot, entry name</td></tr><tr><td>A5PJB2_BOVIN</td><td>UniProtKB/TrEMBL, entry name</td></tr><tr><td>A2BC19, P12345,</td><td>A0A022YWF9    UniProt, accession number</td></tr><tr><td>GLA, GLB, UGT1A1</td><td>HGNC Gene Symbol</td></tr><tr><td>U12345, AF123456</td><td>GenBank, NCBI, accession number</td></tr><tr><td>NT_123456, NM_123456, NP_123456</td><td>RefSeq, NCBI, accession number</td></tr><tr><td>10598, 717</td><td>Entrez ID, NCBI</td></tr><tr><td>uc001ett, uc031tla.1</td><td>UCSC ID</td></tr></tbody></table><a id="more"></a><h2 id="1-Ensembl-stable-ID"><a href="#1-Ensembl-stable-ID" class="headerlink" title="1. Ensembl stable ID"></a>1. Ensembl stable ID</h2><p>Ensembl stable ID 的结构是根据不同物种设置的前缀, 加上数据所指的类型, 如基因蛋白质, 再加上一系列的数字. 有的时候可以有不同的版本, 则在 Ensembl ID 后面加上小数点和版本号.</p><p>Ensembl_gene_identifier是Ensembl ID里的一种, Enseml ID包括exon, protein family, gene, gene tree, protein, regulatory feature 和 transcript.</p><p>Ensembl ID的由5部分构成: ENS(species)(object type)(identifier).(version)<br>第一部分ENS代表这是一个Ensembl ID<br>第二部分代表物种, 如MUS代表小鼠(如果物种是人则此处为空)<br>第三部分代表ID的类型, 如G代表基因, T代表转录本, P代表蛋白, E代表外显子, S代表<br>第四部分是一个特殊的数字标志<br>第五部分代表版本号  </p><p>如:ENSMUSG00000017167.6<br>我们知道这是一个Ensembl ID (ENS), 物种为小鼠(MUS), 代表一个基因(G), 并且这是第6个版本(.6).</p><h3 id="物种前缀"><a href="#物种前缀" class="headerlink" title="物种前缀"></a>物种前缀</h3><table><thead><tr><th>物种前缀</th><th>学名</th></tr></thead><tbody><tr><td>ENSCEL</td><td>Caenorhabditis elegans (Caenorhabditis elegans)</td></tr><tr><td>ENSCAF</td><td>Canis lupus familiaris (Dog)</td></tr><tr><td>ENSDAR</td><td>Danio rerio (Zebrafish)</td></tr><tr><td>FB</td><td>Drosophila melanogaster (Fruitfly)</td></tr><tr><td>ENS</td><td>Homo sapiens (Human)</td></tr><tr><td>ENSMUS</td><td>Mus musculus (Mouse)</td></tr><tr><td>ENSRNO</td><td>Rattus norvegicus (Rat)</td></tr><tr><td>ENSXET</td><td>Xenopus tropicalis (Xenopus)</td></tr></tbody></table><h3 id="类型前缀"><a href="#类型前缀" class="headerlink" title="类型前缀"></a>类型前缀</h3><table><thead><tr><th>类型前缀</th><th>类型</th></tr></thead><tbody><tr><td>E</td><td>exon</td></tr><tr><td>FM</td><td>Ensembl protein family</td></tr><tr><td>G</td><td>gene</td></tr><tr><td>GT</td><td>gene tree</td></tr><tr><td>P</td><td>protein</td></tr><tr><td>R</td><td>regulatory feature</td></tr><tr><td>T</td><td>transcript</td></tr></tbody></table><h2 id="2-UniProt"><a href="#2-UniProt" class="headerlink" title="2. UniProt"></a>2. UniProt</h2><p>UniProt中录入的数据都被分配了一个唯一的entry name.</p><ul><li><p>UniProtKB/Swiss-Prot entry name 是最多有 11 位包含大写字母的字符串, 一般有着 “X_Y” 的形式, 其中 “X” 是最多五个便于记忆的蛋白质编号, “_” 是下划线, “Y” 是最多五个便于记忆的物种编号.</p></li><li><p>UniProtKB/TrEMBL entry name 是最多 16 位包含大写字母的字符串, 一般有着 “X_Y” 的形式, 其中 “X” 是 6 到 10 个字符组成的 accession number, “_” 是下划线, “Y” 是最多五个便于记忆的物种编号.</p></li></ul><ul><li>UniProtKB 的 Accession Number 相当于数据库的主键, 由 6 到 10 个大写字母或者数字组成. 其构成规律为: [OPQ][0-9][A-Z0-9]{3}[0-9]|[A-NR-Z]<a href="[A-Z][A-Z0-9]{2}[0-9]">0-9</a>{1,2}</li></ul><h3 id="蛋白质编号示例"><a href="#蛋白质编号示例" class="headerlink" title="蛋白质编号示例"></a>蛋白质编号示例</h3><table><thead><tr><th>Code(X)</th><th>Recommended protein name</th><th>Gene name</th></tr></thead><tbody><tr><td>B2MG</td><td>Beta-2-microglobulin</td><td>B2M</td></tr><tr><td>HBA</td><td>Hemoglobin subunit alpha</td><td>HBA1</td></tr><tr><td>INS</td><td>Insulin</td><td>INS</td></tr><tr><td>CAD17</td><td>Cadherin-17</td><td>CDH17</td></tr></tbody></table><h3 id="物种编号"><a href="#物种编号" class="headerlink" title="物种编号"></a>物种编号</h3><table><thead><tr><th>编号</th><th>物种</th></tr></thead><tbody><tr><td>BOVIN</td><td>Bovine</td></tr><tr><td>CHICK</td><td>Chicken</td></tr><tr><td>ECOLI</td><td>Escherichia coli</td></tr><tr><td>HORSE</td><td>Horse</td></tr><tr><td>HUMAN</td><td>Homo sapiens</td></tr><tr><td>MAIZE</td><td>Maize (Zea mays)</td></tr><tr><td>MOUSE</td><td>Mouse</td></tr></tbody></table><h2 id="3-Gene-Symbol"><a href="#3-Gene-Symbol" class="headerlink" title="3. Gene Symbol"></a>3. Gene Symbol</h2><p>Gene Symbol 是用来表示基因的编码, 由大写字母构成, 或由大写字母和数字构成, 首字母均应该是字母.如: GLA “galactosidase, alpha”; GLB “galactosidase, beta”; UGT1A1 “UDP glycosyltransferase 1 family, polypeptide A1” 再到 UGT1A13 代表了 13 个不同的 gene symbol.</p><h2 id="4-NCBI"><a href="#4-NCBI" class="headerlink" title="4. NCBI"></a>4. NCBI</h2><ul><li>GenBank的通用accession number通常是由一个大写字母加上 5 个数字的组合, 或者两个大写字母加上6个数字的组合.</li><li>RefSeq有一套特殊的Accesion Number.形式是: [A-Z]{2}[_][0-9]{6:},两个大写字母,一个下划线,6个或更多的数字.</li></ul><table><thead><tr><th>Accession</th><th>前缀</th><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>AC_</td><td>Genomic</td><td>Complete genomic molecule, usually alternate assembly</td></tr><tr><td>NC_</td><td>Genomic</td><td>Complete genomic molecule, usually reference assembly</td></tr><tr><td>NG_</td><td>Genomic</td><td>Incomplete genomic region</td></tr><tr><td>NT_</td><td>Genomic</td><td>Contig or scaffold, clone-based or WGS</td></tr><tr><td>NW_</td><td>Genomic</td><td>Contig or scaffold, primarily WGS</td></tr><tr><td>NS_</td><td>Genomic</td><td>Environmental sequence</td></tr><tr><td>NZ_</td><td>Genomic</td><td>Unfinished WGS</td></tr><tr><td>NM_</td><td>mRNA</td><td>none</td></tr><tr><td>NR_</td><td>RNA</td><td>none</td></tr><tr><td>XM_</td><td>mRNA</td><td>Predicted model</td></tr><tr><td>XR_</td><td>RNA</td><td>Predicted model</td></tr><tr><td>AP_</td><td>Protein</td><td>Annotated on AC_ alternate assembly</td></tr><tr><td>NP_</td><td>Protein</td><td>Associated with an NM_ or NC_ accession</td></tr><tr><td>YP_</td><td>Protein</td><td>none</td></tr><tr><td>XP_</td><td>Protein</td><td>Predicted model, associated with an XM_ accession</td></tr><tr><td>ZP_</td><td>Protein</td><td>Predicted model, annotated on NZ_ genomic records</td></tr></tbody></table><h2 id="5-Entrez-ID"><a href="#5-Entrez-ID" class="headerlink" title="5. Entrez ID"></a>5. Entrez ID</h2><p>Entrez 是 NCBI 使用的能够对众多数据库进行联合搜索的搜索引擎, 其对不同的 Gene 进行了编号, 每个 gene 的编号就是 entrez gene id. 由于 entrez id 相对稳定, 所以也被众多其他数据库, 如 KEGG 等采用. Entrez Gene ID 就是一系列数字, 也比较容易辨识. R 或网站都有众多的工具可以帮助从不同的 ID 转换为 entrez id 或者反向转换.</p><h2 id="6-UCSC-ID"><a href="#6-UCSC-ID" class="headerlink" title="6.UCSC ID"></a>6.UCSC ID</h2><p>UCSC ID由小写字母和数字构成, 起始均为 uc, 然后是三位数字, 接着又是三位小写字母, 最后有小数点和数字构成版本号.<br>如: uc010qfk.3, uc010qfk.3.</p><h2 id="7-使用R包org-Hs-eg-db转换ID-org-xx-eg-db"><a href="#7-使用R包org-Hs-eg-db转换ID-org-xx-eg-db" class="headerlink" title="7.使用R包org.Hs.eg.db转换ID(org.xx.eg.db)"></a>7.使用R包org.Hs.eg.db转换ID(org.xx.eg.db)</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 类似数据库查询一样</span></span><br><span class="line"><span class="keyword">library</span>(org.Hs.eg.db)</span><br><span class="line"><span class="comment"># 显示可转换的ID类型</span></span><br><span class="line">keytypes(org.Hs.eg.db)</span><br><span class="line">ids = yourid_vector</span><br><span class="line"><span class="comment"># 你要转换的选项,由keytypes里面选</span></span><br><span class="line">cols &lt;- c(<span class="string">"SYMBOL"</span>, <span class="string">"GENENAME"</span>, <span class="string">'ENTREZID'</span>)</span><br><span class="line">getIDs = select(org.Hs.eg.db, keys=ensids, columns=cols, keytype=<span class="string">"ENSEMBL"</span>)</span><br></pre></td></tr></table></figure><h2 id="8-使用biomaRt包转换"><a href="#8-使用biomaRt包转换" class="headerlink" title="8.使用biomaRt包转换"></a>8.使用biomaRt包转换</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span>(<span class="string">"https://bioconductor.org/biocLite.R"</span>)</span><br><span class="line">biocLite(<span class="string">"biomaRt"</span>)</span><br><span class="line">listMarts()</span><br><span class="line"></span><br><span class="line">ensembl&lt;-useMart(<span class="string">"ENSEMBL_MART_ENSEMBL"</span>)</span><br><span class="line">all_datasets &lt;- listDatasets(ensembl)</span><br><span class="line"></span><br><span class="line"><span class="keyword">library</span>(DT)</span><br><span class="line">datatable(all_datasets,</span><br><span class="line">        options = list(searching = <span class="literal">FALSE</span>,pageLength = <span class="number">5</span>,lengthMenu = c(<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>)))</span><br><span class="line">        </span><br><span class="line">ensembl &lt;- useMart(<span class="string">"ensembl"</span>, dataset = <span class="string">"hsapiens_gene_ensembl"</span>)</span><br><span class="line">filters = listFilters(ensembl)</span><br><span class="line">datatable(filters, options = list(searching = <span class="literal">FALSE</span>,pageLength = <span class="number">5</span>,lengthMenu = c(<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>)))</span><br><span class="line">attributes = listAttributes(ensembl)</span><br><span class="line">datatable(attributes, options = list(searching = <span class="literal">FALSE</span>,pageLength = <span class="number">5</span>,lengthMenu = c(<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>)))</span><br><span class="line">entrez.mart&lt;-getBM(attributes=c(<span class="string">'ensembl_gene_id'</span>, <span class="string">'entrezgene'</span>), filters = <span class="string">'ensembl_gene_id'</span>, values = rownames(fpkmtpens), mart = ensembl)</span><br></pre></td></tr></table></figure><h2 id="9-其他数据库整合包"><a href="#9-其他数据库整合包" class="headerlink" title="9. 其他数据库整合包"></a>9. 其他数据库整合包</h2><p><a href="http://www.bio-info-trainee.com/1399.html" target="_blank" rel="noopener">http://www.bio-info-trainee.com/1399.html</a></p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>生信基础 无重复样本的差异分析</title>
      <link href="/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E6%97%A0%E9%87%8D%E5%A4%8D%E6%A0%B7%E6%9C%AC%E7%9A%84%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/"/>
      <url>/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E6%97%A0%E9%87%8D%E5%A4%8D%E6%A0%B7%E6%9C%AC%E7%9A%84%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<ul><li>edgeR</li><li>DESeq2</li><li>GFOLD</li></ul><a id="more"></a><h2 id="1-no-replicates-with-edgeR"><a href="#1-no-replicates-with-edgeR" class="headerlink" title="1. no replicates with edgeR"></a>1. no replicates with edgeR</h2><p>当没有重复样本时,edgeR给出了以下四条建议,这并不是说以下建议是完美的.而且他也不推荐以这种方式来替代样本的重复.此外,最好是在数据分析的阶段执行以下建议,2-4条建议最好是在没有生物差异时使用.</p><ol><li><p>只画一个MDS-plot图,统计分析一下fold change, 但是不做差异性分析.</p></li><li><p>根据以往类似实验的经验,选择一个可信的离散值(dispersion vlaue),用这个离散值做exactTest和glmFit. Typical values for the common BCV (square-root-dispersion) for datasets arising from well-controlled experiments are 0.4 for human data, 0.1 for data on genetically identical model organisms or 0.01 for technical replicates.</p></li></ol><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bcv &lt;- <span class="number">0.2</span></span><br><span class="line">counts &lt;- matrix(rnbinom(<span class="number">40</span>, size=<span class="number">1</span>/bcv^<span class="number">2</span>,num=<span class="number">10</span>), <span class="number">20</span>, <span class="number">2</span>)</span><br><span class="line">y &lt;- DGEList(counts=counts, group=<span class="number">1</span>:<span class="number">2</span>)</span><br><span class="line">et &lt;- exactTest(y, dispersion=bcv^<span class="number">2</span>)</span><br></pre></td></tr></table></figure><ol start="3"><li>把某个/些可解释的因子从线性模型里面移除</li><li>从大量稳定转录的转录本数据中估测离散值,用这个离散值进行统计.</li></ol><h2 id="2-DESeq2"><a href="#2-DESeq2" class="headerlink" title="2.DESeq2"></a>2.DESeq2</h2><p>由于差异分析基于离散度的负二项分析方法,没有重复样本时的离散度计算不准确,DESeq2已经不支持无重复样本的差异分析.</p><h2 id="3-GFOLD"><a href="#3-GFOLD" class="headerlink" title="3.GFOLD"></a>3.GFOLD</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gfold diff -s1 Sample1.count -s2 Sample2.count -o Sample1VSSample2.diff</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>生信基础 测序原理</title>
      <link href="/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E6%B5%8B%E5%BA%8F%E5%8E%9F%E7%90%86/"/>
      <url>/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E6%B5%8B%E5%BA%8F%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>在生信分析中，我们通常接触的都是下机数据，也就是测序的结果数据，但是这些数据是怎么产生的呢？这就要讲到测序的原理。其实，测序的本质原理就是DNA链的合成咯，通过合成新的 DNA 链我们从而知道 DNA 链的序列组成。一代测序的 sanger 法是通过每步添加一种特定标记的双脱氧核糖核苷酸( ddNTP )来合成 DNA 链，由于 ddNTP 会导致 DNA 链合成的中断，那就可以得到各个长度大小的 DNA 片段，通过跑胶分离则可知道不同DNA长度的链上分别是什么标记，由此知道其标记对应的 ddNTP，从而推出 DNA 的序列组成；这类一代测序法过程比较耗时。而二代测序的改进在于，它是边合成边测序的，无需后续的跑胶等实现；DNA 合成的数量巨大，也就使得测序过程也更为快速。在如今市场上，二代测序虽然说有许多平台，如 Illumina，Roche 454、Ion Torrent，但市场上一直是 Illumina 占据主导地位。所以我们这里将说明一下 Illumina 的测序过程。</p><a id="more"></a><h2 id="Illumina-的测序过程"><a href="#Illumina-的测序过程" class="headerlink" title="Illumina 的测序过程"></a>Illumina 的测序过程</h2><p>Illumina 的测序原理基本上可以采用这几个关键词来概括：桥式 PCR，可逆阻断技术；其测序过程基本可以分为三个阶段，library preparation，cluster，sequencing。在建库之前，我们需要对样品进行预处理。</p><h3 id="sample-preprocessing"><a href="#sample-preprocessing" class="headerlink" title="sample preprocessing"></a>sample preprocessing</h3><p>在这一步，主要是对样品进行处理筛选，把不符合测序要求的低质量样品排除，以免影响测序结果。进行测序的样品主要有以下要求。</p><ul><li>样品DNA最好是单倍体，避免等位基因与测序错误相混淆（但这个似乎很难把控）</li><li>DNA的纯度要高，OD值</li><li>DNA要避免降解，以防影响打断片段的大小</li><li>DNA的样品量要满足基本的建库需求</li></ul><h3 id="library-preparation"><a href="#library-preparation" class="headerlink" title="library preparation"></a>library preparation</h3><p>在建库的过程中，也可以粗略打断、添加 adapter 。<br>首先是对 DNA 进行打断，使其片段化（fragment）。基本方法有超声法，机械法和酶解法，其打断后的 DNA fragment 大小一般分别是 500,150,300，在实际应用中，一般使用的是超声法。我们应该注意，500 的片段大小是指打断后的大部分片段都是在 500bp 附近。这 个DNA fragment length 我们也称之为insertSize。<br>其次是添加 adapter。在添加 adapter 之前，需要给 DNA fragment 进行末端补齐，然后加上一个 A 碱基，使其变为黏性末端；随后通过该黏性末端添加上 adapter 。至此文库制备完成。</p><h3 id="cluster"><a href="#cluster" class="headerlink" title="cluster"></a>cluster</h3><p>在制备好文库以后，需要将文库样品上样至 flowcell 中。flowcell的具体情况可看下图(<a href="https://imgchr.com/i/PAg4o9)。" target="_blank" rel="noopener">https://imgchr.com/i/PAg4o9)。</a></p><p><img src="https://s1.ax1x.com/2018/07/02/PAg4o9.png" alt="flowcell"></p><p>在 flowcell 的 tile 上锚定了大量的 DNA 短序列，这些DNA短序列能与 adapter 进行互补配对。在我们上样后，添加了 adapter 的 DNA fragment 可被这些 tile 上的序列捕捉锚定。在洗脱多余的 DNA fragment 后，改变缓冲液，使得被锚定的 DNA fragment 的另一端也被锚定，从而导致 DNA fragment 形成拱形，这也是桥式PCR的由来。基于此，DNA fragment 被扩增，形成了 DNA fragment cluster。此举可使得每个 DNA fragment cluster 组成一致成分单一但数目巨大，为后续测序做准备。最后，加入对应的酶将DNA链的反向链切除（酶切位点在反向 adapter 上），使得 DNA fragment 正向链剩余。</p><h3 id="sequencing"><a href="#sequencing" class="headerlink" title="sequencing"></a>sequencing</h3><p>测序的过程是边合成边测序的。在加入正向 adapter 的对应引物后，加入经过处理后的 ATCG，使其进行合成，在合成的过程中收集信号。ATCG 经过的处理有：其一是核苷酸的 3‘ 位置加入叠氮基团，以使每次反应序列只增长一个碱基；其次是对核苷酸进行荧光标记。该过程则是：序列增长一个碱基，激发荧光；收集荧光信号；加入试剂后洗脱；如此循环。加入试剂的作用有两点，其一是把叠氮基团去掉，使得 DNA 链可以继续延长；其二是切除荧光标记以防影响后续信号收集。</p><h2 id="各代测序技术的比较"><a href="#各代测序技术的比较" class="headerlink" title="各代测序技术的比较"></a>各代测序技术的比较</h2><h3 id="一代测序"><a href="#一代测序" class="headerlink" title="一代测序"></a>一代测序</h3><p>一代测序采用的是 sanger 法测序，在DNA复制过程中采用单种染料特异标记的双脱氧核糖核酸作为原料，但该类核酸会终止延长反应；进而导致 DNA 的复制链长短不一、末端碱基则分别为对应的双脱氧核酸。在电泳后，长短不同的 DNA 电泳位置不同，携带染料不同，则被有效地鉴别出来。因为涉及到电泳鉴别，时间长，基本无法做到高通量。</p><h3 id="二代测序"><a href="#二代测序" class="headerlink" title="二代测序"></a>二代测序</h3><p>二代测序的基本原理是多分子、多克隆同时进行，荧光成像。可分为三类：Illumina、Roche 454、Ion Torrent。Illumina 将桥式 PCR、四色荧光可逆终止和激光扫描成像结合起来，DNA 每延长 1 个碱基成像一次，最终根据成像荧光颜色获得 DNA 序列；它能测量同聚物的准确长度；但其读长较短（200-500bp，这是因为测序过程中由测序不同步产生的杂信号越来越多、酶活性也越来越不稳定造成）。Roche 454 则使用油包水 PCR、dNTP 轮番使用、焦磷酸水平发光的原理进行测序；其平均测序长度达 400bp，但它无法准确检测多聚物的个数，会引入插入和缺失。Ion Torrent 则是将 Roche 454 的焦磷酸测序更改为微电极 pH 检测，无需发光成像检测，检测体积小、简单、时间短；但其通量无法与前二者相比，适合小基因组和外显子验证测序。</p><h3 id="三代测序"><a href="#三代测序" class="headerlink" title="三代测序"></a>三代测序</h3><p>三代测序保持了测序速度和通量，并使读长大幅度上升，可达 1000bp 以上，它不用进行 PCR 扩增，基于单分子测序，目前有三类：Oxford nanopore、PacBio SMRT和Helicosope。Oxford 的测序是基于纳米孔内的分子接头，当碱基通过纳米孔时，孔内的电荷环境发生变化，分子接头可捕获电流强度的变化，进而得到碱基组成；其读长一般在几十 kb，30x 人类基因组在一天左右完成，保持输入 DNA 的完整性，还可直接测序 RNA；但其错误率较高。PacBio 采用的是纳米孔和荧光可逆终止 dNTP 技术，活性久高保真的聚合酶大大提高了边合成边测序的读长，可达 10kb，但它同样具有较高的随机错误率。Heliscope 基于边合成边测序的思想，将 DNA 随机打断成小片段分别进行 dNTP 荧光标记，经过不断地重复合成、洗脱、成像、淬灭过程完成测序。</p><h2 id="相关-FAQ"><a href="#相关-FAQ" class="headerlink" title="相关 FAQ"></a>相关 FAQ</h2><h3 id="1-GC-bias-的影响"><a href="#1-GC-bias-的影响" class="headerlink" title="1. GC bias 的影响"></a>1. GC bias 的影响</h3><p>由于GC的含量多少会影响PCR过程的偏好性（PCR bias），从而会导致某些原始 DNA 序列不被扩增或者扩增减少，这些序列可能会无法测序到。</p><h3 id="2-read-length-和insert-size-的选择"><a href="#2-read-length-和insert-size-的选择" class="headerlink" title="2. read length 和insert size 的选择"></a>2. read length 和insert size 的选择</h3><p>首先我们要明白的是，read length 是测序仪的测序长度，也就是读长；而 insert size 是指构建文库时 DNA 被打断后的大小（文库片段大小）；而 fragment size 是片段加上了 adapter 后的大小。一般来说，这二者是相适应协调的。例如进行 denovo 拼接的话，我们应当优先选用小片段文库，然后逐渐提高。而在进行 RNA-seq 时，我们应该选择较小的文库，较低的读长以保证准确性。</p><h3 id="3-为何-Illumina-只能测-150bp？"><a href="#3-为何-Illumina-只能测-150bp？" class="headerlink" title="3. 为何 Illumina 只能测 150bp？"></a>3. 为何 Illumina 只能测 150bp？</h3><p>这是因为随着反应的进行，反应底物减少、酶的活性降低，DNA 扩增时的准确性降低，杂信号会越来越多。<br>Phasing：酶活性不行了。。。<br>Pre-phasing：叠氮基团没发挥作用。</p><h3 id="4-adapter-barcode-index-的作用"><a href="#4-adapter-barcode-index-的作用" class="headerlink" title="4. adapter,barcode,index 的作用"></a>4. adapter,barcode,index 的作用</h3><p>adapter 的作用有二：一是将文库片段与 flowcell 上的锚点固定；二是作为桥式 PCR 的扩增引物。在建库过程中，基本顺序是 adapter1-Index-fragment-adapter2，而 adapter2 则与 flowcell 上的锚点 oligoDT 互补结合。桥式 PCR 之后的测序，所用 primer 的序列是与 Index 互补的而非 adapter1 。<br>由于二代测序一次上机可得到约 30G 的数据,而通常一个样品测序数据量不需要那么多,所以会把多个样品混杂在一起测序(混池测序), index/barcode 就是用于区分不同样品的标签序列。</p><h3 id="5-adapter的获取"><a href="#5-adapter的获取" class="headerlink" title="5. adapter的获取"></a>5. adapter的获取</h3><p>Illumina: <a href="https://support.illumina.com/downloads/illumina-customer-sequence-letter.html" target="_blank" rel="noopener">https://support.illumina.com/downloads/illumina-customer-sequence-letter.html</a><br>cutadapt软件内置<br>trimmomatic内置</p><h3 id="6-测序深度与覆盖度的区别"><a href="#6-测序深度与覆盖度的区别" class="headerlink" title="6.测序深度与覆盖度的区别"></a>6.测序深度与覆盖度的区别</h3><p><strong>测序深度</strong>: 在测序后,指定区域得到的测序碱基数目除以该区域的碱基长度就是测序深度.就拿人的全基因组测序来讲,它的大小是30亿的碱基长度(3G),而测序得到了8.9亿条的150bp的reads.那么平均测序深度就是8.9亿*150/30亿=45,简称45x.<br><strong>覆盖度</strong>：在测序后,测序获得的序列占整个基因组或指定区域的比例.由于基因组中的高GC、重复序列等复杂结构的存在，测序最终拼接组装获得的序列往往无法覆盖有所的区域，这部分没有获得的区域就称为Gap。</p><h3 id="7-各种组"><a href="#7-各种组" class="headerlink" title="7.各种组"></a>7.各种组</h3><p><strong>外显子组</strong>, exome, 是指真核生物基因组中全部外显子区域的总和，包含了蛋白质合成最直接的信息。外显子 组测序（Exome-seq）是利用设计好的探针试剂盒将坐标已知的全基因组外显子区域的 DNA 捕捉并富集后，进行高通量测序的基因组分析方法。 对于人类基因组来说，外显子区域大概占到基因组的1%，大概在 30M 左右.一般全外显子测序的测序深度为 50X~200X.</p><p><strong>转录组</strong>, RNA-seq, 是指在相同环境（或生理条件）下的在一个细胞、或一群细胞中所能转录出的所有RNA的总和，包括信 使RNA（mRNA）、核糖体 RNA（rRNA）、转运 RNA（tRNA）及非编码 RNA。转录组测序（RNA-seq）是将提取所要研究的特定类型的 RNA，将其反转录成 cDNA，利用高通量测序技术获得某一物种特定组织或器官在某一状态下的几乎所有转录本序列信息。</p><p><strong>染色质免疫共沉淀</strong>, CHIP-seq, 主要用于蛋白质与 DNA 相互作用研究，采用特异抗体对目的蛋白进行免疫沉淀，分离与目的蛋白结合的基因组DNA片段，对其进行纯化和文库构建，再通过高通量测序的方法，在全基因组范围内寻找目的蛋白的DNA结合位点，从而获得全基因组范围内与组蛋白、转录因子等互作的 DNA 片段信息。（与外显子测序不一样，不是通过设计好的探针来捕获序列的，而是通过特异的 RNApoly 酶、组蛋白、转录因子来捕获序列的，蛋白结合在哪里就捕获哪里。每做一次实验，换一个蛋白，所捕获的序列是不一样的。）因此其主要研究点——研究用不同组蛋白、转录因子等不同蛋白来做不同的实验，找出互作的 DNA 序列的不同。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;mid=2247484311&amp;idx=1&amp;sn=7845d8341562531e968598da685b38a4&amp;chksm=9b48432cac3fca3aed2d57cc12d94eb58c6fce4e5aa698b7a2d0f261cadd2d9f7121635f5e52&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">各种组</a></p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>生信基础 生信数据格式汇总</title>
      <link href="/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E7%94%9F%E4%BF%A1%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E6%B1%87%E6%80%BB/"/>
      <url>/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E7%94%9F%E4%BF%A1%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="Fastq和Fasta格式"><a href="#Fastq和Fasta格式" class="headerlink" title="Fastq和Fasta格式"></a>Fastq和Fasta格式</h2><h3 id="FASTA"><a href="#FASTA" class="headerlink" title="FASTA"></a>FASTA</h3><p>Fasta格式是存储序列相关信息的一种格式，包含两个部分。Fasta第一个部分是以“&gt;”开头的一行。以序列来源、序列ID为值对，用竖线“|”进行分隔。在最后竖线处，以空格分开，添加序列相关描述。第二部分是序列的详细信息，多数为序列组成。其基本形式如下：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;ENSEMBL|geneID|source2|geneID description</span><br><span class="line">序列ATCG</span><br></pre></td></tr></table></figure><a id="more"></a><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;gi|<span class="number">13650073</span>|gb|AF349571.1| Homo sapiens hemoglobin alpha-<span class="number">1</span> globin chain (HBA1) mRNA, complete cds</span><br><span class="line">ATCGATCGATCGATCG...</span><br><span class="line"></span><br><span class="line"><span class="comment"># gi|13650073 基因ID</span></span><br><span class="line"><span class="comment"># gb|AF349571.1 genebank编号</span></span><br><span class="line"><span class="comment"># Homo sapiens hemoglobin alpha-1 globin chain (HBA1) 基因名称</span></span><br><span class="line"><span class="comment"># mRNA, complete cds 序列类型</span></span><br></pre></td></tr></table></figure><h3 id="FASTQ"><a href="#FASTQ" class="headerlink" title="FASTQ"></a>FASTQ</h3><p>Fastq格式是Fasta的一种补充集合格式。由于Fasta格式文件一般不包含序列中碱基质量信息，往往需要额外的一个质量文件。而Fastq格式文件则将这二者综合起来；一个Fastq文件格式亚单位由四行构成。第一行是基本序列信息，由“@”符号开头提示。第二行是序列碱基组成字符。第三行是额外补充信息，由“+”开头提示。第四行是测序碱基的质量值，与第二行的每个字符一一相对应。其基本形式如下：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">line1:  @sequence-ID description</span><br><span class="line">line2:  ATCGATCG...</span><br><span class="line">line3:  +description</span><br><span class="line">line4:  Qualityvalue</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">@ST-E00126:<span class="number">128</span>:HJFLHCCXX:<span class="number">2</span>:<span class="number">1101</span>:<span class="number">7405</span>:<span class="number">1133</span></span><br><span class="line">ATCGATCG…..</span><br><span class="line">+</span><br><span class="line">Aliclisjlgij922jida</span><br><span class="line"></span><br><span class="line"><span class="comment"># @，开始的标记符号;</span></span><br><span class="line"><span class="comment"># ST-E00126:128:HJFLHCCXX，测序仪唯一的设备名称;  </span></span><br><span class="line"><span class="comment"># 2，lane的编号;           </span></span><br><span class="line"><span class="comment"># 1101，tail的坐标;</span></span><br><span class="line"><span class="comment"># 7405，在tail中的X坐标;</span></span><br><span class="line"><span class="comment"># 1133，在tail中的Y坐标</span></span><br></pre></td></tr></table></figure><h3 id="phred质量值"><a href="#phred质量值" class="headerlink" title="phred质量值"></a>phred质量值</h3><p>由于在测序过程中，信号有强弱，这就导致测序所得碱基与真实碱基之间有偏差的可能；为了衡量这种与实际之间的差异，就出现了phred质量值。Phred质量值指代在某个位点的碱基测序出现错误的可能性（机率）。例如某个碱基测序的错误机率为0.001，那么对该值取log对数值的十倍负值，则可得到phred质量值，如此，质量值越大，代表者测序出错的几率越小。计算公式如下：</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Qphred，<span class="number">0.001</span>=-<span class="number">10</span>*log10(<span class="number">0.001</span>)=<span class="number">30</span></span><br></pre></td></tr></table></figure><p>但是，每次测序存储数据的内存占用很大，又要额外的内存存储诸如30一类的2位数数字；因此为了简化存储，便将这类质量值与ASCLⅡ对应的字符一一对应起来，实现单个字符显示质量值。在现有版本中，由于fastq格式文件单位首行以\@符号开头，其ASCII值为33；当有碱基的质量值为33时，其质量值字符就与首行提示符\@相冲突。为了避免这种冲突，便将实际质量值加上33作为ASCII码对应字符，这就是Phred33。如果实际质量值加上64则是Phred64。<br>通过测序所得的原始下机数据因为要包含测序质量信息，这类数据使用fastaq文件格式就更为方便；而经过拼接组装、翻译后的碱基序列、蛋白序列，并没有质量信息，使用fasta格式则较合适。</p><table><thead><tr><th>平台</th><th>质量值</th><th>具体值</th><th>ASCII</th></tr></thead><tbody><tr><td>sanger</td><td>phred + 33</td><td>0-93</td><td>33-126</td></tr><tr><td>solexa</td><td>solexa + 64</td><td>-5-62</td><td>59-126</td></tr><tr><td>illumina~1.8</td><td>phred + 64</td><td>0-62</td><td>64-126</td></tr><tr><td>illumina1.8+</td><td>phred + 33</td><td>0-94</td><td>32-126</td></tr></tbody></table><h2 id="SAM和BAM格式"><a href="#SAM和BAM格式" class="headerlink" title="SAM和BAM格式"></a>SAM和BAM格式</h2><p><a href="https://wikis.utexas.edu/display/bioiteam/Variant+calling+using+SAMtools" target="_blank" rel="noopener">利用samtools进行variant calling</a></p><p>SAM是sequence alignment/map format的简称，用于存储序列比对的信息；而BAM是SAM文件的二进制格式，取自binary of SAM。该文件由两部分组成，一部分是以@开头的注释行，另一部分是比对结果部分。查看 FLAG 的具体对应信息，可以在 <a href="https://broadinstitute.github.io/picard/explain-flags.html" target="_blank" rel="noopener">https://broadinstitute.github.io/picard/explain-flags.html</a> 中进行。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">注释行部分：以@开头进行注释。如：</span><br><span class="line">@HD 说明符合标准的版本、对比序列的排列顺序</span><br><span class="line">@SQ 参考序列的说明</span><br><span class="line">@PG 使用的比对程序</span><br><span class="line">@LN 参考序列的长度</span><br><span class="line"></span><br><span class="line">比对结果部分</span><br><span class="line">column <span class="number">1</span>: query name, 比对片段的编号</span><br><span class="line">column <span class="number">2</span>: FLAG，表明比对的情况</span><br><span class="line">column <span class="number">3</span>：比对上的染色体号</span><br><span class="line">column <span class="number">4</span>：POS，比对上的位置</span><br><span class="line">column <span class="number">5</span>：MAPQ，比对的质量</span><br><span class="line">column <span class="number">6</span>：CIGAR，Concise IdiosyncraRc Gapped Alignment Report. 记录插入，删除，错配以及splice junctions（后剪切拼接的接头）</span><br><span class="line">column <span class="number">7</span>：MRNM，chr，下一个片段比对上的参考序列的编号</span><br><span class="line">column <span class="number">8</span>：mate pos，下一个片段比对上的位置</span><br><span class="line">column <span class="number">9</span>：ISIZE，模版的长度</span><br><span class="line">column <span class="number">10</span>：序列片段的序列信息，read序列</span><br><span class="line">column <span class="number">11</span>：read质量</span><br><span class="line">column <span class="number">12</span>：程序用的标记，可选区域</span><br><span class="line"></span><br><span class="line"><span class="comment"># sam to bam</span></span><br><span class="line">samtools view -bS input.sam &gt; output.bam</span><br></pre></td></tr></table></figure><p><img src="https://s1.ax1x.com/2018/07/04/PEHkNV.png" alt="SAM records"></p><h2 id="GTF-GFF格式"><a href="#GTF-GFF格式" class="headerlink" title="GTF/GFF格式"></a>GTF/GFF格式</h2><p>GTF和GFF是用来存储基因和基因组注释信息的文件格式，共有9列信息。<br>其中，GFF的type必需注明，attribute的名称和值要以空格分开。<br>GTF的attribute则是以‘=’分开。<br>我们可以使用cufflinks、gffread、gff2gtf对二者进行转换。  </p><p><a href="https://zhuanlan.zhihu.com/p/36065699" target="_blank" rel="noopener">该格式文件的下载方法</a></p><table><thead><tr><th>格式</th><th>列1</th><th>列2</th><th>列3</th><th>列4</th><th>列5</th><th>列6</th><th>列7</th><th>列8</th><th>列9</th></tr></thead><tbody><tr><td>GFF</td><td>seqID</td><td>source</td><td>type</td><td>start</td><td>end</td><td>score</td><td>strand</td><td>phase</td><td>attributes</td></tr><tr><td>GTF</td><td>seqName</td><td>souce</td><td>start</td><td>end</td><td>feature</td><td>score</td><td>strand</td><td>frame</td><td>attrbuites</td></tr></tbody></table><h2 id="Bigwig-wiggle"><a href="#Bigwig-wiggle" class="headerlink" title="Bigwig/wiggle"></a>Bigwig/wiggle</h2><ul><li>wiggle track format(wig): <a href="http://genome.ucsc.edu/goldenPath/help/wiggle.html" target="_blank" rel="noopener">http://genome.ucsc.edu/goldenPath/help/wiggle.html</a></li><li>bigwig track format(bigwig): <a href="http://genome.ucsc.edu/goldenPath/help/bigWig.html" target="_blank" rel="noopener">http://genome.ucsc.edu/goldenPath/help/bigWig.html</a></li><li>bedgraph track format(bdg): <a href="http://genome.ucsc.edu/goldenPath/help/bedgraph.html" target="_blank" rel="noopener">http://genome.ucsc.edu/goldenPath/help/bedgraph.html</a></li></ul><p>wig,bigwig,bedgraph 格式文件的作用是追踪参考基因组的各个区域的覆盖度,测序深度, 可以上传到UCSC的genome browser进行可视化.bigwig是wig的二进制版本. 下方是一个wig文件的示例,它只会在前面标明当前染色体一次(chrom=chr1), 测序深度统计的区间间隔是10.<br>bedgraph是对bed文件的拓展, 是只有4列的BED格式,不过有额外的属性关键字.值得注意的是, bedgraph文件里面的染色体坐标是从0开始的, 坐标终点是个开区间.  </p><p>对于wig,bw,bdg,gtf,gff等各种文件的转换,可以使用<a href="http://barcwiki.wi.mit.edu/wiki/SOPs/coordinates" target="_blank" rel="noopener">这个网站</a>的脚本.如果是SE的比对文件,可以直接使用下面的命令. 在UCSC的ftp站点中也可以直接下载这类格式的文件.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sample.wig</span></span><br><span class="line">track <span class="built_in">type</span>=<span class="built_in">print</span> wiggle_0 name=hek  description=hek</span><br><span class="line">variableStep chrom=chr1 span=10</span><br><span class="line">10008    7</span><br><span class="line">10018    14</span><br><span class="line">10028    27</span><br><span class="line"></span><br><span class="line"><span class="comment"># sample.bedgraph</span></span><br><span class="line">track <span class="built_in">type</span>=bedGraph name=<span class="string">"hek_treat_all"</span> description=<span class="string">"Extended tag pileup from MACS version 1.4.2 20120305"</span></span><br><span class="line">chr1    9997    9999    1</span><br><span class="line">chr1    9999    10000   2</span><br><span class="line">chr1    10000   10001   4</span><br></pre></td></tr></table></figure><h3 id="wig-bigwig-bdg的常见转换工具"><a href="#wig-bigwig-bdg的常见转换工具" class="headerlink" title="wig,bigwig,bdg的常见转换工具"></a>wig,bigwig,bdg的常见转换工具</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SE.bam to bdg</span></span><br><span class="line">macs2 pileup --extsize 200 -i sample.bam -o sample.bdg</span><br><span class="line"></span><br><span class="line">bigwigToBedGraph</span><br><span class="line">bigWigToWig</span><br><span class="line">bigWigSummary</span><br><span class="line">bigWigAverageOverBed</span><br><span class="line">bigWigInfo</span><br></pre></td></tr></table></figure><h2 id="VCF格式"><a href="#VCF格式" class="headerlink" title="VCF格式"></a>VCF格式</h2><p>vcf(variant calling format)格式文件用来存储与突变相关的信息。它由两部分组成。<br>第一部分：头行（vcf header）,以##开头，有文件格式，使用软件信息，参考序列信息，重叠群（contig）的相关信息（拼接时reads之间的overlap区域）等等。<br>第二部分：具体的突变信息，共有<strong>八列</strong>。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> CHROM染色体名称（chromosome）,哪一个参考序列上发现了突变，如MAL1 </span><br><span class="line"><span class="number">2</span> POS参考基因组上发生突变的位置，以<span class="number">1</span>开始计算，如<span class="number">265854</span> </span><br><span class="line"><span class="number">3</span> ID突变的ID,如果在dbSNP中有该SNP的id,则给出;否则为<span class="string">'.'</span>,表示是新的variant</span><br><span class="line"><span class="number">4</span> REF参考序列上的碱基, 必需是ATCGN之一,N表示不确定.</span><br><span class="line"><span class="number">5</span> ALT与参考碱基相比,发生突变的碱基.如REF是G, 而这里是C</span><br><span class="line"><span class="number">6</span> QUAL发生突变的碱基质量, 质量越高则是真实variant的可能性越大.如<span class="number">6.2</span>.</span><br><span class="line"><span class="number">7</span> FILTER过滤后的状态,如果variant通过GATK的过滤,值为pass.</span><br><span class="line"><span class="number">8</span> INFOvariant的详细信息</span><br><span class="line"></span><br><span class="line">详细信息含：</span><br><span class="line">DP 该位置的read覆盖度(reads有经过过滤)</span><br><span class="line">MQ比对到该位置reads质量值的均方值(RMS Mapping Quality)</span><br><span class="line">FQ 质量值,表征所有样本相似的可能性</span><br><span class="line">AF1 AF1/<span class="number">2</span>表示等位基因发生频率的可能性评估,<span class="number">1</span>为第一个等位基因的频率</span><br><span class="line">AC1 AC1/<span class="number">2</span>表示等位基因出现数目的可能性评估</span><br><span class="line">AN 等位基因的总数目</span><br><span class="line">IS 插入缺失或部分插入缺失的reads所允许的最大数目</span><br><span class="line">INDEL表明这个variant是插入缺失</span><br><span class="line">QBD测序深度对碱基质量的影响</span><br><span class="line">其他(http://www.bio-info-trainee.com/<span class="number">863.</span>html)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://asia.ensembl.org/info/website/glossary.html" target="_blank" rel="noopener">Ensembl</a></li><li><a href="http://genome.ucsc.edu/FAQ/FAQformat.html" target="_blank" rel="noopener">UCSC</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>生信基础 质控的那些事</title>
      <link href="/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E8%B4%A8%E6%8E%A7%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
      <url>/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E8%B4%A8%E6%8E%A7%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="质控的方向"><a href="#质控的方向" class="headerlink" title="质控的方向"></a>质控的方向</h2><p>就平常的生物实验而言，质控是要贯穿到实验的各个阶段的，比如那些阳性阴性对照就可以认为是在进行质控了。而在测序数据的分析过程中，也同样需要将质控贯穿到分析的各个阶段。质控基本上可以分为三个阶段，依据你的分析对象和分析目的不同而有所变化：raw sequence data, alignment, variant calling. 目前比较常见的质控多是局限在raw data的质控这个阶段。虽然如此，另外两个阶段的质控也应该是需要的，因为后续的许多分析也是基于这两个阶段。Raw data 质控的方向通常有以下几类：quality trimming, adapter removal, contaminant filtering. 而在alignment阶段，我们可以通过uniquely mapped reads, signed noise ratio 进行质控。在variant calling阶段，还在调查中……</p><a id="more"></a><h2 id="QC-of-Raw-data"><a href="#QC-of-Raw-data" class="headerlink" title="QC of Raw data"></a>QC of Raw data</h2><h3 id="FastQC质量统计"><a href="#FastQC质量统计" class="headerlink" title="FastQC质量统计"></a>FastQC质量统计</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastqc /path/*.fastq.gz -o /path/QC_result/</span><br></pre></td></tr></table></figure><h3 id="质控条件"><a href="#质控条件" class="headerlink" title="质控条件"></a>质控条件</h3><ul><li>去除非测序序列：adapter、primer、barcode、index</li><li>去除低质量reads：低于Q20、Q30的碱基占比达30%</li><li>去除含N过多reads: 占比达10%</li><li>去除重复序列：RNA-seq、16s-seq一般不做去除</li><li>去除3’端质量Q低于10的碱基，即碱基错误率为0.1</li><li>去除较短长度reads：低于25的去除</li><li>根据分析结果, 适当地重复上面某些步骤</li></ul><h3 id="使用Trimmomatic修剪reads"><a href="#使用Trimmomatic修剪reads" class="headerlink" title="使用Trimmomatic修剪reads"></a>使用Trimmomatic修剪reads</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">trimmomatic PE read1.fq.gz  read2.fq.gz \</span><br><span class="line">    clean_paired_forward.fq.gz clean_unpaired_forward.fq.gz \</span><br><span class="line">    clean_paired_reverse.fq.gz clean_unpaired_reverse.fq.gz \</span><br><span class="line">    ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 \</span><br><span class="line">    LEADING:4 TRAILING:5 SLIDINGWINDOW:4:5 MINLEN:25 &amp;</span><br><span class="line"><span class="comment"># ILLUMINACLIP:adpater存在.fa文件中，允许2个错配；回文模式下匹配阈值;；简单模式下匹配阈值</span></span><br><span class="line"><span class="comment"># LEADING：切除首端质量值小于4的碱基</span></span><br><span class="line"><span class="comment"># TRAILING: 切除末端质量小于5的碱基</span></span><br></pre></td></tr></table></figure><h3 id="使用cutadapt-修剪-reads"><a href="#使用cutadapt-修剪-reads" class="headerlink" title="使用cutadapt 修剪 reads"></a>使用cutadapt 修剪 reads</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cutadapt -a ADAPTER_FWD -A ADAPTER_REV -o out.1.fastq -p out.2.fastq reads.1.fastq reads.2.fastq</span><br></pre></td></tr></table></figure><h3 id="fastx-toolkit-个性化清洗和过滤"><a href="#fastx-toolkit-个性化清洗和过滤" class="headerlink" title="fastx_toolkit 个性化清洗和过滤"></a>fastx_toolkit 个性化清洗和过滤</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fastq_quality_filter -q 30 -p 80 -z -i input.fastq -o out.fastq</span><br><span class="line"><span class="comment"># input.fastq不支持gz，可以如下,使用-c保留源文件</span></span><br><span class="line">gunzip -c input.fastq.gz | fastq_quality_filter ....etc....</span><br></pre></td></tr></table></figure><h3 id="multiqc"><a href="#multiqc" class="headerlink" title="multiqc"></a>multiqc</h3><h3 id="fastp"><a href="#fastp" class="headerlink" title="fastp"></a>fastp</h3><p>据说是一步到位</p><h2 id="另外两个阶段的质控"><a href="#另外两个阶段的质控" class="headerlink" title="另外两个阶段的质控"></a>另外两个阶段的质控</h2><p>在比对阶段和变异检测阶段的质控软件不多，已有的软件通常都包含了这两个阶段的质控，所以合并起来。</p><h3 id="使用RSeQC进行质控"><a href="#使用RSeQC进行质控" class="headerlink" title="使用RSeQC进行质控"></a>使用RSeQC进行质控</h3><p><a href="http://rseqc.sourceforge.net/#usage-information" target="_blank" rel="noopener">http://rseqc.sourceforge.net/#usage-information</a><br>该软件的input格式有SAM、BAM、Fasta、BED</p><table><thead><tr><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>bam2fq.py</td><td>bam2wig.py</td><td>bam_stat.py</td><td>insertion_profile.py</td></tr><tr><td>clipping_profile.py</td><td>deletion_profile.py</td><td>divide_bam.py</td><td>infer_experiment.py</td></tr><tr><td>FPKM_count.py</td><td>eneBody_coverage.py</td><td>geneBody_coverage2.py</td><td>inner_distance.py   </td></tr><tr><td>junction_annotation.py</td><td>junction_saturation.py</td><td>mismatch_profile.py</td><td>overlay_bigwig.py</td></tr><tr><td>normalize_bigwig.py</td><td>read_distribution.py</td><td>read_duplication.py</td><td>read_GC.pyread_hexamer.py</td></tr><tr><td>read_NVC.py</td><td>read_quality.py</td><td>RNA_fragment_size.py</td><td>RPKM_count.py</td></tr><tr><td>RPKM_saturation.py</td><td>spilt_bam.py</td><td>split_paired_bam.py</td><td>none</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python scripts/bam2fq.py -i test_PairedEnd_StrandSpecific_hg19.sam  -o bam2fq_out1</span><br><span class="line"></span><br><span class="line">python clipping_profile.py -i Pairend_StrandSpecific_51mer_Human_hg19.bam -s <span class="string">"PE"</span> -o out</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="http://www.bio-info-trainee.com/1914.html" target="_blank" rel="noopener">用sickle软件来对双端测序数据过滤低质量reads</a>  </li><li><a href="https://doi.org/10.1016/j.ygeno.2014.03.006" target="_blank" rel="noopener">使用Q30进行质控</a></li><li><a href="http://www.biotrainee.com/thread-324-1-4.html" target="_blank" rel="noopener">论QC的重要性</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>生信基础 链特异性</title>
      <link href="/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E9%93%BE%E7%89%B9%E5%BC%82%E6%80%A7/"/>
      <url>/2018/10/12/%E7%94%9F%E4%BF%A1%E5%9F%BA%E7%A1%80-%E9%93%BE%E7%89%B9%E5%BC%82%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="1-链特异性的基本知识"><a href="#1-链特异性的基本知识" class="headerlink" title="1.链特异性的基本知识"></a>1.链特异性的基本知识</h2><ul><li><a href="http://www.genek.tv/article/27" target="_blank" rel="noopener">http://www.genek.tv/article/27</a></li><li><a href="http://databeauty.com/blog/opinion/2016/09/21/RNA-seq-strand-issues.html" target="_blank" rel="noopener">http://databeauty.com/blog/opinion/2016/09/21/RNA-seq-strand-issues.html</a></li></ul><p>在建库的时候,选择的建库方法可以是链特异性的,链特异性的文库可以清楚地分出reads的方向是否与转录本相同;常用的链特异性文库方法是基于dUTP的方法.</p><table><thead><tr><th>文库类型</th><th>PE</th><th>SE</th><th>建库方法</th></tr></thead><tbody><tr><td>非特异性</td><td>无</td><td>无</td><td>Standard Illumina</td></tr><tr><td>fr-firststrand</td><td>RF</td><td>R</td><td>dUTP,NSR,NNSR</td></tr><tr><td>fr-secondstrand</td><td>FR</td><td>F</td><td>Ligation,Standard SOLiD</td></tr></tbody></table><a id="more"></a><h2 id="2-链特异性与软件"><a href="#2-链特异性与软件" class="headerlink" title="2.链特异性与软件"></a>2.链特异性与软件</h2><p>在许多软件中,需要设置链特异性的参数,设置错了会导致结果与预期大相径庭.常用软件的参数设置如下。</p><ul><li>Trinity:  链特异性的文库需要设置–SS_lib_type, dUTP法值为RF</li><li>cufflinks: 链特异性的文库需要设置–library-type=fr-firststrand(RF时)</li><li>tophat: dUTP, –library-type fr-firststrand</li><li>hisat2: dUTP, –rna-strandnes RF</li><li>eXpress: dUTP, –rf-stranded</li><li>RSEM: dUTP, –strandness reverse</li></ul><h2 id="3-如何判断测序数据是否是链特异性"><a href="#3-如何判断测序数据是否是链特异性" class="headerlink" title="3.如何判断测序数据是否是链特异性"></a>3.如何判断测序数据是否是链特异性</h2><ol><li>samtools建立索引</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># aim.bam, 生成aim.bai</span></span><br><span class="line">samtools index aim.bam</span><br></pre></td></tr></table></figure><ol start="2"><li><p>判断链特异性<br>进入IGV软件<br>右键选择color alignments by first-of-pair strand, 红蓝分布就是链特异性的</p></li><li><p>判断链特异性的种类<br>在链特异性的样本上右键选color alignments by read strand, 或者鼠标放在read上, 如果信息显示first of pair的那个read的箭头方向与基因的方向相反,就是dUTIP的建库</p></li><li><p>用途<br>在STAR运行结束后的ReadsPerGene.out.tab文件中, 非特异性链的reads数是在第二列;链特异性的reads数要选第四列.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>质控软件 raw_data质控</title>
      <link href="/2018/10/12/%E8%B4%A8%E6%8E%A7%E8%BD%AF%E4%BB%B6-raw_data%E8%B4%A8%E6%8E%A7/"/>
      <url>/2018/10/12/%E8%B4%A8%E6%8E%A7%E8%BD%AF%E4%BB%B6-raw_data%E8%B4%A8%E6%8E%A7/</url>
      
        <content type="html"><![CDATA[<p>测序数据的质控是必须的，也是主要的。</p><a id="more"></a><h2 id="1-fastqc"><a href="#1-fastqc" class="headerlink" title="1. fastqc"></a>1. fastqc</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastqc input_path/*.fastq(.gz) -o output_path -p 10</span><br></pre></td></tr></table></figure><h2 id="2-cutadapt"><a href="#2-cutadapt" class="headerlink" title="2. cutadapt"></a>2. cutadapt</h2><p><a href="https://cutadapt.readthedocs.io/en/stable/guide.html#basic-usage" target="_blank" rel="noopener">https://cutadapt.readthedocs.io/en/stable/guide.html#basic-usage</a></p><p>基本的用法如下，你需要将序列改成对应的3‘端adapter。支持压缩文件作为输入和输出。如果你的输出是fasta的话，cutadapt不会进行去除adapter，而是进行转化。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于pair-end</span></span><br><span class="line">cutadapt -a ADAPTER_FWD -A ADAPTER_REV -o out.1.fastq -p out.2.fastq reads.1.fastq reads.2.fastq</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于single-end</span></span><br><span class="line">cutadapt -a AACCGGTT -o output.fastq input.fastq</span><br><span class="line"></span><br><span class="line">cutadapt -a AACCGGTT input.fastq &gt; output.fastq 2&gt;&lt;report class=<span class="string">"txt"</span>&gt;&lt;/report&gt;</span><br><span class="line"><span class="comment"># 使用管道的话，输入文件位置以-代替</span></span><br><span class="line">tail -n 4 input.fastq | cutadapt -a AACCGGTT - &gt; output.fastq</span><br><span class="line"></span><br><span class="line"><span class="comment"># 双端时，-u指前一个，-U指后一个。指定切除特定长度的碱基, -5 表示切除3‘端（反向切除5个碱基），5表示切除5’端（正向切除5个碱基）</span></span><br><span class="line">cutadapt -u 5 -o trimmed.fastq input.fastq</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单双端都可用. 切除碱基质量低于10的碱基（3‘端），使用的是phred quality+33.如果要使用+64版本，--quality-base=64指定</span></span><br><span class="line">cutadapt -q 10 -o output.fastq input.fastq</span><br><span class="line"><span class="comment"># 切除5‘端低于15的，3’端低于10的碱基</span></span><br><span class="line">cutadapt -q 15,10 -o output.fastq input.fastq</span><br><span class="line"></span><br><span class="line"><span class="comment"># 把read切成指定长度，注意是从3‘端切掉.如果要从两端切掉，使用-u参数</span></span><br><span class="line">cutadapt -l 120 -o output.fastq input.fastq</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给read name添加内容，下方指令把read1 改成read1 we found adapter1如果ACGT在该read1找到的话</span></span><br><span class="line">cutadapt -a adapter1=ACGT -y <span class="string">' we found &#123;names&#125;'</span> input.fastq</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果要添加上length字符的话. output.fastq =&gt; "&gt;read1 length=120"</span></span><br><span class="line">cutadapt -l 120 -o output.fastq --length-tag <span class="string">'length='</span> input.fastq</span><br><span class="line"></span><br><span class="line"><span class="comment"># -m length: 只输出长度大于length的reads</span></span><br><span class="line"><span class="comment"># --too-short-output FILE: 把-m删除的reads输入到FILE</span></span><br><span class="line"><span class="comment"># -M length：只输出短于length的reads</span></span><br><span class="line"><span class="comment"># --too-long-output FILE: 把-M删除的reads出入到FILE</span></span><br><span class="line"><span class="comment"># --untrimmed-output FILE</span></span><br><span class="line"><span class="comment"># --discard-trimmed:去掉含有接头的reads</span></span><br><span class="line"><span class="comment"># --discard-untrimmed：去掉不含接头的reads</span></span><br></pre></td></tr></table></figure><p>除了去除adapter，cutadapt可以做的事情有很多，比如3‘端低质量碱基的切除，reads过滤等等。下表是指定adapter类型的对应指令。</p><table><thead><tr><th>接头类型</th><th>命令</th><th>接头类型</th><th>命令</th></tr></thead><tbody><tr><td>3’adapter</td><td>-a ADAPTER</td><td>5’adapter</td><td>-g ADAPTER</td></tr><tr><td>Anchored 3’adapter</td><td>-a ADAPTER$</td><td>Anchored 5’adapter</td><td>-g ^ADAPTER</td></tr><tr><td>5’or3’(both possible)</td><td>-b ADAPTER</td><td>Linked adapter</td><td>-a ADAPTER1…ADAPTER2</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1. Unconditional base removal with --cut</span></span><br><span class="line"><span class="comment">#2. Quality trimming (-q)</span></span><br><span class="line"><span class="comment">#3. Adapter trimming (-a, -b, -g and uppercase versions)</span></span><br><span class="line"><span class="comment">#4. Read shortening (--length)</span></span><br><span class="line"><span class="comment">#5. N-end trimming (--trim-n)</span></span><br><span class="line"><span class="comment">#6. Length tag modification (--length-tag)</span></span><br><span class="line"><span class="comment">#7. Read name suffix removal (--strip-suffix)</span></span><br><span class="line"><span class="comment">#8. Addition of prefix and suffix to read name (-x/--prefix and -y/--suffix)</span></span><br><span class="line"><span class="comment">#9. Double-encode the sequence (only colorspace)</span></span><br><span class="line"><span class="comment">#10.Replace negative quality values with zero (zero capping, only colorspace)</span></span><br></pre></td></tr></table></figure><h2 id="3-Fastx-toolkit"><a href="#3-Fastx-toolkit" class="headerlink" title="3. Fastx-toolkit"></a>3. Fastx-toolkit</h2><table><thead><tr><th>用途</th><th>用途</th><th>用途</th></tr></thead><tbody><tr><td>01.去除接头</td><td>02.去除低质量碱基</td><td>03.转换成fasta  </td></tr><tr><td>04.碱基质量统计</td><td>05.生成碱基质量箱图</td><td>06.生成碱基质量分布图</td></tr><tr><td>07.重命名read</td><td>08.输出指定长度read(前后切除)</td><td>09.去重reads</td></tr><tr><td>10.去除人工reads(artifact)</td><td>11.生成反向互补序列</td><td>12.对fasta文件进行格式化</td></tr><tr><td>13.DNA序列与RNA互换</td><td>14.生成reads长度分布图</td><td>15.依据barcode进行reads分类成不同文件</td></tr></tbody></table><h3 id="3-1-去除接头"><a href="#3-1-去除接头" class="headerlink" title="3.1.去除接头"></a>3.1.去除接头</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fastx_clipper -a AGATCGGAAGAGCACACG -l 25 -d 0 -Q 33 -i SRR306394_1.fastq -o </span><br><span class="line"></span><br><span class="line"> <span class="comment"># [-a ADAPTER] =接头序列（默认为CCTTAAGG）</span></span><br><span class="line"> <span class="comment"># [-l N]       = 忽略那些碱基数目少于N的reads，默认为5</span></span><br><span class="line"> <span class="comment"># [-d N]       = 保留接头序列后的N个碱基默认  -d 0</span></span><br><span class="line"> <span class="comment"># [-c]         = 放弃那些没有接头的序列.</span></span><br><span class="line"> <span class="comment"># [-C]         = 只保留没有接头的序列.</span></span><br><span class="line"> <span class="comment"># [-k]         = 报告只有接头的序列.</span></span><br><span class="line"> <span class="comment"># [-n]         = 保留有N多序列，默认不保留</span></span><br><span class="line"> <span class="comment"># [-v]         =详细-报告序列编号</span></span><br><span class="line"> <span class="comment"># [-z]         =压缩输出.</span></span><br><span class="line"> <span class="comment"># [-D]       = 输出调试结果.</span></span><br><span class="line"> <span class="comment"># [-M N]   =要求最小能匹配到接头的长度N，如果和接头匹配的长度小于N不修剪</span></span><br><span class="line"> <span class="comment"># [-i INFILE]  = 输入文件</span></span><br><span class="line"> <span class="comment"># [-o OUTFILE] = 输出文件</span></span><br></pre></td></tr></table></figure><h3 id="3-2-去除低质量碱基"><a href="#3-2-去除低质量碱基" class="headerlink" title="3.2. 去除低质量碱基"></a>3.2. 去除低质量碱基</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> fastq_quality_filter -q 20 -p 80 -Q 33 -i input.fastq -o output.fastq</span><br><span class="line"></span><br><span class="line"><span class="comment"># [-q N]       = 最小的需要留下的质量值</span></span><br><span class="line"><span class="comment"># [-p N]       = 每个reads中最少有百分之多少的碱基需要有-q的质量值</span></span><br><span class="line"><span class="comment"># [-z]         =压缩输出</span></span><br><span class="line"><span class="comment"># [-v]         =详细-报告序列编号，如果使用了-o则报告会直接在STDOUT，如果没有则输入到STDERR</span></span><br></pre></td></tr></table></figure><h3 id="3-3-转换成fasta"><a href="#3-3-转换成fasta" class="headerlink" title="3.3. 转换成fasta"></a>3.3. 转换成fasta</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fastq_to_fasta [-h] [-r] [-n] [-v] [-z] [-i INFILE] [-o OUTFILE]</span><br><span class="line">[-h]         显示帮助信息</span><br><span class="line">[-r]         使用连续的数字来重命名序列</span><br><span class="line">[-n]         保持序列中的未知碱基N, 默认为丢弃这样的序列</span><br><span class="line">[-v]         打印出转换的reads数</span><br><span class="line">[-z]         用GZIP压缩输出</span><br><span class="line">[-i INFILE]  指定输入fastq</span><br><span class="line">[-o OUTFILE] 指定输出fasta</span><br></pre></td></tr></table></figure><h3 id="3-4-碱基质量统计"><a href="#3-4-碱基质量统计" class="headerlink" title="3.4. 碱基质量统计"></a>3.4. 碱基质量统计</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fastx_quality_stats [-h] [-i INFILE] [-o OUTFILE]</span><br><span class="line">[-h]            显示帮助信息</span><br><span class="line">[-i INFILE]     指定输入文件, 如果输入为fasta, 只统计碱基分布</span><br><span class="line">[-o OUTFILE]    指定输出文件</span><br></pre></td></tr></table></figure><h3 id="3-5-生成碱基质量箱图"><a href="#3-5-生成碱基质量箱图" class="headerlink" title="3.5. 生成碱基质量箱图"></a>3.5. 生成碱基质量箱图</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fastq_quality_boxplot_graph.sh [-i INPUT.TXT] [-t TITLE] [-p] [-o OUTPUT]</span><br><span class="line">[-p]            生成图片格式为Generate PostScript (.PS), 默认PNG图片</span><br><span class="line">[-i INPUT.TXT]  输入文件名, 应为fastx_quality_stats的结果</span><br><span class="line">[-o OUTPUT]     输出文件名</span><br><span class="line">[-t TITLE]      箱线图的标题</span><br></pre></td></tr></table></figure><h3 id="3-6-生成碱基质量分布图"><a href="#3-6-生成碱基质量分布图" class="headerlink" title="3.6. 生成碱基质量分布图"></a>3.6. 生成碱基质量分布图</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fastx_nucleotide_distribution_graph.sh [-i INPUT.TXT] [-t TITLE] [-p] [-o OUTPUT]</span><br><span class="line">[-p]            生成图片格式为Generate PostScript (.PS), 默认PNG图片</span><br><span class="line">[-i INPUT.TXT]  输入文件名, 应为fastx_quality_stats的结果</span><br><span class="line">[-o OUTPUT]     输出文件名</span><br><span class="line">[-t TITLE]      柱状图的标题</span><br></pre></td></tr></table></figure><h3 id="3-7-重命名read"><a href="#3-7-重命名read" class="headerlink" title="3.7.重命名read"></a>3.7.重命名read</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fastx_renamer [-n TYPE] [-h] [-z] [-v] [-i INFILE] [-o OUTFILE]</span><br><span class="line">[-n TYPE]    重命名类型:</span><br><span class="line">             SEQ - 使用核苷酸序列作为名称</span><br><span class="line">             COUNT - 使用简单的计数重命名</span><br><span class="line">[-h]         显示帮助信息</span><br><span class="line">[-z]         用GZIP压缩输出</span><br><span class="line">[-i INFILE]  指定输入文件, 默认为标准输入</span><br><span class="line">[-o OUTFILE] 指定输出文件, 默认为标准输出</span><br></pre></td></tr></table></figure><h3 id="3-8-输出指定长度read（前后切除）"><a href="#3-8-输出指定长度read（前后切除）" class="headerlink" title="3.8. 输出指定长度read（前后切除）"></a>3.8. 输出指定长度read（前后切除）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fastx_trimmer [-h] [-f N] [-l N] [-z] [-v] [-i INFILE] [-o OUTFILE]</span><br><span class="line">[-h]            显示帮助信息</span><br><span class="line">[-f N]          从前面第几个碱基开始保留, 默认值为1</span><br><span class="line">[-l N]          保留几个碱基, 默认值为全部保留</span><br><span class="line">[-z]            用GZIP压缩输出</span><br><span class="line">[-i INFILE]     指定输入文件, 默认为标准输入</span><br><span class="line">[-o OUTFILE]    指定输出文件, 默认为标准输出</span><br></pre></td></tr></table></figure><h3 id="3-9-去重reads"><a href="#3-9-去重reads" class="headerlink" title="3.9.去重reads"></a>3.9.去重reads</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fastx_collapser [-h] [-v] [-i INFILE] [-o OUTFILE]</span><br><span class="line">[-h]         显示帮助信息</span><br><span class="line">[-v]         打印出输入/输出的统计摘要</span><br><span class="line">[-i INFILE]  指定输入文件, 默认为标准输入</span><br><span class="line">[-o OUTFILE] 指定输出文件, 默认为标准输出</span><br></pre></td></tr></table></figure><h3 id="3-10-去除人工reads（artifact）"><a href="#3-10-去除人工reads（artifact）" class="headerlink" title="3.10.去除人工reads（artifact）"></a>3.10.去除人工reads（artifact）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fastx_artifacts_filter [-h] [-v] [-z] [-i INFILE] [-o OUTFILE]</span><br><span class="line">[-h]         显示帮助信息</span><br><span class="line">[-v]         报告处理的序列数目</span><br><span class="line">                 如果有<span class="string">'-o'</span>, 在屏幕上标准输出</span><br><span class="line">                 如果无<span class="string">'-o'</span>, 信息在屏幕上输出, 则报告在标准错误上输出</span><br><span class="line">[-z]         用GZIP压缩输出</span><br><span class="line">[-i INFILE]  指定输入文件, 默认为标准输入</span><br><span class="line">[-o OUTFILE] 指定输出文件, 默认为标准输出</span><br></pre></td></tr></table></figure><h3 id="3-11-生成反向互补序列"><a href="#3-11-生成反向互补序列" class="headerlink" title="3.11. 生成反向互补序列"></a>3.11. 生成反向互补序列</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fastx_reverse_complement -i input.fastq -o output.fastq</span><br></pre></td></tr></table></figure><h3 id="3-12-对fasta文件进行格式化"><a href="#3-12-对fasta文件进行格式化" class="headerlink" title="3.12.对fasta文件进行格式化"></a>3.12.对fasta文件进行格式化</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fasta_formatter [-h] [-i INFILE] [-o OUTFILE] [-w N] [-t] [-e]</span><br><span class="line">[-w N]          输出fasta每行最大的碱基数, 默认值为0, 也就是每条fasta占据一行序列, 容易脚本操作</span><br><span class="line">[-t]            输出为制表符格式, 而不是fasta, 第一列为序列ID, 第二列为序列的单行显示</span><br><span class="line">[-e]            输出空白序列, 默认值为丢弃, 具有序列ID但并没有任何碱基的为空序列</span><br></pre></td></tr></table></figure><h3 id="3-13-DNA序列与RNA互换"><a href="#3-13-DNA序列与RNA互换" class="headerlink" title="3.13.DNA序列与RNA互换"></a>3.13.DNA序列与RNA互换</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fasta_nucleotide_changer [-h] [-z] [-v] [-i INFILE] [-o OUTFILE] [-r] [-d]</span><br><span class="line">[-r]         DNA to RNA, T to U</span><br><span class="line">[-d]         RNA to DNA, U to T</span><br><span class="line">[-v]         报告序列的数目</span><br><span class="line">             如果有<span class="string">'-o'</span>, 在屏幕上标准输出</span><br><span class="line">             如果无<span class="string">'-o'</span>, 则在标准错误输出</span><br><span class="line">[-z]         用GZIP压缩输出</span><br></pre></td></tr></table></figure><h3 id="3-14-生成reads长度分布图"><a href="#3-14-生成reads长度分布图" class="headerlink" title="3.14.生成reads长度分布图"></a>3.14.生成reads长度分布图</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fasta_clipping_histogram.pl INPUT_FILE.FA OUTPUT_FILE.PNG</span><br><span class="line">INPUT_FILE.FA   指定输入fasta文件, 可以为GZIP格式</span><br><span class="line">OUTPUT_FILE.PNG 生成的柱状图</span><br></pre></td></tr></table></figure><h3 id="3-15-依据barcode进行reads分类成不同文件"><a href="#3-15-依据barcode进行reads分类成不同文件" class="headerlink" title="3.15. 依据barcode进行reads分类成不同文件"></a>3.15. 依据barcode进行reads分类成不同文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">fastx_barcode_splitter.pl --bcfile FILE --prefix PREFIX [--suffix SUFFIX] [--bol|--eol] [--mismatches N] [--exact] [--partial N] [--quiet] [--debug]</span><br><span class="line">--bcfile FILE       Barcodes文件名, 解释如下</span><br><span class="line">--prefix PREFIX     文件前缀, 会添加到输出文件, 可以用来辨别输出目录</span><br><span class="line">--suffix            文件后缀, 可选, 可以用来辨别文件扩展名</span><br><span class="line">--bol               尝试在序列的开始匹配barcodes, 也就是5‘端, 程序从0开始</span><br><span class="line">--eol               尝试在序列的末尾匹配barcodes, 也就是3‘端, 程序从最后开始</span><br><span class="line">                    --bol 与 --eo l必须有其一</span><br><span class="line">--mismatches N      允许的最大错配数, 默认为1</span><br><span class="line">--exact             等同于<span class="string">'--mismatches 0'</span>, 如果与<span class="string">'--mismatches'</span>同时存在, 那么<span class="string">'--exact'</span>具有优先级</span><br><span class="line">--partial N         允许部分barcodes匹配, 默认不允许, 解释如下</span><br><span class="line">--quiet             运行结束不打印统计信息, 默认为打印</span><br><span class="line">--debug             在标准错误上打印大量有用的debug信息</span><br></pre></td></tr></table></figure><h2 id="4-Trimmomatic"><a href="#4-Trimmomatic" class="headerlink" title="4.Trimmomatic"></a>4.Trimmomatic</h2><blockquote><p>你需要指定adapter的path,线程数,SRR的共有部分,及循环体.还要各种path</p></blockquote><ul><li>Paired end</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">adapter=</span><br><span class="line">threads=</span><br><span class="line">SRR_base=</span><br><span class="line"><span class="keyword">for</span> ((id=4;id&lt;=8;id++));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">time trimmomatic PE ../00rawdata/<span class="variable">$&#123;SRR_base&#125;</span><span class="variable">$&#123;id&#125;</span>_1.fastq.gz  ../00rawdata/<span class="variable">$&#123;SRR_base&#125;</span><span class="variable">$&#123;id&#125;</span>_2.fq.gz \</span><br><span class="line">    ./trim/<span class="variable">$&#123;SRR_base&#125;</span><span class="variable">$&#123;id&#125;</span>_F.fastq.gz ./trim/<span class="variable">$&#123;SRR_base&#125;</span><span class="variable">$&#123;id&#125;</span>_UF.fastq.gz \</span><br><span class="line">    ./trim/<span class="variable">$&#123;SRR_base&#125;</span><span class="variable">$&#123;id&#125;</span>_R.fastq.gz ./trim/<span class="variable">$&#123;SRR_base&#125;</span><span class="variable">$&#123;id&#125;</span>_UR.fastq.gz \</span><br><span class="line">    ILLUMINACLIP:<span class="variable">$&#123;adapter&#125;</span>:2:30:10 \</span><br><span class="line">    -threads <span class="variable">$&#123;threads&#125;</span> \</span><br><span class="line">    LEADING:4 TRAILING:5 SLIDINGWINDOW:4:5 MINLEN:25</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><ul><li>Single end</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">adapter=</span><br><span class="line">threads=</span><br><span class="line">SRR_base=</span><br><span class="line"><span class="keyword">for</span> ((id=4;id&lt;=8;id++));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">time trimmomatic SE ../00rawdata/<span class="variable">$&#123;SRR_base&#125;</span><span class="variable">$&#123;id&#125;</span>.fastq.gz \</span><br><span class="line">    ./trim/<span class="variable">$&#123;SRR_base&#125;</span><span class="variable">$&#123;id&#125;</span>_F.fastq.gz \</span><br><span class="line">    ILLUMINACLIP:<span class="variable">$&#123;adapter&#125;</span>:2:30:10 \</span><br><span class="line">    -threads <span class="variable">$&#123;threads&#125;</span> \</span><br><span class="line">    LEADING:4 TRAILING:5 SLIDINGWINDOW:4:5 MINLEN:25</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>组装或定量 eXpress</title>
      <link href="/2018/10/12/%E7%BB%84%E8%A3%85%E6%88%96%E5%AE%9A%E9%87%8F-eXpress/"/>
      <url>/2018/10/12/%E7%BB%84%E8%A3%85%E6%88%96%E5%AE%9A%E9%87%8F-eXpress/</url>
      
        <content type="html"><![CDATA[<a id="more"></a><blockquote><p><a href="https://pachterlab.github.io/eXpress/downloads/express-1.5.1/express-1.5.1-linux_x86_64.tgz" target="_blank" rel="noopener">https://pachterlab.github.io/eXpress/downloads/express-1.5.1/express-1.5.1-linux_x86_64.tgz</a></p></blockquote><h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">express [options]* &lt;target_seqs.fasta&gt; &lt;aligned_reads.(sam/bam)&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># &lt;target_seqs.fasta&gt;:参考序列的fasta文件</span></span><br><span class="line"><span class="comment"># &lt;aligned_reads.(sam/bam)&gt;:比对结果文件</span></span><br><span class="line"><span class="comment"># -o path: 指定输出路径</span></span><br><span class="line"><span class="comment"># -B n:指定进行batch EM rounds计算的次数,以时间为代价提高定量准确性</span></span><br><span class="line"><span class="comment"># -O n:指定进行online EM rounds计算的次数,以时间为代价提高定量准确性</span></span><br><span class="line"><span class="comment"># -m n:指定fragment的平均长度</span></span><br><span class="line"><span class="comment"># -s n：指定fragment长度的标准差</span></span><br><span class="line"><span class="comment"># -H str:以逗号分隔的位置坐标,指定haplotypes的位置。利于等位基因的特异表达定量</span></span><br><span class="line"><span class="comment"># --output-align-samp:</span></span><br><span class="line"><span class="comment"># --output-align-prob:</span></span><br><span class="line"><span class="comment"># --fr-stranded: 指定链特异性比对的方向,read1比对到forward链,read2比对到reverse链</span></span><br><span class="line"><span class="comment"># --rf-stranded：指定链特异性比对的方向,read1比对到reverse链,read2比对到forward链</span></span><br><span class="line"><span class="comment"># --f-stranded: single-end, read比对到forward链</span></span><br><span class="line"><span class="comment"># --r-stranded: single-end, read比对到reverse链</span></span><br><span class="line"><span class="comment">#</span></span><br></pre></td></tr></table></figure><h2 id="输入文件"><a href="#输入文件" class="headerlink" title="输入文件"></a>输入文件</h2><p>eXpress需要一个multi-fasta格式的输入文件,计算该文件序列的转录丰度。</p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 定量 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>组装或定量 kallisto_sleuth</title>
      <link href="/2018/10/12/%E7%BB%84%E8%A3%85%E6%88%96%E5%AE%9A%E9%87%8F-kallisto_sleuth/"/>
      <url>/2018/10/12/%E7%BB%84%E8%A3%85%E6%88%96%E5%AE%9A%E9%87%8F-kallisto_sleuth/</url>
      
        <content type="html"><![CDATA[<h2 id="免比对的定量：kallisto"><a href="#免比对的定量：kallisto" class="headerlink" title="免比对的定量：kallisto"></a>免比对的定量：kallisto</h2><p><a href="https://pachterlab.github.io/kallisto/manual.html" target="_blank" rel="noopener">kallisto</a>是一个align-free的测序结果定量工具。速度快得很.他可以在10min内完成index的构建，然后花3min完成30 million的human reads的定量。它不仅快速而且准确。</p><p>Pseudoalignment保存了用于定量的关键信息。An important feature of kallisto is that it outputs bootstraps along with the estimates of transcript abundances</p><a id="more"></a><h3 id="流程概览"><a href="#流程概览" class="headerlink" title="流程概览"></a>流程概览</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 建立一个索引</span></span><br><span class="line">kallisto index -i transcripts.idx transcripts.fasta.gz</span><br><span class="line"><span class="comment"># 进行定量</span></span><br><span class="line">kallisto quant -i transcripts.idx -o output -b 100 reads_1.fastq.gz reads_2.fastq.gz</span><br><span class="line"><span class="comment"># single-end</span></span><br><span class="line"><span class="comment"># kallisto quant -i transcripts.idx -o output -b 100 --single -l 180 -s 20 reads.fastq.gz</span></span><br></pre></td></tr></table></figure><h3 id="0-安装"><a href="#0-安装" class="headerlink" title="0. 安装"></a>0. 安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install kallisto</span><br></pre></td></tr></table></figure><h3 id="1-kallisto-index-建立索引"><a href="#1-kallisto-index-建立索引" class="headerlink" title="1. kallisto index: 建立索引"></a>1. kallisto index: 建立索引</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kallisto index [arguments] ref.fa[.gz]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 必需参数</span></span><br><span class="line">-i, --index=STRING          存放索引的目录名字</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可选参数</span></span><br><span class="line">-k, --kmer-size=INT         k-mer (odd) length (default: 31, max value: 31)</span><br><span class="line">    --make-unique           Replace repeated target names with unique names</span><br></pre></td></tr></table></figure><h3 id="2-kallisto-quant-进行定量"><a href="#2-kallisto-quant-进行定量" class="headerlink" title="2. kallisto quant: 进行定量"></a>2. kallisto quant: 进行定量</h3><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><ul><li>每次的输入文件只能是一个样本的文件, 输入多个文件仅仅是因为这个样本的数据被分成了多个文件.</li><li>对于single-end,你必需通过-l参数指定fragment length</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">kallisto quant [arguments] reads.fastq</span><br><span class="line"></span><br><span class="line">示例: pair-end / single-end</span><br><span class="line">kallisto quant -i index -o output pairA_1.fastq pairA_2.fastq pairB_1.fastq pairB_2.fastq</span><br><span class="line">kallisto quant -i index -o output --single -l 200 -s 20 file1.fastq.gz file2.fastq.gz file3.fastq.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 必需参数</span></span><br><span class="line">-i, --index=STRING            索引所在目录</span><br><span class="line">-o, --output-dir=STRING       输出目录。默认输出三个文件,abuncance.h5, abundance.tsv, run_info.json</span><br><span class="line"></span><br><span class="line">Optional arguments:</span><br><span class="line">    --bias                    Perform sequence based bias correction</span><br><span class="line">-b, --bootstrap-samples=INT   Number of bootstrap samples (default: 0)</span><br><span class="line">    --seed=INT                Seed <span class="keyword">for</span> the bootstrap sampling (default: 42)</span><br><span class="line">    --plaintext               指定输出纯文本文件,而非HDF5格式</span><br><span class="line">    --fusion                  搜索融合位点?(Search <span class="keyword">for</span> fusions <span class="keyword">for</span> Pizzly)</span><br><span class="line">    --single                  输入的文件是single-end reads</span><br><span class="line">    --single-overhang         对不再转录本上的<span class="built_in">read</span>也进行定量</span><br><span class="line">    --fr-stranded             Strand specific reads, first <span class="built_in">read</span> forward</span><br><span class="line">    --rf-stranded             Strand specific reads, first <span class="built_in">read</span> reverse</span><br><span class="line">-l, --fragment-length=DOUBLE  Estimated average fragment length</span><br><span class="line">-s, --sd=DOUBLE               Estimated standard deviation of fragment length</span><br><span class="line">                              (default: -l, -s values are estimated from paired</span><br><span class="line">                               end data, but are required when using --single)</span><br><span class="line">-t, --threads=INT             Number of threads to use (default: 1)</span><br><span class="line">    --pseudobam               Save pseudoalignments to transcriptome to BAM file</span><br><span class="line">    --genomebam               Project pseudoalignments to genome sorted BAM file</span><br><span class="line">-g, --gtf                     GTF file <span class="keyword">for</span> transcriptome information</span><br><span class="line">                              (required <span class="keyword">for</span> --genomebam)</span><br><span class="line">-c, --chromosomes             Tab separated file with chrosome names and lengths</span><br><span class="line">                              (optional <span class="keyword">for</span> --genomebam, but recommended)</span><br></pre></td></tr></table></figure><h3 id="3-kallisto-preudo-伪比对"><a href="#3-kallisto-preudo-伪比对" class="headerlink" title="3. kallisto preudo: 伪比对"></a>3. kallisto preudo: 伪比对</h3><p>这个功能是进行伪比对这一步，主要是用于单细胞RNA-seq的。它的命令在形式上与目的上与kallisto quant相似，但是它不会利用EM-算法来计算reads abundance.而且它还有个选项指定多个细胞到一个批文件里面.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">kallisto pseudo [arguments] FASTQ-files</span><br><span class="line"></span><br><span class="line"><span class="comment"># 必需参数</span></span><br><span class="line">-i, --index=STRING            Filename <span class="keyword">for</span> the kallisto index to be used <span class="keyword">for</span></span><br><span class="line">                              pseudoalignment</span><br><span class="line">-o, --output-dir=STRING       Directory to write output to</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可选参数</span></span><br><span class="line">-u  --umi                     First file <span class="keyword">in</span> pair is a UMI file</span><br><span class="line">-b  --batch=FILE              Process files listed <span class="keyword">in</span> FILE</span><br><span class="line">    --single                  Quantify single-end reads</span><br><span class="line">-l, --fragment-length=DOUBLE  Estimated average fragment length</span><br><span class="line">-s, --sd=DOUBLE               Estimated standard deviation of fragment length</span><br><span class="line">                              (default: -l, -s values are estimated from paired</span><br><span class="line">                               end data, but are required when using --single)</span><br><span class="line">-t, --threads=INT             Number of threads to use (default: 1)</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># batch file的形式, single-end只有一个fastq,2变成1</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">#id file1 file 2</span></span><br><span class="line">cell1 cell1_1.fastq.gz cell1_1.fastq.gz</span><br><span class="line">cell2 cell2_1.fastq.gz cell2_1.fastq.gz</span><br><span class="line">cell3 cell3_1.fastq.gz cell3_1.fastq.gz</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 对于--umi指定后的形式</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">#id umi-file file-1</span></span><br><span class="line">cell1 cell_1.umi cell_1.fastq.gz</span><br><span class="line">cell2 cell_2.umi cell_2.fastq.gz</span><br><span class="line">cell3 cell_3.umi cell_3.fastq.gz</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-kallisto-h5dump-把HDF5文件转为纯文本格式"><a href="#4-kallisto-h5dump-把HDF5文件转为纯文本格式" class="headerlink" title="4. kallisto h5dump: 把HDF5文件转为纯文本格式"></a>4. kallisto h5dump: 把HDF5文件转为纯文本格式</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kallisto h5dump -o output_path abundance.h5</span><br></pre></td></tr></table></figure><h2 id="利用sleuth进行差异分析"><a href="#利用sleuth进行差异分析" class="headerlink" title="利用sleuth进行差异分析"></a>利用sleuth进行差异分析</h2><p>sleuth可以与kallisto进行无缝对接，进行表达定量的后续差异分析；它在RStudio上工作，让你能交互式地进行数据探索。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过bioconductor安装</span></span><br><span class="line"><span class="keyword">source</span>(<span class="string">'http://bioconductor.org/biocLite.R'</span>)</span><br><span class="line">biocLite(<span class="string">'devtools'</span>)</span><br><span class="line">biocLite(<span class="string">'pachterlab/sleuth'</span>)</span><br><span class="line"><span class="comment"># 通过conda安装</span></span><br><span class="line"><span class="comment"># conda install --channel bioconda r-sleuth</span></span><br></pre></td></tr></table></figure><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><ul><li>既适用于transcript-level的分析，也适合gene-level的分析</li><li>与kallisto兼容，让你的分析流程更快</li><li>使用bootstraps来检测和校正实验的技术性变异</li><li>用于数据分析的可交互应用</li></ul><h3 id="get-started-with-RStudio"><a href="#get-started-with-RStudio" class="headerlink" title="get started with RStudio"></a><a href="https://pachterlab.github.io/sleuth_walkthroughs/trapnell/analysis.html" target="_blank" rel="noopener">get started with RStudio</a></h3><h4 id="1-构建实验设计表格"><a href="#1-构建实验设计表格" class="headerlink" title="1. 构建实验设计表格"></a>1. 构建实验设计表格</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不打印messages</span></span><br><span class="line">suppressMessages(&#123;</span><br><span class="line"><span class="keyword">library</span>(<span class="string">'sleuth'</span>)</span><br><span class="line">&#125;)</span><br><span class="line">options(stringsAsFactors=<span class="literal">F</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到kallisto处理结果</span></span><br><span class="line">sample_id &lt;- dir(file.path(<span class="string">'..'</span>, <span class="string">'results'</span>))</span><br><span class="line">kal_dirs &lt;- file.path(<span class="string">'..'</span>, <span class="string">'results'</span>, sample_id, <span class="string">'kallisto'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到对于的实验设计文件</span></span><br><span class="line">s2c &lt;- read.table(file.path(<span class="string">'..'</span>, <span class="string">'metadata'</span>, <span class="string">'hiseq_info.txt'</span>), header=<span class="literal">T</span>)</span><br><span class="line">s2c &lt;- dplyr::select(s2c, sample=run_accession, condition)</span><br><span class="line"><span class="comment"># 将path作为列添加上去，否则会报错</span></span><br><span class="line">s2c &lt;- dplyr::mutate(s2c, path=kal_dirs)</span><br><span class="line"></span><br><span class="line"><span class="comment">##      sample condition                          path</span></span><br><span class="line"><span class="comment">## 1 SRR493366  scramble ../results/SRR493366/kallisto</span></span><br><span class="line"><span class="comment">## 2 SRR493367  scramble ../results/SRR493367/kallisto</span></span><br><span class="line"><span class="comment">## 3 SRR493368  scramble ../results/SRR493368/kallisto</span></span><br><span class="line"><span class="comment">## 4 SRR493369   HOXA1KD ../results/SRR493369/kallisto</span></span><br><span class="line"><span class="comment">## 5 SRR493370   HOXA1KD ../results/SRR493370/kallisto</span></span><br><span class="line"><span class="comment">## 6 SRR493371   HOXA1KD ../results/SRR493371/kallisto</span></span><br></pre></td></tr></table></figure><h4 id="2-构建‘sleuth’对象"><a href="#2-构建‘sleuth’对象" class="headerlink" title="2. 构建‘sleuth’对象"></a>2. 构建‘sleuth’对象</h4><p>sleuth对象不仅包含了实验信息，也包含了用于差异分析的模型和结果。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 添加kallisto处理好的数据</span></span><br><span class="line">so &lt;- sleuth_prep(s2c, extra_bootstrap_summary=<span class="literal">T</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 确定sleuth应答错误衡量(full)模型的参数, condition是前面构建的实验设计表格里面的</span></span><br><span class="line"><span class="comment"># 详细讲就是~condition作为formula进行线性回归，然后对样本数据进行平滑</span></span><br><span class="line">so &lt;- sleuth_fit(so, ~condition, <span class="string">'full'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 确定sleuth归并模型的参数;前提是假定各个条件下的表达量是一致的</span></span><br><span class="line">so &lt;- sleuth_fit(so, ~<span class="number">1</span>, <span class="string">'reduced'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 使用似然率确定表达差异</span></span><br><span class="line">so &lt;- sleuth_lrt(so, <span class="string">'reduced'</span>, <span class="string">'full'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看使用了哪些回归模型</span></span><br><span class="line">models(so)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 进行差异分析</span></span><br><span class="line">sleuth_table &lt;- sleuth_results(so, <span class="string">'reduced:full'</span>, <span class="string">'lrt'</span>, show_all=<span class="literal">F</span>)</span><br><span class="line">sleuth_significant &lt;- dplyr::filter(sleuth_table, qval&lt;=<span class="number">0.05</span>)</span><br><span class="line">head(sleuth_significant, <span class="number">20</span>)</span><br></pre></td></tr></table></figure><h4 id="3-基因名注释"><a href="#3-基因名注释" class="headerlink" title="3. 基因名注释"></a>3. 基因名注释</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意,这里使用的ENSEMBL human transcriptome, 所以使用biomaRt</span></span><br><span class="line"><span class="keyword">source</span>(<span class="string">'http://bioconductor.org/biocLite.R'</span>)</span><br><span class="line">biocLite(<span class="string">'biomaRt'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">mart &lt;- biomaRt::useMart(biomart=<span class="string">'ENSEMBL_MART_ENSEMBL'</span>,</span><br><span class="line">dataset=<span class="string">'hsapiens_gene_ensembl'</span>,</span><br><span class="line">host=<span class="string">'ensembl.org'</span>)</span><br><span class="line">t2g &lt;- biomaRt::getBM(attributes=c(<span class="string">'ensembl_transcript_id'</span>,</span><br><span class="line"><span class="string">'ensembl_gene_id'</span>,</span><br><span class="line"><span class="string">'extenal_gene_name'</span>),</span><br><span class="line">  mart=mart)</span><br><span class="line">t2g &lt;- dplyr::rename(t2g, </span><br><span class="line"> target_id=ensembl_transcript_id,</span><br><span class="line"> ens_gene=ensembl_gene_id,</span><br><span class="line"> ext_gene=external_gene_name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加到sleuth对象上</span></span><br><span class="line">so &lt;- sleuth_prep(s2c, target_mapping=t2g)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再进行一次计算</span></span><br><span class="line">so &lt;- sleuth_fit(so, ~condition, <span class="string">'full'</span>)</span><br><span class="line">so &lt;- sleuth_fit(so, ~<span class="number">1</span>, <span class="string">'reduced'</span>)</span><br><span class="line">so &lt;- sleuth_rlt(so, <span class="string">'reduced'</span>, <span class="string">'full'</span>)</span><br></pre></td></tr></table></figure><h4 id="4-可视化结果"><a href="#4-可视化结果" class="headerlink" title="4. 可视化结果"></a>4. 可视化结果</h4><ul><li>对结果的查看和交互可以通过产生sleuth live site实现</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sleuth_live(so)</span><br></pre></td></tr></table></figure><ul><li>箱图</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_bootstrap(so, <span class="string">'ENST00000264734'</span>, units=<span class="string">'est_counts'</span>, color_by=<span class="string">'condition'</span>)</span><br></pre></td></tr></table></figure><ul><li>PCA plot<br>以实验条件的pca条件</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_pca(so, color_by=<span class="string">'condition'</span>, text_labels=<span class="literal">T</span>)</span><br></pre></td></tr></table></figure><ul><li>样品counts分布图</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_group_density(so, use_filtered=<span class="literal">T</span>, units=<span class="string">'est_counts'</span>, trans=<span class="string">'log'</span>,grouping=setdiff(colnames(so$sample_to_corvariates), <span class="string">'sample'</span>),offset=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><ul><li>MA-plot</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_ma(so, test=<span class="string">'condition'</span>)</span><br></pre></td></tr></table></figure><ul><li>均值方差分析</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_mean_var(so)</span><br></pre></td></tr></table></figure><ul><li>热图</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(pheatmap)</span><br><span class="line">plot_transcript_heatmap(so, transcripts=sleuth_table$target_id[<span class="number">1</span>:<span class="number">20</span>])</span><br></pre></td></tr></table></figure><ul><li>火山图</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_volcano(so, test=<span class="string">'condition'</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 定量 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>组装或定量 stringTie</title>
      <link href="/2018/10/12/%E7%BB%84%E8%A3%85%E6%88%96%E5%AE%9A%E9%87%8F-stringTie/"/>
      <url>/2018/10/12/%E7%BB%84%E8%A3%85%E6%88%96%E5%AE%9A%E9%87%8F-stringTie/</url>
      
        <content type="html"><![CDATA[<p>stringTie 是用于 RNA-seq 的转录本组装和定量软件</p><a id="more"></a><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><p>输入文件是BAM格式的比对结果文件，该文件必需经过排序，排序的方式基因组位置。这些文件可以是来源于Tophat比对的结果文件accepted_hits.bam，也可以是hisat2的结果文件经过转换和排序的文件(使用samtools)。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">stringtie &lt;aligned_reads.bam&gt; [options]*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项</span></span><br><span class="line">-o [&lt;path/&gt;]&lt;out.gtf&gt; 设置输出文件;组装的结果将写入out.gtf</span><br><span class="line">-p &lt;int&gt;指定threads</span><br><span class="line">-G &lt;ref_ann.gff&gt;指定参考注释文件</span><br><span class="line">--rf 说明是fr-firststrand的文库</span><br><span class="line">--fr 说明是fr-secondstrand的文库</span><br><span class="line">-l &lt;label&gt;设定输出转录本的前缀,默认是STRG</span><br><span class="line">-m &lt;int&gt; 最短的预测转录本长度</span><br><span class="line">-A &lt;gene_abund.tab&gt;将基因表达量输出到gene_abund.tab文件(tab delimited format)</span><br><span class="line">-C &lt;cov_refs.gtf&gt;输出reads能完全覆盖的参考序列区域的所有转录本</span><br><span class="line">-a &lt;int&gt;没有剪切后reads比对上的junction最短长度</span><br><span class="line">-j &lt;<span class="built_in">float</span>&gt;可比对到junction的剪切reads的最少个数</span><br><span class="line">-t 禁止在组装转录本的两端进行trim</span><br><span class="line">-c &lt;<span class="built_in">float</span>&gt; 设置进行转录本预测的最小<span class="built_in">read</span>覆盖度</span><br><span class="line">-g &lt;int&gt;locus的最小间隔值,如果reads比对区域距离小于该值,则会被合并</span><br><span class="line">-B 允许生成Ballgown的输入文件</span><br><span class="line">-b &lt;path&gt; 指定-B生成文件的存储路径</span><br><span class="line">-e 指定只进行比对文件的定量和输出能比对到参考转录本的组装转录本</span><br><span class="line">-M &lt;0.0-1.0&gt;设定多位置比对reads在给定位置序列的最大占比</span><br><span class="line">-x &lt;seqid_list&gt;忽略这里设置的参考序列区域,可以是逗号分隔的染色体. -x <span class="string">'chrM,chrX,chrY'</span></span><br><span class="line">--merge指定使用转录合并模式,在本模式中，将使用GTF/GFF文件作为输入，然后把这些转录合并成非冗余的转录集合。</span><br><span class="line">主要是在多样本的RNA-seq数据结果中使用.</span><br><span class="line">本模式下有效的选项:-G, -o, -c,-m,-F,-T,-f,-i,-l</span><br></pre></td></tr></table></figure><blockquote><p>使用hisat2结果作为输入时, 首先在比对时要指定–dta选项,其次需要进行排序</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">samtools view -Su alns.sam | samtools sort - alns.sorted</span><br></pre></td></tr></table></figure><h2 id="输出文件"><a href="#输出文件" class="headerlink" title="输出文件"></a>输出文件</h2><p>主要的输出:</p><ul><li>.GTF文件, 组装的转录本</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#seqname source      feature     start   end     score   strand  frame attributes</span></span><br><span class="line"><span class="comment">#chrX    StringTie   transcript  281394  303355  1000    +       .     gene_id "ERR188044.1"; transcript_id "ERR188044.1.1"; reference_id "NM_018390"; ref_gene_id "NM_018390";ref_gene_name "PLCXD1"; cov "101.256691"; FPKM "530.078918"; TPM "705.667908";</span></span><br><span class="line"><span class="comment">#chrX    StringTie   exon        281394  281684  1000    +       .     gene_id "ERR188044.1"; transcript_id "ERR188044.1.1"; exon_number "1"; reference_id "NM_018390";ref_gene_id "NM_018390"; ref_gene_name "PLCXD1"; cov "116.270836";</span></span><br></pre></td></tr></table></figure><ul><li>.tab文件, 基因表达量</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Gene ID     Gene Name   Reference   Strand  Start   End     Coverage    FPKM        TPM</span></span><br><span class="line"><span class="comment">#NM_000451   SHOX        chrX        +       624344  646823  0.000000    0.000000    0.000000</span></span><br><span class="line"><span class="comment">#NM_006883   SHOX        chrX        +       624344  659411  0.000000    0.000000    0.000000</span></span><br></pre></td></tr></table></figure><ul><li><p>.GTF文件, 能与参考注释匹配的完全覆盖转录<br>同组装的转录本</p></li><li><p>用于Ballgown进行下游差异分析的文件<br>总共有5个文件, e2t.ctab, e_data.ctab, i2t.ctab, i_data.ctab, t_data.ctab</p></li><li><p>在merge mode, merged_gtf文件<br>如果stringtie在merge mode下运行的话，会将输入的一系列GTF/GFF文件合并组装成无冗余的转录本。输出的文件只是包含转录本，没有其他的数据如coverage，FPKM，TPM。stringtie可以用这个新的转录本重新计算表达量，但是你得设置-e参数。如果你要寻找新的转录本或者寻找转录本的来源，你可以使用gffcompare软件来实现。</p></li></ul><h2 id="结合Ballgown进行差异分析"><a href="#结合Ballgown进行差异分析" class="headerlink" title="结合Ballgown进行差异分析"></a>结合Ballgown进行差异分析</h2><h3 id="完全的差异分析"><a href="#完全的差异分析" class="headerlink" title="完全的差异分析"></a>完全的差异分析</h3><p><img src="https://ccb.jhu.edu/software/stringtie/DE_pipeline.png" alt="差异分析"></p><p>推荐的流程:</p><ol><li><p>对每个样本, 使用hisat2 –dta选项与参考基因组进行比对。<br>在比对时，我们强烈推荐加入参考注释信息。这可以通过hisat2 –ss/–exon实现,也可以通过hisat2的–know-splicesite-infile实现。值得注意的是，你一定要对输出的比对文件进行排序和转换成BAM文件。</p></li><li><p>对得到的每个样本的比对文件，用strintie进行组装。<br>我们推荐使用-G参数提供参考注释(如果有的话.)</p></li><li><p>用生成组装文件，使用stringtie –merge生成无冗余的转录本<br>同样的，如果有参考注释，也推荐使用</p></li><li><p>对每个样本的比对文件, 使用stringtie -B/-b, -G和-e选项计算表达量和生成Ballgown所需的table文件。<br>-G选项指定第三步生成无冗余转录本，这是唯一没有使用参考注释的情况。虽然说这里的-e选项不是必需的，但是使用它可以得到一个更准确的结果。</p></li><li><p>使用Ballgown进行差异分析</p></li></ol><h3 id="简化的差异分析"><a href="#简化的差异分析" class="headerlink" title="简化的差异分析"></a>简化的差异分析</h3><p><img src="https://ccb.jhu.edu/software/stringtie/DE_pipeline_refonly.png" alt="简化的差异分析"></p><hr><h2 id="stringtie结合DESeq2和edgeR的差异分析"><a href="#stringtie结合DESeq2和edgeR的差异分析" class="headerlink" title="stringtie结合DESeq2和edgeR的差异分析"></a>stringtie结合DESeq2和edgeR的差异分析</h2><ol><li>使用stringtie -e得到定量结果</li><li>使用<a href="https://ccb.jhu.edu/software/stringtie/dl/prepDE.py" target="_blank" rel="noopener">“prepDE.py”</a>提取定量结果生成counts矩阵</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># prepDE.py [options]</span></span><br><span class="line"><span class="comment"># -i &lt;input&gt; 指定gtfs文件的路径和样品ID的txt文件</span></span><br><span class="line"><span class="comment"># -g G 指定gene count matrix的输出路径</span></span><br><span class="line"><span class="comment"># -t T 指定transcripts count matrix的输出路径</span></span><br><span class="line"><span class="comment"># -l length 指定平均read长度</span></span><br><span class="line"><span class="comment"># -p pattern选择样品子路径的正则表达式</span></span><br><span class="line"><span class="comment"># -c 是否合并重复的gene,虽然它们有不同的gene ID</span></span><br><span class="line"><span class="comment"># -s string 指定stringtie添加geneID前缀的字符串,默认为MSTRG</span></span><br><span class="line"><span class="comment"># -k Key 如果-c指定,则指定本脚本添加到gneIDs的前缀, 默认为prepG</span></span><br><span class="line"><span class="comment"># --legend=Legend 如果-c指定,转录比对到geneIDs的表头文件的输出路径,默认为legend.csv</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#prepDE.py -i sample_lst.txt</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## sample_lst.txt</span></span><br><span class="line"> <span class="comment">## ERR188021 &lt;PATH_TO_ERR188021.gtf&gt;</span></span><br><span class="line"> <span class="comment">## ERR188023 &lt;PATH_TO_ERR188023.gtf&gt;</span></span><br><span class="line"> <span class="comment">## ERR188024 &lt;PATH_TO_ERR188024.gtf&gt;</span></span><br></pre></td></tr></table></figure><ol start="3"><li>使用DESeq2进行差异分析</li></ol><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">countData &lt;- as.matrix(read.csv(<span class="string">'gene_count_matrix.csv'</span>, row.names=<span class="string">'gene_id'</span>))</span><br><span class="line">colData &lt;- read.csv(PHENO_DATA, sep=<span class="string">'\t'</span>, row.names=<span class="number">1</span>) <span class="comment"># 这里是你的表型文件</span></span><br><span class="line">all(rownames(colData) %<span class="keyword">in</span>% colnames(countData))<span class="comment"># 检测是否一致</span></span><br><span class="line">countData &lt;- countData[, rownames(colData)]</span><br><span class="line">all(rownames(colData) == colnames(countData))</span><br><span class="line"></span><br><span class="line">dds &lt;- DESeqDataSetFromMatrix(countData = countData,</span><br><span class="line">  colData = colData,</span><br><span class="line">  design=~CHOOSE_FEATURE)</span><br><span class="line">dds &lt;- DESeq(dds)</span><br><span class="line">res &lt;- results(dds)</span><br></pre></td></tr></table></figure><hr><h2 id="组装super-reads"><a href="#组装super-reads" class="headerlink" title="组装super-reads"></a>组装super-reads</h2><p>stringtie还可以把短的transcripts组装成长的contigs，我们把这个叫做super-reads。这一步可以省略，但我们还是推荐使用这一步，因为他可以提高转录本组装的正确性。不过你需要安装MaSuRCA genome assembler包。</p><p>1.super-reads的生成</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">superreads.pl reads_1.fastq reads_2.fastq &lt;masurca_path&gt; [options]*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选项</span></span><br><span class="line">-t &lt;num_threads&gt;</span><br><span class="line">-j &lt;jf_size&gt; MasuRCA需要运行Jellyfish,这里设置后者使用的<span class="built_in">hash</span> size</span><br><span class="line">-s &lt;step&gt;打印运行成功的步骤</span><br><span class="line">-r &lt;paired_read_prefix&gt; 设置paired <span class="built_in">read</span>的前缀</span><br><span class="line">-f &lt;fragment_size&gt;设置mean library insert length</span><br><span class="line">-d &lt;stdev&gt;设置insert length的标准偏差</span><br><span class="line">-l &lt;name&gt; 设置组装的super-reads文件名</span><br><span class="line">-u &lt;prefix&gt;设置为组装的reads的文件名</span><br></pre></td></tr></table></figure><ol start="2"><li>super-reads比对到参考基因组上<br>可以使用你喜欢的比对软件，如tophat，hisat，bowtie等。比如：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tophat [options]* &lt;genome_index_base&gt; PE_reads_1.notAssembled.fq.gz,super_reads.fq PE_reads_2.notAssembled.fq.gz</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
            <tag> 定量 </tag>
            
            <tag> 组装 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>芯片专题 AffyMetrix</title>
      <link href="/2018/10/12/%E8%8A%AF%E7%89%87%E4%B8%93%E9%A2%98-AffyMetrix/"/>
      <url>/2018/10/12/%E8%8A%AF%E7%89%87%E4%B8%93%E9%A2%98-AffyMetrix/</url>
      
        <content type="html"><![CDATA[<h2 id="一、芯片基础"><a href="#一、芯片基础" class="headerlink" title="一、芯片基础"></a>一、芯片基础</h2><h3 id="1-1-芯片平台和包"><a href="#1-1-芯片平台和包" class="headerlink" title="1.1 芯片平台和包"></a>1.1 芯片平台和包</h3><table><thead><tr><th>平台</th><th>包</th></tr></thead><tbody><tr><td>illumina</td><td>beadarray, lumi</td></tr><tr><td>affymatrix</td><td>affy,simpleaffy, oligo</td></tr><tr><td>agilent</td><td>没有找到</td></tr></tbody></table><a id="more"></a><h3 id="1-2-bioconductor包内置芯片数据"><a href="#1-2-bioconductor包内置芯片数据" class="headerlink" title="1.2 bioconductor包内置芯片数据"></a>1.2 bioconductor包内置芯片数据</h3><blockquote><p><a href="http://www.bio-info-trainee.com/1399.html" target="_blank" rel="noopener">http://www.bio-info-trainee.com/1399.html</a></p></blockquote><h3 id="1-3-GEO数据库"><a href="#1-3-GEO数据库" class="headerlink" title="1.3 GEO数据库"></a>1.3 GEO数据库</h3><ul><li>GEO platform: GPL</li><li>GEO sample:    GSM</li><li>GEO series:    GSE</li><li>GEO dataset:    GDS</li></ul><p>处理GEO数据有两条思路,第一条速录是利用GEOquery来下载。另一条则是自己下载原始的芯片数据，然后转换成表达矩阵.当然，有些比较常用的芯片则是有对应的包,我们只需要把对应包进行安装就有相应的芯片数据了。</p><h4 id="1-3-1-GEOquery"><a href="#1-3-1-GEOquery" class="headerlink" title="1.3.1 GEOquery"></a>1.3.1 GEOquery</h4><p>getGEO(GEOID, destdir):</p><ul><li>GDS858:     下载数据集</li><li>GPL96：    下载芯片设计信息,probe-geneID对应表(soft文件)</li><li>GSE1009:    下载表达矩阵,在下载该数据时GPL96.soft也会自动下载,但无法读取.得用GPL96作为ID使用getGEO函数.这时候的getGPL干脆设为False</li></ul><p>getGEOfile:         下载GEO soft文件<br>getGEOSuppFiles: 下载原始数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 使用GDS858的ID下载</span><br><span class="line">GDS = getGEO(&apos;GDS858&apos;, destdir=&apos;.&apos;)</span><br><span class="line">expr_matrix = Table(GDS)#得到表达矩阵</span><br><span class="line">Des_info = Meta(GDS)#得到描述信息(metadata)</span><br><span class="line">eSet = GDS2eSet(GDS, do.log2=T)#得到expressionSet,做log2变换</span><br><span class="line"></span><br><span class="line"># 使用GSE1009的ID下载</span><br><span class="line"># 返回的是含expressionSet对象的list</span><br><span class="line">genes = geneNames(GSE[[1]])# 得到gene名, geneNames是biobase包里面的</span><br><span class="line">samples = sampleNames(GSE[[1]])# 得到样品名</span><br><span class="line">pdata = pData(GSE[[1]])# 得到描述信息(metadata)</span><br><span class="line">expr_matrix = exprs(GSE[[1]])# 得到表达矩阵</span><br><span class="line"></span><br><span class="line"># GPL16699的ID下载</span><br><span class="line">Des_info = Meta(GPL)# 得到描述信息</span><br><span class="line">Annotation = Table(GPL)# 得到芯片注释信息(geneID-probeID)</span><br><span class="line"></span><br><span class="line"># 下载原始数据信息</span><br><span class="line">rawdata = getGEOSuppFiles(GSE1009)</span><br></pre></td></tr></table></figure><h4 id="1-3-2-GEO页面"><a href="#1-3-2-GEO页面" class="headerlink" title="1.3.2 GEO页面"></a>1.3.2 GEO页面</h4><p><img src="https://s1.ax1x.com/2018/07/19/P3GY5j.png" alt="P3GY5j.png"></p><h3 id="1-4-原始数据的预处理"><a href="#1-4-原始数据的预处理" class="headerlink" title="1.4 原始数据的预处理"></a>1.4 原始数据的预处理</h3><ol><li><p>背景信号处理<br>由于图像处理软件对芯片划格后,取杂交点周围区域内每个像素的吸光度均值作为背景信号,但是芯片的不同区域像素不同则均值不同,各个区域扣除的背景则多少不一.所以要进行背景信号处理. 可以利用芯片最低信号轻度的点作为背景信号,或者把芯片非杂交点的背景吸光度均值作为整个芯片的背景信号.</p></li><li><p>芯片数据清理<br>经背景校正后的芯片数据会出现异常值,通常的处理方法就是去除这些异常值,去除的方法有:标准值法, 奇异值法, 变异系数法, 前景值法(front value &lt;200), 中位数法等等.Affymetrix的芯片则时直接将负值修正为一个固定值.</p></li></ol><p>紧接着,对于缺失值的处理,方法有多种.一个时删除, 如果某行或某列的缺失值多于某个阈值,则删除该行/列. 另一种是补全.补全值的选择有使用0值补全,使用均值或中值补全,还可以时K邻近法进行补全.</p><ol start="3"><li><p>归一化<br>由于芯片数据值变化很大, 呈偏态,标准差大.但是后续的差异分析基本都是假定数据的正态分布,所以可以使用对数转换使数据趋于正态分布, 减少标准差.然后是消除技术误差/偏差.这时候使用的方法有平均数标准化, 中位数标准化等方法.此时就得到了表达矩阵.</p></li><li><p>差异分析<br>芯片数据的差异分析有三种方法：</p></li></ol><ul><li>倍数分析法(fold change)</li><li>参数检验(t-test)</li><li>非参数检验(经验贝叶斯,SAM法)</li></ul><p>常用的软件有:limma、DESeq2、edgeR、GFOLD等。</p><h2 id="二、使用Affy包分析芯片质量"><a href="#二、使用Affy包分析芯片质量" class="headerlink" title="二、使用Affy包分析芯片质量"></a>二、使用Affy包分析芯片质量</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span>(<span class="string">'http://biconductor.org/biocLite.R'</span>)</span><br><span class="line">biocLite(c(<span class="string">'affy'</span>, <span class="string">'simpleaffy'</span>))</span><br></pre></td></tr></table></figure><h3 id="2-1-读取CEL文件-查看基本信息"><a href="#2-1-读取CEL文件-查看基本信息" class="headerlink" title="2.1 读取CEL文件,查看基本信息"></a>2.1 读取CEL文件,查看基本信息</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">suppressPackageStartupMessages(&#123;</span><br><span class="line">    <span class="keyword">library</span>(affy))</span><br><span class="line">    <span class="keyword">library</span>(simpleaffy))</span><br><span class="line"></span><br><span class="line"><span class="comment">###################读取文件####################</span></span><br><span class="line">filenames = list.files(<span class="string">'./GSE30668'</span>, pattern=<span class="string">'*.CEL'</span>)</span><br><span class="line">the.data = ReadAffy(filenames=paste0(<span class="string">'./GSE30668/'</span>, filenames, sep=<span class="string">''</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">##############芯片基本信息####################</span></span><br><span class="line">old.names = sampleNames(the.data) <span class="comment"># 芯片名</span></span><br><span class="line">sampleNames(the.data) = gsub(<span class="string">'.CEL'</span>, <span class="string">''</span>, filenames)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 完美匹配探针,错配探针; perfect match probes / mismatch probes</span></span><br><span class="line">pm.data = pm(the.data)</span><br><span class="line">mm.data = mm(the.data)</span><br><span class="line">head(pm.data)</span><br><span class="line">head(mm.data)</span><br><span class="line"></span><br><span class="line">pdata = pData(the.data)</span><br><span class="line">probes = geneNames(the.data)</span><br></pre></td></tr></table></figure><h3 id="2-2-查看芯片质量"><a href="#2-2-查看芯片质量" class="headerlink" title="2.2 查看芯片质量"></a>2.2 查看芯片质量</h3><ul><li>灰度图、灰度值</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">nmatrix = length(filenames)</span><br><span class="line"></span><br><span class="line"><span class="comment">#################### 画灰度图,并统计灰度值 ######################</span></span><br><span class="line">par(mfrow=c(ceiling(nmatrix/<span class="number">2</span>), <span class="number">2</span>))</span><br><span class="line">par(mar=c(<span class="number">0.2</span>,<span class="number">0.2</span>,<span class="number">0.2</span>,<span class="number">0.2</span>))</span><br><span class="line"><span class="comment"># 设置调色板为灰度</span></span><br><span class="line">pallette.gray = c(grep(gray(<span class="number">0</span>:<span class="number">10</span>/<span class="number">10</span>), times=seq(<span class="number">1</span>, <span class="number">41</span>,by=<span class="number">4</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1</span>:nmatrix) &#123;</span><br><span class="line">image(the.data[, i], col=pallette.gray)</span><br><span class="line"><span class="comment"># 如果芯片图像有版斑块就有可能时坏片</span></span><br><span class="line">&#125;</span><br><span class="line">par(mfrow=c(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">par(mar=c(<span class="number">4</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">0.5</span>))</span><br><span class="line">par(cex=<span class="number">0.7</span>)</span><br><span class="line"><span class="keyword">if</span> (nmatrix &gt; <span class="number">40</span>) par(cex=<span class="number">0.5</span>)</span><br><span class="line">colors = rainbow(nmatrix*<span class="number">1.2</span>)</span><br><span class="line">boxplot(the.data, col=colors, xlab=<span class="string">'Sample'</span>, ylab=<span class="string">'Log intensity'</span>)</span><br></pre></td></tr></table></figure><ul><li>曲线图，MA-plot，RNA降解分析</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##################### 画曲线图 ######################</span></span><br><span class="line">par(mar=c(<span class="number">4</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">0.5</span>))</span><br><span class="line">hist(the.data, lty=<span class="number">1</span>:<span class="number">3</span>, col=colors)</span><br><span class="line">legend(<span class="string">'topright'</span>, legend=sampleNames(the.data),</span><br><span class="line">lty=<span class="number">1</span>:<span class="number">3</span>, col=colors, </span><br><span class="line">box.col=<span class="string">'white'</span>, xpd=<span class="literal">T</span>,</span><br><span class="line">cex=<span class="number">1.5</span>)</span><br><span class="line">box()</span><br><span class="line"></span><br><span class="line"><span class="comment">####################### MA-plot #####################</span></span><br><span class="line"><span class="comment"># 作图得到IQR,如果IQR较大的话芯片可能有问题</span></span><br><span class="line">par(mfrow=c(ceiling(nmatrix/<span class="number">2</span>), <span class="number">2</span>))</span><br><span class="line">par(mar=c(<span class="number">3</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">0.5</span>))</span><br><span class="line">par(tcl=<span class="number">0.2</span>)</span><br><span class="line">par(mgp=c(<span class="number">2</span>,<span class="number">0.5</span>,<span class="number">0</span>))</span><br><span class="line">MAplot(the.data, cex=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">####################### RNA降解分析 #################</span></span><br><span class="line"><span class="comment"># 理想情况下每个样品的线(分段)是平行的</span></span><br><span class="line">par(mfrow=c(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">par(mar=c(<span class="number">4</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">0.5</span>))</span><br><span class="line">RNAdeg = AffyRNAdeg(the.data)</span><br><span class="line">summaryAffyRNAdeg(RNAdeg)</span><br><span class="line">plotAffyRNAdeg(RNAdeg, cols=colors)</span><br><span class="line">legend(<span class="string">'topleft'</span>, legend=sampleNames(the.data),</span><br><span class="line">lty=<span class="number">1</span>, col=colors,</span><br><span class="line">box.col=<span class="string">'white'</span>, xpd=<span class="literal">T</span>)</span><br><span class="line">box()</span><br></pre></td></tr></table></figure><ul><li>背景信号值、样品缩放因子、阳性信号值（表达基因占比，内参占比）</li></ul><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">suppressPackageStartupMessages(<span class="keyword">library</span>(simpleaffy))</span><br><span class="line"></span><br><span class="line"><span class="comment">################# 查看背景信号值 ####################</span></span><br><span class="line"><span class="comment"># 如果背景信号值太大,说明芯片结果并不好(太大是多大?)</span></span><br><span class="line">qc.data = qc(the.data)</span><br><span class="line">avbg.data = as.data.frame(sort(avbg(qc.data)))</span><br><span class="line">max(avbg.data)</span><br><span class="line"></span><br><span class="line"><span class="comment">################# 样品scale factor###################</span></span><br><span class="line"><span class="comment"># 如果scale factor的最大值与最小值的比值超过3倍的话</span></span><br><span class="line"><span class="comment"># 芯片结果也不好</span></span><br><span class="line">sfs.data = sort(sfs(qc.data))</span><br><span class="line">ratio = max(sfs.data) / min(sfs.data)</span><br><span class="line">ratio</span><br><span class="line"></span><br><span class="line"><span class="comment">################# 有表达的基因占比多少 ###############</span></span><br><span class="line"><span class="comment"># 表达基因占比太小表明芯片结果有问题</span></span><br><span class="line">per.data = as.data.frame(percent.present(qc.data))</span><br><span class="line">min(per.data)</span><br><span class="line"></span><br><span class="line"><span class="comment">################# 内参基因的表达占比 #################</span></span><br><span class="line">rat.data = ratios(qc.data)</span><br><span class="line">head(rat.data)</span><br></pre></td></tr></table></figure><h2 id="三、使用Affy包处理原始芯片数据"><a href="#三、使用Affy包处理原始芯片数据" class="headerlink" title="三、使用Affy包处理原始芯片数据"></a>三、使用Affy包处理原始芯片数据</h2><p>从原始芯片数据开始处理需要经过四个步骤：背景校正、归一化(标准化)、计算表达量、得到表达矩阵。你也可以通过使用mas5或rma或gcrma函数直接从读入的原始芯片数据(见2.1, the.data)计算表达量(见3.3),最后得到表达矩阵.</p><h3 id="3-1-背景校正"><a href="#3-1-背景校正" class="headerlink" title="3.1.背景校正"></a>3.1.背景校正</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">suppressPackageStartupMessages(<span class="keyword">library</span>(affy))</span><br><span class="line">suppressPackageStartupMessages(<span class="keyword">library</span>(simpleaffy))</span><br><span class="line">load(<span class="string">'GSE30668_eSet.RData'</span>)</span><br><span class="line"><span class="comment">################ rma, mas 两种校正方法###########################</span></span><br><span class="line"><span class="comment"># mas校正后pm和mm的值都被重新计算了</span></span><br><span class="line"><span class="comment"># rma校正仅针对pm,mm的值不会变化</span></span><br><span class="line">rma.data = bg.correct(the.data, method=<span class="string">'rma'</span>)</span><br><span class="line">mas.data = bg.correct(the.data, method=<span class="string">'mas'</span>)</span><br><span class="line">crt.data = list(rma.data, mas.data)</span><br></pre></td></tr></table></figure><h3 id="3-2-归一化处理"><a href="#3-2-归一化处理" class="headerlink" title="3.2.归一化处理"></a>3.2.归一化处理</h3><p>芯片的归一化方法有线性缩放法、非线性缩放法、分位数法、Cyclic loess法、Contrasts法。</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这里取rma背景校正的结果进行后续的归一化.</span></span><br><span class="line">data = crt.data[[<span class="number">1</span>]]</span><br><span class="line"><span class="comment">############## 线性缩放 ############################</span></span><br><span class="line"><span class="comment"># 选择某个芯片作为参考,其他芯片与其分别做线性回归</span></span><br><span class="line"><span class="comment"># 得到的回归线对剩余其他芯片做缩放(同一缩放倍数)</span></span><br><span class="line"></span><br><span class="line">ln.data = normalize(data, method=<span class="string">'constant'</span>)</span><br><span class="line">head(pm(ln.data)/pm(data))</span><br><span class="line">head(mm(ln.data)/mm(data))</span><br><span class="line"><span class="comment">############# 非线性缩放 ###########################</span></span><br><span class="line"><span class="comment"># 仅使用部分芯片结果做非线性拟合,然后进行缩放(不同缩放倍数)</span></span><br><span class="line">invar.data = normalize(data, method=<span class="string">'invariantest'</span>)</span><br><span class="line">head(pm(invar.data)/pm(data))</span><br><span class="line">head(mm(invar.data)/mm(data))</span><br><span class="line"><span class="comment">############# 分位数(quantile) #####################</span></span><br><span class="line"><span class="comment"># 前提是假设每个芯片信号的经验分布函数一样</span></span><br><span class="line"><span class="comment"># 任两个芯片的QQ-plot会形成45度对角线</span></span><br><span class="line">qt.data = normalize(data, method=<span class="string">'quantiles'</span>)</span><br><span class="line">head(pm(qt.data)/pm(data))</span><br><span class="line">head(mm(qt.data)/mm(data))</span><br><span class="line"><span class="comment">############# Cyclic loess #########################</span></span><br><span class="line">loe.data = normalize(data, method=<span class="string">'loess'</span>)</span><br><span class="line"><span class="comment">############# contrasts ############################</span></span><br><span class="line">cont.data = normalize(data, method=<span class="string">'contrasts'</span>)</span><br></pre></td></tr></table></figure><h3 id="3-3-计算表达量"><a href="#3-3-计算表达量" class="headerlink" title="3.3 计算表达量"></a>3.3 计算表达量</h3><ul><li><p>使用affy::computeExprSet计算表达矩阵,它需要指定统计方法和PM校正方式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">################# 显示PM校正方式种类 #######################</span><br><span class="line">pmcorrect.methods()</span><br><span class="line">################# 显示统计方法种类 ##########################</span><br><span class="line">generateExprSet.methods()</span><br><span class="line">################# 计算表达矩阵 ######################</span><br><span class="line">eSet.pmo.liw = computeExprSet(ln.data, pmcorrect.method=&apos;pmonly&apos;, summary.method=&apos;liwong&apos;)</span><br></pre></td></tr></table></figure></li><li><p>使用mas5或rma或gcrma函数一步到位</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">eSet.mas5 = mas5(the.data)</span><br><span class="line">eSet.rma = rma(the.data)</span><br><span class="line">suppressPackageStartupMessages(library(gcrma))</span><br><span class="line">eset.gcrma = gcrma(the.data)</span><br></pre></td></tr></table></figure></li></ul><h3 id="3-4-得到表达矩阵"><a href="#3-4-得到表达矩阵" class="headerlink" title="3.4 得到表达矩阵"></a>3.4 得到表达矩阵</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">############### 进行rma或mas5处理 ###############</span></span><br><span class="line"><span class="comment">#eSet.mas5 = mas5(the.data)</span></span><br><span class="line"><span class="comment">#eSet.rma = rma(the.data)</span></span><br><span class="line"><span class="comment">############### 获取表达矩阵 ################</span></span><br><span class="line"><span class="comment"># 注意，rma法计算表达量</span></span><br><span class="line">expr.rma.lg2 = exprs(eSet.rma)</span><br><span class="line">expr.rma.nlg = <span class="number">2</span>^expr.rma.lg2</span><br><span class="line">expr.mas5.nlg = exprs(eSet.mas5)</span><br><span class="line">expr.mas5.lg2 = log2(expr.mas5.nlg)</span><br><span class="line"></span><br><span class="line"><span class="comment">############### 筛选有表达的基因 ################</span></span><br><span class="line"><span class="comment"># mas5calls: P为present, A为absent, M为marginal</span></span><br><span class="line">eSet.calls = mas5calls(the.data)</span><br><span class="line">expr.calls = exprs(eSet.calls)</span><br><span class="line">probes = apply(expr.calls, <span class="number">1</span>, <span class="keyword">function</span>(x) any(x==<span class="string">'P'</span>))</span><br><span class="line"><span class="comment"># 以rma为例</span></span><br><span class="line">expr.chose = expr.rma.lg2[probes, ]</span><br><span class="line">save(expr.chose, file=<span class="string">'GEO30668_expr_rma_chose.RData'</span>)</span><br></pre></td></tr></table></figure><h3 id="3-5-差异分析和注释"><a href="#3-5-差异分析和注释" class="headerlink" title="3.5 差异分析和注释"></a>3.5 差异分析和注释</h3><p>差异分析可以使用limma直接对表达矩阵进行。注释的话，需要通过GEOquery得到的GPL文件中获取探针ID对应的基因ID。然后可以进行其他分析如富集分析、基因关联分析。</p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生信基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>比对 STAR</title>
      <link href="/2018/10/12/%E6%AF%94%E5%AF%B9-STAR/"/>
      <url>/2018/10/12/%E6%AF%94%E5%AF%B9-STAR/</url>
      
        <content type="html"><![CDATA[<p>STAR 的比对速率要比 bowtie 快那么一丢丢。</p><a id="more"></a><h2 id="1-生成索引"><a href="#1-生成索引" class="headerlink" title="1. 生成索引"></a>1. 生成索引</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">STAR --runThreadN numberOfThreads \</span><br><span class="line">--runMode genomeGenerata \</span><br><span class="line">--genomeDir /path/to/output/index \</span><br><span class="line">--genomeFastaFiles /path/to/ref.fasta1 /path/to/ref.fasta2... \</span><br><span class="line">--sjdbGTFfile /path/to/annotations.gtf \</span><br><span class="line">--sjdbOverhang ReadLength-1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用的参考基因组：一般来说，不应该包含patches和可变单倍体。可以使用的比如：</span></span><br><span class="line"><span class="comment"># EMSEMBL：ftp://ftp.ensembl.org/pub/release-77/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz</span></span><br><span class="line"><span class="comment"># NCBI：ftp://ftp.ncbi.nlm.nih.gov/genbank/genomes/Eukaryotes/vertebrates_mammals/Homo_sapiens/GRCh38/seqs_for_alignment_pipelines/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># annotation: 来源要和参考基因组匹配,比如注释和基因组都是来源ENSEMBL的,或者都是来自UCSC的;千万不要混用。这是因为它们对染色体的命名不一样。</span></span><br><span class="line"><span class="comment"># 如果你手动更改成一样的也可以使用。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --sjdbGTFfile&lt;anno.gtf&gt;选项默认只处理GTF中exon的行;</span></span><br><span class="line"><span class="comment"># --sddbGTFfeatureExon exon 默认值为exon,使只处理exon的行.</span></span><br><span class="line"><span class="comment"># --sjdbGTFtagExonParent 如果使用的是GTF3格式文件,需要指定本选项。</span></span><br><span class="line"><span class="comment"># --sjdbGTFtagExonParentTranscript &lt;transcript_id&gt; 如果指定,将只会处理能比对到指定transcript(transcript_id)的exon</span></span><br><span class="line"><span class="comment"># --sjdbFileChrStartEnd &lt;sjdbFile.txt&gt; 指定可变剪接的注释文件</span></span><br><span class="line"><span class="comment"># sjdbOverhang: 对于2x100b的Illumina双端测序来说, 是100-1=99.如果length是变化的，就用max(length)-1</span></span><br><span class="line"><span class="comment"># --genomeSAindexNbases &lt;int&gt; 对于较小的基因组,需要用此选项指定N的值.计算方式: min(14, log2(genomeLength)/2-1). 1Mb的基因组一般为7.</span></span><br><span class="line"><span class="comment"># --genomeChrBinNbits &lt;int&gt;对于较大的基因组,需要用此选项指定N的值,计算方式: min(18, log2(genomeLength/NumberofReference)).对于3GB含100000个染色体/scaffolds的基因组来说,取15.</span></span><br></pre></td></tr></table></figure><h2 id="2-进行比对"><a href="#2-进行比对" class="headerlink" title="2. 进行比对"></a>2. 进行比对</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">STAR --runThreadN numberofthreads \</span><br><span class="line">--genomeDir index_path \</span><br><span class="line">--readFilesIn read1.fastq read2.fastq</span><br><span class="line">--outFileNamePrefix path/prefix</span><br><span class="line"></span><br><span class="line"><span class="comment"># --readFilesCommand &lt;command&gt;如果是压缩文件,可以提供解压缩命令.zcat, gzip -c, bzip2 -c.依据压缩文件的压缩形式而不同.</span></span><br><span class="line"><span class="comment"># --outSAMstrandField introMotif 指定值为introMotif将会为unstranded RNA-seq数据生成可用于cufflinks和cuffdiff的文件(含XS strand attribute)</span></span><br><span class="line"><span class="comment"># --outFilterIntroMotifs RemoveNoncanonical 后续进行cufflinks的话,推荐设定此选项.</span></span><br><span class="line"><span class="comment"># --outSAMtype BAM Unsorted 输出未排序的aligned.out.bam,可以直接用于HTSeq,不用进行name sorting</span></span><br><span class="line"><span class="comment"># --outSAMtype BAM SortedByCoordinate 输出根据坐标排序的aligned.sortedByCoord.out.bam,与samtools sort命令的输出一致</span></span><br><span class="line"><span class="comment"># --outSAMtype BAM Unsorted SortedByCoordinate两种情况均输出.</span></span><br><span class="line"><span class="comment"># --quantMode TranscriptomeSAM将会输出翻译成转录本坐标的bam文件,aligned.toTranscriptome.out.bam.</span></span><br><span class="line">这个可以用于转录本定量软件的输入.比如RSEM, eXpress.</span><br></pre></td></tr></table></figure><h2 id="3-2-pass-mapping-with-re-generated-genome"><a href="#3-2-pass-mapping-with-re-generated-genome" class="headerlink" title="3. 2-pass mapping with re-generated genome"></a>3. 2-pass mapping with re-generated genome</h2><p>在初次比对后,为了提高比对到新的剪接位点的reads数,推荐再进行一次比对.新的比对将需要提供上一次比对产生的剪接位点文件.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 把SJ.out.tab文件合并,过滤掉在线粒体染色体上的junction、non-canonical junction。</span></span><br><span class="line"><span class="comment"># 1. 如果使用了注释的话,这里只需考虑新的剪接位点.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 把1.中得到的合并文件通过--sjdbFileChrStartEnd指定输入, --sjdbGTFile指定注释,重新生成索引</span></span><br><span class="line"><span class="comment"># 3. 使用新的索引再次进行比对</span></span><br></pre></td></tr></table></figure><h2 id="4-2-pass-mapping-without-re-generated-genome"><a href="#4-2-pass-mapping-without-re-generated-genome" class="headerlink" title="4. 2-pass mapping without re-generated genome"></a>4. 2-pass mapping without re-generated genome</h2><p>要进行此项,在首次进行比对时,就要设置–twopass1readsN选项,值为所有reads数.此外，你还得设置–sjdbOverhang参数.</p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件和包 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
